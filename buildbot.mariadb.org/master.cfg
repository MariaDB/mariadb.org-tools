# -*- python -*-
# ex: set filetype=python:

from buildbot.plugins import *
from buildbot.process.properties import Property, Properties
from buildbot.steps.shell import ShellCommand, Compile, Test, SetPropertyFromCommand
from buildbot.steps.mtrlogobserver import MTR, MtrLogObserver
from buildbot.steps.source.github import GitHub
from buildbot.process.remotecommand import RemoteCommand
from twisted.internet import defer
import sys
import docker
from datetime import timedelta

sys.setrecursionlimit(10000)

from constants import *
from utils import *
from locks import *
from common_factories import *

# This is the dictionary that the buildmaster pays attention to. We also use
# a shorter alias to save typing.
c = BuildmasterConfig = {}

# Load the slave, database passwords and 3rd-party tokens from an external private file, so
# that the rest of the configuration can be public.
config = { "private": { } }
exec(open("master-private.cfg").read(), config, { })

####### BUILDBOT SERVICES

# 'services' is a list of BuildbotService items like reporter targets. The
# status of each build will be pushed to these targets. buildbot/reporters/*.py
# has a variety to choose from, like IRC bots.


c['services'] = []
context = util.Interpolate("buildbot/%(prop:buildername)s")
gs = reporters.GitHubStatusPush(token=config["private"]["gh_mdbci"]["access_token"],
                                context=context,
                                startDescription='Build started.',
                                endDescription='Build done.',
                                verbose=True,
                                builders=github_status_builders)
c['services'].append(gs)

####### PROJECT IDENTITY

# the 'title' string will appear at the top of this buildbot installation's
# home pages (linked to the 'titleURL').
c['title'] = "MariaDB CI"
c['titleURL'] = "https://github.com/MariaDB/server"

# the 'buildbotURL' string should point to the location where the buildbot's
# internal web server is visible. This typically uses the port number set in
# the 'www' entry below, but with an externally-visible host name which the
# buildbot cannot figure out without some help.

c['buildbotURL'] = "https://buildbot.mariadb.org/"

# Custom plugin
# exec(open("grid.py").read())

# 'protocols' contains information about protocols which master will use for
# communicating with workers. You must define at least 'port' option that workers
# could connect to your master with this protocol.
# 'port' must match the value configured into the workers (with their
# --master option)
c['protocols'] = {'pb': {'port': 9992}}

####### DB URL

c['db'] = {
    # This specifies what database buildbot uses to store its state.
    'db_url' : config["private"]["db_url"]
}

mtrDbPool = util.EqConnectionPool("MySQLdb", config["private"]["db_host"], config["private"]["db_user"], config["private"]["db_password"], config["private"]["db_mtr_db"])

####### Disable net usage reports from being sent to buildbot.net
c['buildbotNetUsageData'] = None

####### SCHEDULERS

# Configure the Schedulers, which decide how to react to incoming changes.
c['schedulers'] = []

c['schedulers'].append(schedulers.Triggerable(name="s_upstream_all",
        builderNames=getBranchBuilderNames))

schedulerProtectedBranches = schedulers.Triggerable(name="s_protected_branches",
        builderNames=github_status_builders)
c['schedulers'].append(schedulerProtectedBranches)

schedulerPackages = schedulers.Triggerable(name="s_packages",
        builderNames=getAutobakeBuilderNames)
c['schedulers'].append(schedulerPackages)

schedulerBigtests = schedulers.Triggerable(name="s_bigtest",
        builderNames=getBigtestBuilderNames)
c['schedulers'].append(schedulerBigtests)

schedulerInstall = schedulers.Triggerable(name="s_install",
        builderNames=getInstallBuilderNames)
c['schedulers'].append(schedulerInstall)

schedulerUpgrade = schedulers.Triggerable(name="s_upgrade",
        builderNames=getUpgradeBuilderNames)
c['schedulers'].append(schedulerUpgrade)

schedulerEco = schedulers.Triggerable(name="s_eco",
        builderNames=getEcoBuilderNames)
c['schedulers'].append(schedulerEco)

schedulerDockerlibrary = schedulers.Triggerable(name="s_dockerlibrary",
        builderNames=getDockerLibraryNames)
c['schedulers'].append(schedulerDockerlibrary)

####### WORKERS

# The 'workers' list defines the set of recognized workers. Each element is
# a Worker object, specifying a unique worker name and password.  The same
# worker name and password must be configured on the worker.
c['workers'] = []

# Docker workers

## hz-bbw2-docker
c['workers'].append(worker.DockerLatentWorker("hz-bbw1-docker-tarball-debian-10", None,
                    docker_host=config["private"]["docker_workers"]["hz-bbw1-docker"],
                    image="quay.io/mariadb-foundation/bb-worker:debian10",
                    followStartupLogs=False,
                    autopull=True,
                    alwaysPull=True,
                    masterFQDN='buildbot.mariadb.org',
                    hostconfig={ 'shm_size':'1G' },
                    volumes=['/mnt/autofs/master_packages/:/packages'],
                    max_builds=1,
                    build_wait_timeout=0,
                    properties={ 'jobs':4, 'save_packages':True }))

c['workers'].append(worker.DockerLatentWorker("hz-bbw4-docker-tarball-debian-10", None,
                    docker_host=config["private"]["docker_workers"]["hz-bbw4-docker"],
                    image="quay.io/mariadb-foundation/bb-worker:debian10",
                    followStartupLogs=False,
                    autopull=True,
                    alwaysPull=True,
                    masterFQDN='buildbot.mariadb.org',
                    hostconfig={ 'shm_size':'1G' },
                    volumes=['/mnt/autofs/master_packages/:/packages'],
                    max_builds=1,
                    build_wait_timeout=0,
                    properties={ 'jobs':4, 'save_packages':True }))

c['workers'].append(worker.DockerLatentWorker("hz-bbw2-docker-eco-php-ubuntu-2004", None,
                    docker_host=config["private"]["docker_workers"]["hz-bbw2-docker"],
                    dockerfile=open("dockerfiles/eco-php-ubuntu-2004.dockerfile").read(),
                    followStartupLogs=False,
                    masterFQDN='buildbot.mariadb.org',
                    hostconfig={ 'shm_size':'6G' },
                    build_wait_timeout=0,
                    max_builds=1,
                    volumes=['/srv/buildbot/eco/code:/code', '/srv/buildbot/eco/build:/build'],
                    properties={ 'jobs':7, 'save_packages':False }))

c['workers'].append(worker.DockerLatentWorker("hz-bbw2-docker-eco-dbdeployer-ubuntu-2004", None,
                    docker_host=config["private"]["docker_workers"]["hz-bbw2-docker"],
                    dockerfile=open("dockerfiles/eco-dbdeployer-ubuntu-2004.dockerfile").read(),
                    followStartupLogs=False,
                    masterFQDN='buildbot.mariadb.org',
                    hostconfig={ 'shm_size':'6G' },
                    build_wait_timeout=0,
                    max_builds=1,
                    volumes=['/srv/buildbot/eco/dbdeployer:/dbdeployer'],
                    properties={ 'jobs':7, 'save_packages':False }))

c['workers'].append(worker.DockerLatentWorker("hz-bbw2-docker-eco-pymysql-python-3-9-slim-buster", None,
                    docker_host=config["private"]["docker_workers"]["hz-bbw2-docker"],
                    dockerfile=open("dockerfiles/eco-pymysql-python-3-9-slim-buster.dockerfile").read(),
                    followStartupLogs=False,
                    masterFQDN='buildbot.mariadb.org',
                    hostconfig={ 'shm_size':'6G' },
                    build_wait_timeout=0,
                    max_builds=1,
                    volumes=['/srv/buildbot/eco/pymysqlcode:/code'],
                    properties={ 'jobs':7, 'save_packages':False }))

c['workers'].append(worker.DockerLatentWorker("hz-bbw2-docker-eco-mysqljs-nodejs15-buster", None,
                    docker_host=config["private"]["docker_workers"]["hz-bbw2-docker"],
                    dockerfile=open("dockerfiles/eco-mysqljs-nodejs15-buster.dockerfile").read(),
                    followStartupLogs=False,
                    masterFQDN='buildbot.mariadb.org',
                    hostconfig={ 'shm_size':'6G' },
                    build_wait_timeout=0,
                    max_builds=1,
                    volumes=['/srv/buildbot/eco/mysqljscode:/code'],
                    properties={ 'jobs':7, 'save_packages':False }))

workers={}
def addWorker(worker_name_prefix, worker_id, worker_type, dockerfile, jobs=5, save_packages=False, shm_size='15G'):
    worker_name = worker_name_prefix + str(worker_id) + '-docker'
    name = worker_name + worker_type

    i = worker_id
    tls = None
    #if worker_name_prefix.startswith('aarch64'):
    #    tls = docker.tls.TLSConfig(verify=True, ca_cert='/srv/buildbot/tlscerts/ca-arm-bbw' + str(i)+ '.pem', client_cert=('/srv/buildbot/tlscerts/cert-arm-bbw' + str(i) + '.pem', '/srv/buildbot/tlscerts/key-arm-bbw' + str(i) + '.pem'))
    #else:
    #    tls = None

    if worker_name_prefix.startswith('hz'):
        b_name = 'x64-bbw'
    elif worker_name_prefix.startswith('intel'):
        b_name = 'x64-bbw'
    elif worker_name_prefix.startswith('p9'):
        b_name = 'p9-bbw'
    else:
        b_name = worker_name_prefix
    base_name = b_name + '-docker' + worker_type

    if base_name not in workers:
        workers[base_name] = [name]
    else:
        workers[base_name].append(name)

    volumes=['/srv/buildbot/ccache:/mnt/ccache', '/srv/buildbot/packages:/mnt/packages', '/mnt/autofs/master_packages/:/packages']
    # Set master FQDN - for VPN machines it should be 100.64.100.1
    fqdn = 'buildbot.mariadb.org'
    if worker_name_prefix.startswith('intel') or worker_name_prefix.startswith('bg'):
        fqdn = '100.64.100.1'
    if worker_name_prefix.startswith('p9-rhel'):
        fqdn = '10.103.203.6'
    if 'vladbogo' in dockerfile or 'quay' in dockerfile:
        dockerfile_str = None
        image_str = dockerfile
        need_pull = True
    else:
        dockerfile_str = open("dockerfiles/" + dockerfile).read()
        image_str = None
        need_pull = False
    if 'rhel' in worker_type and dockerfile_str is not None and not 'download' in dockerfile:
        dockerfile_str = dockerfile_str % (config["private"]["rhel_sub"]["user"], config["private"]["rhel_sub"]["password"])
    c['workers'].append(worker.DockerLatentWorker(name, None,
                        docker_host=config["private"]["docker_workers"][worker_name],
                        image=image_str,
                        dockerfile=dockerfile_str,
                        tls=tls,
                        autopull=True,
                        alwaysPull=need_pull,
                        followStartupLogs=False,
                        masterFQDN=fqdn,
                        build_wait_timeout=0,
                        max_builds=1,
                        hostconfig={ 'shm_size':shm_size},
                        volumes=volumes,
                        properties={ 'jobs':jobs, 'save_packages':save_packages }))


for w_name in ['hz-bbw', 'intel-bbw']:
    if w_name.startswith('hz'):
        jobs = 7
    else:
        jobs = 15
    if w_name == 'hz-bbw':
        for i in [2, 5]:
            addWorker(w_name, i, '-debian-9', 'quay.io/mariadb-foundation/bb-worker:debian9', jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-debian-9-i386', 'debian-9-i386.dockerfile', jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-debian-sid', 'quay.io/mariadb-foundation/bb-worker:debiansid', jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-debian-sid-i386', 'debian-sid-i386.dockerfile', jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-ubuntu-1804', 'quay.io/mariadb-foundation/bb-worker:ubuntu18.04', jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-sles-12', 'sles-12-download.dockerfile', jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-sles-15', 'sles-15-download.dockerfile', jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-valgrind-ubuntu-1804', "valgrind-ubuntu-1804.dockerfile", jobs=jobs, save_packages=False)
            addWorker(w_name, i, '-icc-ubuntu-1804', "vladbogo/bb:icc-ubuntu-1804", jobs=jobs, save_packages=False)
            addWorker(w_name, i, '-rhel-7', 'quay.io/mariadb-foundation/bb-worker:rhel7', jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-ubuntu-2204', "quay.io/mariadb-foundation/bb-worker:ubuntu22.04",jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-opensuse-15', 'opensuse-15.dockerfile', jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-clang-ubuntu-1804', "clang-ubuntu-1804.dockerfile", jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-fedora-34', 'quay.io/mariadb-foundation/bb-worker:fedora34', jobs=jobs, save_packages=True)
        for i in [1, 4]:
            addWorker(w_name, i, '-centos-7', 'quay.io/mariadb-foundation/bb-worker:centos7', jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-debian-10','quay.io/mariadb-foundation/bb-worker:debian10', jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-debian-11', 'quay.io/mariadb-foundation/bb-worker:debian11', jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-fedora-35', 'quay.io/mariadb-foundation/bb-worker:fedora35', jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-rhel-8', 'quay.io/mariadb-foundation/bb-worker:rhel8', jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-ubuntu-2004-clang', 'clang-ubuntu-2004.dockerfile', jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-ubuntu-2004', 'quay.io/mariadb-foundation/bb-worker:ubuntu20.04', jobs=jobs, save_packages=True)

    if w_name == 'intel-bbw':
        i=1
        addWorker(w_name, i, '-debian-9', 'quay.io/mariadb-foundation/bb-worker:debian9', jobs=jobs, save_packages=True)
        addWorker(w_name, i, '-debian-9-i386', 'debian-9-i386.dockerfile', jobs=jobs, save_packages=True)
        addWorker(w_name, i, '-debian-sid', 'quay.io/mariadb-foundation/bb-worker:debiansid', jobs=jobs, save_packages=True)
        addWorker(w_name, i, '-debian-sid-i386', 'debian-sid-i386.dockerfile', jobs=jobs, save_packages=True)
        addWorker(w_name, i, '-ubuntu-1804', 'quay.io/mariadb-foundation/bb-worker:ubuntu18.04', jobs=jobs, save_packages=True)
        addWorker(w_name, i, '-sles-12', 'sles-12-download.dockerfile', jobs=jobs, save_packages=True)
        addWorker(w_name, i, '-sles-15', 'sles-15-download.dockerfile', jobs=jobs, save_packages=True)
        addWorker(w_name, i, '-valgrind-ubuntu-1804', "valgrind-ubuntu-1804.dockerfile", jobs=jobs, save_packages=False)
        addWorker(w_name, i, '-icc-ubuntu-1804', "vladbogo/bb:icc-ubuntu-1804", jobs=jobs, save_packages=False)
        addWorker(w_name, i, '-rhel-7', 'quay.io/mariadb-foundation/bb-worker:rhel7', jobs=jobs, save_packages=True)
        addWorker(w_name, i, '-ubuntu-2204', "quay.io/mariadb-foundation/bb-worker:ubuntu22.04", jobs=jobs, save_packages=True)
        addWorker(w_name, i, '-opensuse-15', 'opensuse-15.dockerfile', jobs=jobs, save_packages=True)
        addWorker(w_name, i, '-clang-ubuntu-1804', "clang-ubuntu-1804.dockerfile", jobs=jobs, save_packages=True)
        addWorker(w_name, i, '-fedora-34', 'quay.io/mariadb-foundation/bb-worker:fedora34', jobs=jobs, save_packages=True)
        addWorker(w_name, i, '-ubuntu-2110', "quay.io/mariadb-foundation/bb-worker:ubuntu21.10", jobs=jobs, save_packages=True)

## apexis-bbw1-docker
c['workers'].append(worker.DockerLatentWorker("fjord1-docker-ubuntu-1804", None,
                    docker_host=config["private"]["docker_workers"]["apexis-bbw1-docker"],
                    dockerfile=open("dockerfiles/clang-ubuntu-1804.dockerfile").read(),
                    followStartupLogs=False,
                    masterFQDN='buildbot.mariadb.org',
                    hostconfig={ 'shm_size':'6G' },
                    max_builds=1,
                    volumes=['/opt/mariadb-buildbot/ccache:/mnt/ccache', '/opt/mariadb-buildbot/packages:/mnt/packages'],
                    properties={ 'jobs':7, 'save_packages':False }))

c['workers'].append(worker.DockerLatentWorker("fjord2-docker-ubuntu-1804", None,
                    docker_host=config["private"]["docker_workers"]["apexis-bbw2-docker"],
                    dockerfile=open("dockerfiles/clang-ubuntu-1804.dockerfile").read(),
                    followStartupLogs=False,
                    masterFQDN='buildbot.mariadb.org',
                    hostconfig={ 'shm_size':'6G' },
                    max_builds=1,
                    volumes=['/opt/mariadb-buildbot/ccache:/mnt/ccache', '/opt/mariadb-buildbot/packages:/mnt/packages'],
                    properties={ 'jobs':7, 'save_packages':False }))

## Add Power workers
for w_name in ['p9-rhel8-bbw', 'p9-rhel7-bbw', 'p9-db-bbw']:
    jobs = 12
    addWorker(w_name, 1, '-centos-7', 'quay.io/mariadb-foundation/bb-worker:centos7', jobs=jobs, save_packages=True, shm_size='20G')
    addWorker(w_name, 1, '-ubuntu-1804', 'quay.io/mariadb-foundation/bb-worker:ubuntu18.04', jobs=jobs, save_packages=True, shm_size='20G')
    addWorker(w_name, 1, '-ubuntu-2004', 'quay.io/mariadb-foundation/bb-worker:ubuntu20.04', jobs=jobs, save_packages=True, shm_size='20G')
    addWorker(w_name, 1, '-ubuntu-2110', 'quay.io/mariadb-foundation/bb-worker:ubuntu21.10', jobs=jobs, save_packages=True, shm_size='20G')
    # Disable other workers for Ubuntu 22.04 ppc until MDBF-357 is fixed
    if w_name == 'p9-rhel8-bbw':
        addWorker(w_name, 1, '-ubuntu-2204', 'quay.io/mariadb-foundation/bb-worker:ubuntu22.04', jobs=jobs, save_packages=True, shm_size='20G')
        addWorker(w_name, 1, '-debian-sid', 'quay.io/mariadb-foundation/bb-worker:debiansid', jobs=jobs, save_packages=True, shm_size='20G')
    addWorker(w_name, 1, '-debian-9', 'ppc-debian-9-download.dockerfile', jobs=jobs, save_packages=True, shm_size='20G')
    addWorker(w_name, 1, '-debian-10', 'quay.io/mariadb-foundation/bb-worker:debian10', jobs=jobs, save_packages=True, shm_size='20G')
    addWorker(w_name, 1, '-debian-11', 'quay.io/mariadb-foundation/bb-worker:debian11', jobs=jobs, save_packages=True, shm_size='20G')
    addWorker(w_name, 1, '-clang-ubuntu-2004', 'vladbogo/bb:ppc64le-ubuntu-2004-clang1x',jobs=jobs, save_packages=True, shm_size='20G')
    addWorker(w_name, 1, '-rhel-7', 'quay.io/mariadb-foundation/bb-worker:rhel7', jobs=jobs, save_packages=True, shm_size='20G')
    addWorker(w_name, 1, '-rhel-8', 'quay.io/mariadb-foundation/bb-worker:rhel8', jobs=jobs, save_packages=True, shm_size='20G')

## bg-bbw-docker
for i in range(1,5):
    if i == 1:
        jobs = 5
    else:
        jobs = 3

    addWorker('bg-bbw', i, '-clang-ubuntu-1804', "clang-ubuntu-1804.dockerfile", jobs=jobs, save_packages=True)
    addWorker('bg-bbw', i, '-msan-clang-ubuntu-2004', "vladbogo/bb:msan-ubuntu-2004-clang-12", jobs=jobs, save_packages=False)
    addWorker('bg-bbw', i, '-valgrind-ubuntu-1804', "valgrind-ubuntu-1804.dockerfile", jobs=jobs, save_packages=False)
    addWorker('bg-bbw', i, '-fedora-34', 'quay.io/mariadb-foundation/bb-worker:fedora34', jobs=jobs, save_packages=True)
    addWorker('bg-bbw', i, '-fedora-35', "quay.io/mariadb-foundation/bb-worker:fedora35", jobs=jobs, save_packages=True)
    addWorker('bg-bbw', i, '-opensuse-15', "opensuse-15.dockerfile", jobs=jobs, save_packages=True)
    addWorker('bg-bbw', i, '-centos-stream8', "quay.io/mariadb-foundation/bb-worker:centos-stream8", jobs=jobs, save_packages=True)
    addWorker('bg-bbw', i, '-x86-ubuntu-1804', "ubuntu-1804-i386.dockerfile", jobs=jobs, save_packages=False)
    addWorker('bg-bbw', i, '-ubuntu-2004', 'quay.io/mariadb-foundation/bb-worker:ubuntu20.04', jobs=jobs, save_packages=True)
    addWorker('bg-bbw', i, '-debian-10', 'quay.io/mariadb-foundation/bb-worker:debian10', jobs=jobs, save_packages=True)
    addWorker('bg-bbw', i, '-rhel-8', 'quay.io/mariadb-foundation/bb-worker:rhel8', jobs=jobs, save_packages=True)
    addWorker('bg-bbw', i, '-centos-7', 'quay.io/mariadb-foundation/bb-worker:centos7', jobs=jobs, save_packages=True)
    addWorker('bg-bbw', i, '-sles-12', 'sles-12-download.dockerfile', jobs=jobs, save_packages=True)
    addWorker('bg-bbw', i, '-sles-15', 'sles-15-download.dockerfile', jobs=jobs, save_packages=True)

# aarch64-bbw-docker
for i in range(1, 6):
    jobs = 4
    if i == 5:
        jobs = 25
    if i == 4:
        jobs = 8

    if i == 5:
        addWorker('aarch64-bbw', i, '-debian-9', "quay.io/mariadb-foundation/bb-worker:debian9", jobs=jobs, save_packages=True)
        addWorker('aarch64-bbw', i, '-debian-11', "quay.io/mariadb-foundation/bb-worker:debian11", jobs=jobs, save_packages=True)
        addWorker('aarch64-bbw', i, '-debian-sid', "quay.io/mariadb-foundation/bb-worker:debiansid", jobs=jobs, save_packages=True)
        addWorker('aarch64-bbw', i, '-rhel-8', "quay.io/mariadb-foundation/bb-worker:rhel8", jobs=jobs, save_packages=True)
        addWorker('aarch64-bbw', i, '-fedora-34', "quay.io/mariadb-foundation/bb-worker:fedora34", jobs=jobs, save_packages=True)
        addWorker('aarch64-bbw', i, '-fedora-35', "quay.io/mariadb-foundation/bb-worker:fedora35", jobs=jobs, save_packages=True)
        addWorker('aarch64-bbw', i, '-ubuntu-2004', "quay.io/mariadb-foundation/bb-worker:ubuntu20.04", jobs=jobs, save_packages=True)
        addWorker('aarch64-bbw', i, '-ubuntu-2110', "quay.io/mariadb-foundation/bb-worker:ubuntu21.10", jobs=jobs, save_packages=True)
        addWorker('aarch64-bbw', i, '-ubuntu-2204', "quay.io/mariadb-foundation/bb-worker:ubuntu22.04", jobs=jobs, save_packages=True)

    if i == 4 or i == 5:
        addWorker('aarch64-bbw', i, '-debian-10', "quay.io/mariadb-foundation/bb-worker:debian10", jobs=jobs, save_packages=True)
    else:
        addWorker('aarch64-bbw', i, '-debian-9', "quay.io/mariadb-foundation/bb-worker:debian9", jobs=jobs, save_packages=True)
        addWorker('aarch64-bbw', i, '-debian-10', "quay.io/mariadb-foundation/bb-worker:debian10", jobs=jobs, save_packages=True)
        addWorker('aarch64-bbw', i, '-ubuntu-1804', "quay.io/mariadb-foundation/bb-worker:ubuntu18.04", jobs=jobs, save_packages=True)

    if i == 2 or i == 5:
        addWorker('aarch64-bbw', i, '-centos-7', "quay.io/mariadb-foundation/bb-worker:centos7", jobs=jobs, save_packages=True)
        addWorker('aarch64-bbw', i, '-rhel-7', "vladbogo/bb:aarch64-rhel-7", jobs=jobs, save_packages=True)
        addWorker('aarch64-bbw', i, '-centos-stream8', "quay.io/mariadb-foundation/bb-worker:centos-stream8", jobs=8, save_packages=True)

# add s390x workers
for i in [1,2,3]:
    addWorker('s390x-bbw', i, '-ubuntu-2004', "quay.io/mariadb-foundation/bb-worker:ubuntu20.04", jobs=8, save_packages=True)
    addWorker('s390x-bbw', i, '-ubuntu-2204', "quay.io/mariadb-foundation/bb-worker:ubuntu22.04", jobs=8, save_packages=True)
    addWorker('s390x-bbw', i, '-rhel-8', "vladbogo/bb:s390x-rhel-8", jobs=8, save_packages=True)
    addWorker('s390x-bbw', i, '-sles-15', "vladbogo/bb:s390x-sles-15", jobs=8, save_packages=True)

## bm-bbw1-docker
c['workers'].append(worker.DockerLatentWorker("bm-bbw1-docker-ubuntu-1804", None,
                    docker_host=config["private"]["docker_workers"]["bm-bbw1-docker"],
                    image="quay.io/mariadb-foundation/bb-worker:ubuntu18.04",
                    followStartupLogs=False,
                    autopull=True,
                    alwaysPull=True,
                    masterFQDN='buildbot.mariadb.org',
                    hostconfig={ 'shm_size':'20G' },
                    max_builds=1,
                    volumes=['/srv/buildbot/ccache:/mnt/ccache', '/mnt/autofs/master_packages:/packages'],
                    properties={ 'jobs': 2, 'save_packages':False }))

# The 'builders' list defines the Builders, which tell Buildbot how to perform a build:
# what steps, and which workers can execute them.  Note that any particular build will
# only take place on one worker.

def downloadSourceTarball():
    return ShellCommand(
             name="fetch_tarball",
             description="fetching source tarball",
             descriptionDone="fetching source tarball...done",
             haltOnFailure=True,
             command=["bash", "-xc", util.Interpolate("""
  d=/mnt/packages/
  f="%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz"
  find $d -type f -mtime +2 -delete -ls
  for i in `seq 1 10`;
  do
    if flock "$d$f" wget -cO "$d$f" "https://ci.mariadb.org/%(prop:tarbuildnum)s/%(prop:mariadb_version)s.tar.gz"; then
        break
    else
        sleep $i
    fi
  done
""")])


def dpkgDeb():
    return ShellCommand(
            name="dpkg-scanpackages/sources",
            haltOnFailure=True,
            command=["sh", "-xc", util.Interpolate("""
    mkdir -p debs/
    find .. -maxdepth 1 -type f -exec cp {} debs/ \;
    cd debs
    ( dpkg-scanpackages . /dev/null && dpkg-scanpackages --type ddeb . /dev/null  )| gzip -9c > Packages.gz
    dpkg-scansources . /dev/null | gzip -9c > Sources.gz
    cd ..
    find debs -type f -exec sha256sum {} \; | sort > sha256sums.txt
""")], doStepIf=lambda step: hasFiles(step) and savePackage(step))

####### FACTORY CODE

f_quick_build = getQuickBuildFactory(mtrDbPool)
f_rpm_autobake = getRpmAutobakeFactory(mtrDbPool)

## f_tarball - create source tarball
f_tarball = util.BuildFactory()
f_tarball.addStep(steps.SetProperty(property="dockerfile", value=util.Interpolate("%(kw:url)s", url=dockerfile), description="dockerfile"))
f_tarball.addStep(steps.ShellCommand(command=["echo", " revision: ", util.Property('revision')]))
f_tarball.addStep(steps.GitHub(
  repourl=util.Property('repository'),
  mode='full',
  method='clobber',
  workdir='build/server',
  shallow=True,
  submodules=True
))
f_tarball.addStep(steps.Compile(command=["cmake","../server"], workdir='build/mkdist', description="cmake"))
f_tarball.addStep(steps.Compile(command=["make", "dist"], workdir='build/mkdist', description="make dist"))
f_tarball.addStep(steps.SetPropertyFromCommand(property="mariadb_version", command="basename mariadb-*.tar.gz .tar.gz", workdir="build/mkdist"))
f_tarball.addStep(steps.SetPropertyFromCommand(property="master_branch", command=util.Interpolate("echo " + "%(prop:mariadb_version)s" + " | cut -d'-' -f 2 | cut -d'.' -f 1,2")))
f_tarball.addStep(steps.ShellCommand(command=util.Interpolate("mkdir -p %(prop:buildnumber)s/logs"), workdir="build/mkdist"))
f_tarball.addStep(steps.ShellCommand(command=util.Interpolate("sha256sum %(prop:mariadb_version)s" + ".tar.gz >> " + " %(prop:buildnumber)s" + "/sha256sums.txt" + " && mv %(prop:mariadb_version)s" +".tar.gz" + " %(prop:buildnumber)s"), workdir="build/mkdist"))
f_tarball.addStep(steps.SetPropertyFromCommand(command="ls -1 *.tar.gz", extract_fn=ls2list, workdir=util.Interpolate("build/mkdist/" + "%(prop:buildnumber)s")))
#f_tarball.addStep(steps.DirectoryUpload(workersrc=util.Interpolate('%(prop:builddir)s' + '/build/mkdist/' + '%(prop:buildnumber)s'),
#    masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:buildnumber)s'), url=util.Interpolate('https://ci.mariadb.org/' + "%(prop:buildnumber)s"), urlText="Download", doStepIf=hasFiles))
f_tarball.addStep(steps.ShellCommand(name='save_packages', haltOnFailure=True, command=util.Interpolate('cp -r ' + '%(prop:builddir)s' + '/build/mkdist/' + '%(prop:buildnumber)s' + ' /packages && sync /packages/' + '%(prop:buildnumber)s')))
f_tarball.addStep(steps.Trigger(schedulerNames=['s_protected_branches'], waitForFinish=False, updateSourceStamp=False, doStepIf=waitIfStaging,
    set_properties={"tarbuildnum" : Property("buildnumber"), "mariadb_version" : Property("mariadb_version"), "master_branch" : Property("master_branch")}))
f_tarball.addStep(steps.Trigger(schedulerNames=['s_upstream_all'], waitForFinish=False, updateSourceStamp=False,
    set_properties={"tarbuildnum" : Property("buildnumber"), "mariadb_version" : Property("mariadb_version"), "master_branch" : Property("master_branch")}))
f_tarball.addStep(steps.SetPropertyFromCommand(command=util.Interpolate("echo " + "prot-" + "%(prop:master_branch)s"), property="master_staging_branch"))
f_tarball.addStep(steps.ShellSequence( commands=[
    util.ShellArg(command="git config --global user.email '" + config["private"]["gh_mdbci"]["email"] + "'"),
    util.ShellArg(command="git config --global user.name '" + config["private"]["gh_mdbci"]["name"] + "'"),
    util.ShellArg(command="git remote set-url origin https://" + config["private"]["gh_mdbci"]["push_access_token"] + ":x-oauth-basic@github.com/cvicentiu/server"),
    util.ShellArg(command=util.Interpolate("git fetch origin %(prop:master_staging_branch)s && git branch %(prop:master_staging_branch)s FETCH_HEAD && git checkout %(prop:master_staging_branch)s && git checkout %(prop:branch)s && git pull --unshallow"), logfile="rebase"),
    util.ShellArg(command=["bash", "-xc", util.Interpolate("if git checkout %(prop:master_staging_branch)s && git merge --ff-only %(prop:branch)s; then git push --set-upstream origin %(prop:master_staging_branch)s; else  if git checkout %(prop:branch)s && [[ $(git --no-pager log --merges %(prop:master_staging_branch)s..%(prop:branch)s | wc -l) -ne 0 ]]; then exit 1; else git rebase %(prop:master_staging_branch)s && git push --force; fi fi")], logfile="rebase")],
    workdir="build/server", haltOnFailure="true", doStepIf=lambda step: isStagingBranch(step)))
#f_tarball.addStep(steps.ShellSequence( commands=[
#    util.ShellArg(command=util.Interpolate("git checkout " + "%(prop:staging_branch)s"), logfile="rebase"),
#    util.ShellArg(command=util.Interpolate("git merge %(prop:branch)s"), logfile="rebase")], workdir="build/server", haltOnFailure="true", doStepIf=ifStagingSucceeding))
f_tarball.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_32b_quick_build
f_32b_quick_build = util.BuildFactory()
f_32b_quick_build.addStep(steps.SetProperty(property="dockerfile", value=util.Interpolate("%(kw:url)s", url=dockerfile), description="dockerfile"))
f_32b_quick_build.addStep(downloadSourceTarball())
f_32b_quick_build.addStep(steps.ShellCommand(command=util.Interpolate("tar -xvzf /mnt/packages/%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz --strip-components=1")))
f_32b_quick_build.addStep(steps.ShellCommand(name="create html log file", command=['bash', '-c', util.Interpolate(getHTMLLogString(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
# build steps
f_32b_quick_build.addStep(steps.Compile(command=
    ["sh", "-c", util.Interpolate("export PATH=/usr/lib/ccache:/usr/lib64/ccache:$PATH && cmake . -DCMAKE_SYSTEM_LIBRARY_PATH=/usr/lib/i386-linux-gnu/ -DCMAKE_LIBRARY_PATH=/usr/lib/i386-linux-gnu/ -DCMAKE_FIND_ROOT_PATH=/usr/lib/i386-linux-gnu -DCMAKE_LIBRARY_ARCHITECTURE=i386 -DCMAKE_BUILD_TYPE=RelWithDebInfo -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_C_COMPILER=gcc -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER=g++ -DWITH_EMBEDDED_SERVER=OFF -DWITH_SAFEMALLOC=OFF -DWITH_WSREP=OFF -DPLUGIN_ARCHIVE=NO -DPLUGIN_TOKUDB=NO -DPLUGIN_MROONGA=NO -DPLUGIN_SPIDER=NO -DPLUGIN_OQGRAPH=NO -DPLUGIN_CONNECT=NO -DPLUGIN_SPHINX=NO -DWITH_SSL=bundled -DWITH_ZLIB=system -DCMAKE_C_FLAGS=-m32 -DCMAKE_CXX_FLAGS=-m32 && make -j%(kw:jobs)s package", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)') )], env={'CCACHE_DIR':'/mnt/ccache'}, haltOnFailure="true"))

f_32b_quick_build.addStep(steps.MTR(logfiles={"mysqld*": "/buildbot/mysql_logs.html"}, command=
    ["sh", "-c", util.Interpolate("cd mysql-test && exec perl mysql-test-run.pl --verbose-restart --force --retry=3 --max-save-core=1 --max-save-datadir=1 --max-test-fail=20 --mem --parallel=$(expr %(kw:jobs)s \* 2)", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=7200, haltOnFailure="true", parallel=mtrJobsMultiplier, dbpool=mtrDbPool, autoCreateTables=True))
f_32b_quick_build.addStep(steps.ShellCommand(name="move mysqld log files", alwaysRun=True, command=['bash', '-c', util.Interpolate(moveMTRLogs(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
f_32b_quick_build.addStep(steps.DirectoryUpload(name="save mysqld log files", compress="bz2", alwaysRun=True,  workersrc='/buildbot/logs/', masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + '/logs/' + '%(prop:buildername)s' )))
# create package and upload to master
f_32b_quick_build.addStep(steps.SetPropertyFromCommand(command="basename mariadb-*-linux-*.tar.gz", property="mariadb_binary"))
#f_32b_quick_build.addStep(steps.ShellCommand(name='save_packages', timeout=7200, haltOnFailure=True, command=util.Interpolate('mkdir -p ' + '/packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s'+ ' && sha256sum %(prop:mariadb_binary)s >> sha256sums.txt  && cp ' + '%(prop:mariadb_binary)s sha256sums.txt' + ' /packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s' + '/' +  ' && sync /packages/' + '%(prop:tarbuildnum)s'), doStepIf=savePackage))
f_32b_quick_build.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_asan_build
f_asan_build = util.BuildFactory()
f_asan_build.addStep(steps.SetProperty(property="dockerfile", value=util.Interpolate("%(kw:url)s", url=dockerfile), description="dockerfile"))
f_asan_build.addStep(downloadSourceTarball())
f_asan_build.addStep(steps.ShellCommand(command=util.Interpolate("tar -xvzf /mnt/packages/%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz --strip-components=1")))
f_asan_build.addStep(steps.ShellCommand(name="create html log file", command=['bash', '-c', util.Interpolate(getHTMLLogString(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
# build steps
f_asan_build.addStep(steps.ShellCommand(command='echo "leak:libtasn1\nleak:libgnutls\nleak:libgmp" > mysql-test/lsan.supp', doStepIf=filterBranch))
f_asan_build.addStep(steps.ShellCommand(command='cat mysql-test/lsan.supp', doStepIf=filterBranch))
f_asan_build.addStep(steps.Compile(command=
    ["sh", "-c", util.Interpolate('cmake . -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DCMAKE_C_COMPILER=clang-10 -DCMAKE_CXX_COMPILER=clang++ -DCMAKE_C_FLAGS="-O2 -msse4.2 -Wno-unused-command-line-argument -fdebug-macro -Wno-inconsistent-missing-override" -DCMAKE_CXX_FLAGS="-O2 -msse4.2 -Wno-unused-command-line-argument -fdebug-macro -Wno-inconsistent-missing-override" -DCMAKE_EXPORT_COMPILE_COMMANDS=ON -DCMAKE_BUILD_TYPE=Debug -DWITH_ASAN=YES -DPLUGIN_TOKUDB=NO -DPLUGIN_MROONGA=NO -DPLUGIN_OQGRAPH=NO -DPLUGIN_ROCKSDB=NO -DPLUGIN_CONNECT=NO -DWITH_SAFEMALLOC=OFF -DWITH_ZLIB=bundled -DWITH_SSL=bundled -DWITH_PCRE=system && make -j%(kw:jobs)s package', jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], haltOnFailure="true"))
f_asan_build.addStep(steps.MTR(logfiles={"mysqld*": "/buildbot/mysql_logs.html"}, command=
    ["sh", "-c", util.Interpolate('cd mysql-test && MTR_FEEDBACK_PLUGIN=1 ASAN_OPTIONS="abort_on_error=1" LSAN_OPTIONS="print_suppressions=0,suppressions=`pwd`/lsan.supp" perl mysql-test-run.pl --verbose-restart --force --retry=3 --max-save-core=1 --max-save-datadir=1 --max-test-fail=20 --mem --parallel=$(expr %(kw:jobs)s \* 2)', jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=7200, haltOnFailure="true", parallel=mtrJobsMultiplier, dbpool=mtrDbPool, autoCreateTables=True))
f_asan_build.addStep(steps.ShellCommand(name="move mysqld log files", alwaysRun=True, command=['bash', '-c', util.Interpolate(moveMTRLogs(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
f_asan_build.addStep(steps.DirectoryUpload(name="save mysqld log files", compress="bz2", alwaysRun=True,  workersrc='/buildbot/logs/', masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + '/logs/' + '%(prop:buildername)s' )))
f_asan_build.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_msan_build
f_msan_build = util.BuildFactory()
f_msan_build.addStep(steps.SetProperty(property="dockerfile", value=util.Interpolate("%(kw:url)s", url=dockerfile), description="dockerfile"))
f_msan_build.addStep(steps.ShellCommand(name="create html log file", command=['bash', '-c', util.Interpolate(getHTMLLogString(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
f_msan_build.addStep(downloadSourceTarball())
f_msan_build.addStep(steps.ShellCommand(command=util.Interpolate("tar -xvzf /mnt/packages/%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz --strip-components=1")))
# build steps
f_msan_build.addStep(steps.ShellCommand(command='ls /msan-libs'))
f_msan_build.addStep(steps.Compile(command=
    ["bash", "-xc", util.Interpolate('cmake . -DCMAKE_{C_COMPILER=clang,CXX_COMPILER=clang++}-12 -DCMAKE_C_FLAGS="-O2 -Wno-unused-command-line-argument -fdebug-macro" -DCMAKE_CXX_FLAGS="-stdlib=libc++ -O2 -Wno-unused-command-line-argument -fdebug-macro" -DWITH_EMBEDDED_SERVER=OFF -DWITH_UNIT_TESTS=OFF -DCMAKE_BUILD_TYPE=Debug -DWITH_INNODB_{BZIP2,LZ4,LZMA,LZO,SNAPPY}=OFF -DPLUGIN_{ARCHIVE,TOKUDB,MROONGA,OQGRAPH,ROCKSDB,CONNECT,SPIDER}=NO -DWITH_SAFEMALLOC=OFF -DWITH_{ZLIB,SSL,PCRE}=bundled -DHAVE_LIBAIO_H=0 -DCMAKE_DISABLE_FIND_PACKAGE_{URING,LIBAIO}=1 -DWITH_MSAN=ON && make -j%(kw:jobs)s package', jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], haltOnFailure="true"))
f_msan_build.addStep(steps.MTR(logfiles={"mysqld*": "/buildbot/mysql_logs.html"}, command=
    ["bash", "-xc", util.Interpolate('cd mysql-test && LD_LIBRARY_PATH=/msan-libs MSAN_OPTIONS=abort_on_error=1 ./mtr --mem --big-test --force --retry=0 --skip-test=.*compression.* --max-test-fail=100 --parallel=$(expr %(kw:jobs)s \* 2)', jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=7200, haltOnFailure="true", parallel=mtrJobsMultiplier, dbpool=mtrDbPool, autoCreateTables=True))
f_msan_build.addStep(steps.ShellCommand(name="move mysqld log files", alwaysRun=True, command=['bash', '-c', util.Interpolate(moveMTRLogs(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
f_msan_build.addStep(steps.DirectoryUpload(name="save mysqld log files", compress="bz2", alwaysRun=True,  workersrc='/buildbot/logs/', masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + '/logs/' + '%(prop:buildername)s' )))
f_msan_build.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_valgrind_build
f_valgrind_build = util.BuildFactory()
f_valgrind_build.addStep(steps.SetProperty(property="dockerfile", value=util.Interpolate("%(kw:url)s", url=dockerfile), description="dockerfile"))
f_valgrind_build.addStep(steps.ShellCommand(name="create html log file", command=['bash', '-c', util.Interpolate(getHTMLLogString(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
f_valgrind_build.addStep(downloadSourceTarball())
f_valgrind_build.addStep(steps.ShellCommand(command=util.Interpolate("tar -xvzf /mnt/packages/%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz --strip-components=1")))
# build steps
f_valgrind_build.addStep(steps.Compile(command=
    ["sh", "-c", util.Interpolate('cmake . -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DENABLE_ASSEMBLER=1 -DWITH_EXTRA_CHARSETS=complex -DENABLE_THREAD_SAFE_CLIENT=1 -DWITH_BIG_TABLES=1 -DWITH_PLUGIN_ARIA=1 -DWITH_ARIA_TMP_TABLES=1 -DWITH_JEMALLOC=NO=1 -DCMAKE_BUILD_TYPE=Debug -DSECURITY_HARDENED=OFF -DWITH_VALGRIND=1 -DWITH_SSL=bundled -DWITH_MAX=AUTO -DWITH_EMBEDDED_SERVER=1 -DWITH_LIBEVENT=bundled -DPLUGIN_PLUGIN_FILE_KEY_MANAGEMENT=NO -DPLUGIN_ROCKSDB=DYNAMIC -DPLUGIN_TEST_SQL_DISCOVERY=DYNAMIC -DPLUGIN_TOKUDB=NO -DPLUGIN_ROCKSDB=NO -DENABLE_LOCAL_INFILE=1 && make -j%(kw:jobs)s package', jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], haltOnFailure="true"))
f_valgrind_build.addStep(steps.MTR(logfiles={"mysqld*": "/buildbot/mysql_logs.html"}, command=
    ["sh", "-c", util.Interpolate('cd mysql-test && perl mysql-test-run.pl --valgrind="--leak-check=summary --gen-suppressions=yes --num-callers=10" --skip-test=encryption*  --force --retry=0 --max-save-core=1 --max-save-datadir=1 --max-test-fail=20 --parallel=$(expr %(kw:jobs)s \* 2)', jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=7200, haltOnFailure="true", parallel=mtrJobsMultiplier, dbpool=mtrDbPool, autoCreateTables=True))
f_valgrind_build.addStep(steps.ShellCommand(name="move mysqld log files", alwaysRun=True, command=['bash', '-c', util.Interpolate(moveMTRLogs(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
f_valgrind_build.addStep(steps.DirectoryUpload(name="save mysqld log files", compress="bz2", alwaysRun=True,  workersrc='/buildbot/logs/', masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + '/logs/' + '%(prop:buildername)s' )))
f_valgrind_build.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_big_test
f_big_test = util.BuildFactory()
f_big_test.addStep(steps.SetProperty(property="dockerfile", value=util.Interpolate("%(kw:url)s", url=dockerfile), description="dockerfile"))
f_big_test.addStep(steps.ShellCommand(name="create html log file", command=['bash', '-c', util.Interpolate(getHTMLLogString(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
# get the source tarball and extract it
f_big_test.addStep(steps.FileDownload(mastersrc=util.Interpolate("/srv/buildbot/packages/" + "%(prop:tarbuildnum)s" + "/" + "%(prop:mariadb_version)s" + ".tar.gz"),
    workerdest=util.Interpolate("%(prop:mariadb_version)s" + ".tar.gz")))
f_big_test.addStep(steps.ShellCommand(command=util.Interpolate("tar -xvzf " + "%(prop:mariadb_version)s" + ".tar.gz --strip-components=1")))
# build steps
f_big_test.addStep(steps.Compile(command=
    ["sh", "-c", util.Interpolate("export PATH=/usr/lib/ccache:/usr/lib64/ccache:$PATH && cmake . -DCMAKE_BUILD_TYPE=RelWithDebInfo  -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DPLUGIN_ROCKSDB=NO -DPLUGIN_TOKUDB=NO -DPLUGIN_MROONGA=NO -DPLUGIN_SPIDER=NO -DPLUGIN_OQGRAPH=NO -DPLUGIN_SPHINX=NO && make -j%(kw:jobs)s VERBOSE=1 package", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], env={'CCACHE_DIR':'/mnt/ccache'}))
f_big_test.addStep(steps.MTR(logfiles={"mysqld*": "/buildbot/mysql_logs.html"}, command=
    ["sh", "-c", util.Interpolate("cd mysql-test && exec perl mysql-test-run.pl --verbose-restart --force --retry=3 --max-save-core=1 --max-save-datadir=1 --max-test-fail=20 --big --big --mem --parallel=$(expr %(kw:jobs)s \* 2) --skip-test=archive.archive-big", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=10800, dbpool=mtrDbPool, parallel=mtrJobsMultiplier))
f_big_test.addStep(steps.ShellCommand(name="move mysqld log files", alwaysRun=True, command=['bash', '-c', util.Interpolate(moveMTRLogs(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
f_big_test.addStep(steps.DirectoryUpload(name="save mysqld log files", compress="bz2", alwaysRun=True,  workersrc='/buildbot/logs/', masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + '/logs/' + '%(prop:buildername)s' )))
# create package and upload to master
f_big_test.addStep(steps.SetPropertyFromCommand(command="basename mariadb-*-linux-*.tar.gz", property="mariadb_binary"))
#f_big_test.addStep(steps.ShellCommand(name='save_packages', timeout=7200, haltOnFailure=True, command=util.Interpolate('mkdir -p ' + '/packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s'+ ' && sha256sum %(prop:mariadb_binary)s >> sha256sums.txt  && cp ' + '%(prop:mariadb_binary)s sha256sums.txt' + ' /packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s' + '/' +  ' && sync /packages/' + '%(prop:tarbuildnum)s'), doStepIf=savePackage))
f_big_test.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_full_test
f_full_test = util.BuildFactory()
f_full_test.addStep(steps.SetProperty(property="dockerfile", value=util.Interpolate("%(kw:url)s", url=dockerfile), description="dockerfile"))
# get the source tarball and extract it
f_full_test.addStep(steps.FileDownload(mastersrc=util.Interpolate("/srv/buildbot/packages/" + "%(prop:tarbuildnum)s" + "/" + "%(prop:mariadb_version)s" + ".tar.gz"),
    workerdest=util.Interpolate("%(prop:mariadb_version)s" + ".tar.gz")))
f_full_test.addStep(steps.ShellCommand(command=util.Interpolate("tar -xvzf " + "%(prop:mariadb_version)s" + ".tar.gz --strip-components=1")))
# build steps
f_full_test.addStep(steps.Compile(command=
    ["sh", "-c", util.Interpolate("export PATH=/usr/lib/ccache:/usr/lib64/ccache:$PATH && cmake . -DBUILD_CONFIG=mysql_release -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DWITH_SSL=system -DWITH_JEMALLOC=auto -DWITH_EMBEDDED_SERVER=1 -DHAVE_EMBEDDED_PRIVILEGE_CONTROL=1 -DWITH_LIBARCHIVE=ON -Wno-dev && make -j%(kw:jobs)s VERBOSE=1 package", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], env={'CCACHE_DIR':'/mnt/ccache'}))
f_full_test.addStep(steps.MTR(addLogs=True, name="test emb", command=
    ["sh", "-c", util.Interpolate("cd mysql-test && MTR_FEEDBACK_PLUGIN=1 perl mysql-test-run.pl  --verbose-restart --force --retry=3 --max-save-core=0 --max-save-datadir=1 --mem --embedded-server --parallel=$(expr %(kw:jobs)s \* 2)", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=10800, dbpool=mtrDbPool, parallel=mtrJobsMultiplier))
f_full_test.addStep(steps.MTR(addLogs=True, name="test n", command=
    ["sh", "-c", util.Interpolate("cd mysql-test && MTR_FEEDBACK_PLUGIN=1 perl mysql-test-run.pl  --verbose-restart --force --retry=3 --max-save-core=0 --max-save-datadir=1 --mem --parallel=$(expr %(kw:jobs)s \* 2)", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=10800, dbpool=mtrDbPool, parallel=mtrJobsMultiplier))
f_full_test.addStep(steps.MTR(addLogs=True, name="test p", command=
    ["sh", "-c", util.Interpolate("cd mysql-test && MTR_FEEDBACK_PLUGIN=1 perl mysql-test-run.pl  --verbose-restart --force --retry=3 --max-save-core=0 --max-save-datadir=1 --mem --ps-protocol --parallel=$(expr %(kw:jobs)s \* 2)", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=10800, dbpool=mtrDbPool, parallel=mtrJobsMultiplier))
f_full_test.addStep(steps.MTR(addLogs=True, name="test ps-embedded", command=
    ["sh", "-c", util.Interpolate("cd mysql-test && MTR_FEEDBACK_PLUGIN=1 perl mysql-test-run.pl  --verbose-restart --force --retry=3 --max-save-core=0 --max-save-datadir=1 --ps --embedded --mem --parallel=$(expr %(kw:jobs)s \* 2)", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=10800, dbpool=mtrDbPool, parallel=mtrJobsMultiplier))
f_full_test.addStep(steps.MTR(addLogs=True, name="test xtra", command=
    ["sh", "-c", util.Interpolate("cd mysql-test && MTR_FEEDBACK_PLUGIN=1 perl mysql-test-run.pl  --verbose-restart --force --retry=3 --max-save-core=0 --max-save-datadir=1 --mem --suite=funcs_1,funcs_2,stress,jp --big --testcase-timeout=120 --mysqld=--open-files-limit=0 --mysqld=--log-warnings=1 --parallel=$(expr %(kw:jobs)s \* 2)", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=10800, dbpool=mtrDbPool, parallel=mtrJobsMultiplier))
f_full_test.addStep(steps.MTR(addLogs=True, name="test engines", command=
    ["sh", "-c", util.Interpolate("cd mysql-test && MTR_FEEDBACK_PLUGIN=1 perl mysql-test-run.pl  --verbose-restart --force --retry=3 --max-save-core=0 --max-save-datadir=1 --mem --suite=spider,spider/bg,engines/funcs,engines/iuds --big --testcase-timeout=120 --mysqld=--open-files-limit=0 --mysqld=--log-warnings=1 --parallel=$(expr %(kw:jobs)s \* 2)", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=10800, dbpool=mtrDbPool, parallel=mtrJobsMultiplier))
f_full_test.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_deb_autobake
f_deb_autobake = util.BuildFactory()
f_deb_autobake.addStep(steps.SetProperty(property="dockerfile", value=util.Interpolate("%(kw:url)s", url=dockerfile), description="dockerfile"))
f_deb_autobake.addStep(downloadSourceTarball())
f_deb_autobake.addStep(steps.ShellCommand(command=util.Interpolate("tar -xvzf /mnt/packages/%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz --strip-components=1")))
# build steps
f_deb_autobake.addStep(steps.Compile(logfiles={'CMakeCache.txt': './builddir/CMakeCache.txt'}, command=["debian/autobake-deb.sh"],
    env={'CCACHE_DIR':'/mnt/ccache', 'DEB_BUILD_OPTIONS':util.Interpolate('parallel=%(kw:jobs)s', jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))}, description="autobake-deb.sh"))
# upload binaries
f_deb_autobake.addStep(steps.SetPropertyFromCommand(command="find .. -maxdepth 1 -type f", extract_fn=ls2string))
#f_deb_autobake.addStep(steps.MultipleFileUpload(workersrcs=util.Property('packages'),
#    masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s'), mode=0o755, url=util.Interpolate('https://ci.mariadb.org/' + "%(prop:tarbuildnum)s" + "/" + '%(prop:buildername)s' + "/"), doStepIf=lambda step: hasFiles(step) and savePackage(step)))
#f_deb_autobake.addStep(steps.ShellCommand(name='save_packages', haltOnFailure=True, command=util.Interpolate('mkdir -p ' + '/packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s'+ ' && cp ' + '%(prop:packages)s' + ' /packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s' + '/' +  ' && sync /packages/' + '%(prop:tarbuildnum)s'), doStepIf=lambda step: hasFiles(step) and savePackage(step)))
f_deb_autobake.addStep(dpkgDeb())
#f_deb_autobake.addStep(steps.MultipleFileUpload(workersrcs=['debs/Packages.gz', 'debs/Sources.gz'],
#    masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s'), mode=0o755, url=util.Interpolate('https://ci.mariadb.org/' + "%(prop:tarbuildnum)s" + "/" + '%(prop:buildername)s' + "/"), doStepIf=lambda step: hasFiles(step) and savePackage(step)))
f_deb_autobake.addStep(steps.ShellCommand(name='save_packages', timeout=7200, haltOnFailure=True, command=util.Interpolate('mkdir -p ' + '/packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s'+ ' && cp -r debs/ sha256sums.txt /packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s' + '/' +  ' && sync /packages/' + '%(prop:tarbuildnum)s'), doStepIf=lambda step: hasFiles(step) and savePackage(step)))
f_deb_autobake.addStep(steps.Trigger(name='dockerlibrary', schedulerNames=['s_dockerlibrary'], waitForFinish=False, updateSourceStamp=False,
    set_properties={"tarbuildnum" : Property("tarbuildnum"), "mariadb_version" : Property("mariadb_version"), "master_branch" : Property("master_branch"), "parentbuildername": Property("buildername")}, doStepIf=lambda step: hasDockerLibrary(step)))
f_deb_autobake.addStep(steps.Trigger(name='install', schedulerNames=['s_install'], waitForFinish=True, updateSourceStamp=False,
    set_properties={"tarbuildnum" : Property("tarbuildnum"), "mariadb_version" : Property("mariadb_version"), "master_branch" : Property("master_branch"), "parentbuildername": Property("buildername"), "sst_mode": "off"}, doStepIf=lambda step: hasInstall(step) and savePackage(step) and hasFiles(step)))
f_deb_autobake.addStep(steps.Trigger(name='galera-sst-mariabackup', schedulerNames=['s_install'], waitForFinish=True, updateSourceStamp=False,
    set_properties={"tarbuildnum" : Property("tarbuildnum"), "mariadb_version" : Property("mariadb_version"), "master_branch" : Property("master_branch"), "parentbuildername": Property("buildername"), "sst_mode": "mariabackup"}, doStepIf=lambda step: hasInstall(step) and savePackage(step) and hasFiles(step)))
f_deb_autobake.addStep(steps.Trigger(name='galera-sst-mysqldump', schedulerNames=['s_install'], waitForFinish=True, updateSourceStamp=False,
    set_properties={"tarbuildnum" : Property("tarbuildnum"), "mariadb_version" : Property("mariadb_version"), "master_branch" : Property("master_branch"), "parentbuildername": Property("buildername"), "sst_mode": "mysqldump"}, doStepIf=lambda step: hasInstall(step) and savePackage(step) and hasFiles(step)))
f_deb_autobake.addStep(steps.Trigger(name='galera-sst-rsync', schedulerNames=['s_install'], waitForFinish=True, updateSourceStamp=False,
    set_properties={"tarbuildnum" : Property("tarbuildnum"), "mariadb_version" : Property("mariadb_version"), "master_branch" : Property("master_branch"), "parentbuildername": Property("buildername"), "sst_mode": "rsync"}, doStepIf=lambda step: hasInstall(step) and savePackage(step) and hasFiles(step)))
f_deb_autobake.addStep(steps.Trigger(name='major-minor-upgrade', schedulerNames=['s_upgrade'], waitForFinish=True, updateSourceStamp=False,
    set_properties={"tarbuildnum" : Property("tarbuildnum"), "mariadb_version" : Property("mariadb_version"), "master_branch" : Property("master_branch"), "parentbuildername": Property("buildername")}, doStepIf=lambda step: hasUpgrade(step) and savePackage(step) and hasFiles(step)))
f_deb_autobake.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_bintar
f_bintar = util.BuildFactory()
f_bintar.addStep(downloadSourceTarball())
f_bintar.addStep(steps.ShellCommand(command=util.Interpolate("tar -xvzf /mnt/packages/%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz --strip-components=1")))
f_bintar.addStep(steps.ShellCommand(name="create html log file", command=['bash', '-c', util.Interpolate(getHTMLLogString(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
# build steps
f_bintar.addStep(steps.Compile(command=
    ["sh", "-c", util.Interpolate("export PATH=/usr/lib/ccache:/usr/lib64/ccache:$PATH && cmake . -DBUILD_CONFIG=mysql_release -DWITH_READLINE=1 -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER_LAUNCHER=ccache %(kw:additional_args)s  && make -j%(kw:jobs)s package", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'), additional_args=util.Property('additional_args', default=''))], env={'CCACHE_DIR':'/mnt/ccache'}, haltOnFailure="true"))

#f_bintar.addStep(steps.MTR(logfiles={"mysqld*": "/buildbot/mysql_logs.html"}, command=
#    ["sh", "-c", util.Interpolate("cd mysql-test && exec perl mysql-test-run.pl --verbose-restart --force --retry=3 --max-save-core=1 --max-save-datadir=1 --max-test-fail=20 --mem --parallel=$(expr %(kw:jobs)s \* 2)", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=7200, haltOnFailure="true", parallel=mtrJobsMultiplier, dbpool=mtrDbPool, autoCreateTables=True))
#f_bintar.addStep(steps.ShellCommand(name="move mysqld log files", alwaysRun=True, command=['bash', '-c', util.Interpolate(moveMTRLogs(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
#f_bintar.addStep(steps.DirectoryUpload(name="save mysqld log files", compress="bz2", alwaysRun=True,  workersrc='/buildbot/logs/', masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + '/logs/' + '%(prop:buildername)s' )))
# create package and upload to master
f_bintar.addStep(steps.SetPropertyFromCommand(command="basename mariadb-*-linux-*.tar.gz", property="mariadb_binary", doStepIf=savePackage))
f_bintar.addStep(steps.ShellCommand(name='save_packages', timeout=7200, haltOnFailure=True, command=util.Interpolate('mkdir -p ' + '/packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s'+ ' && sha256sum %(prop:mariadb_binary)s >> sha256sums.txt  && cp ' + '%(prop:mariadb_binary)s sha256sums.txt' + ' /packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s' + '/' +  ' && sync /packages/' + '%(prop:tarbuildnum)s'), doStepIf=savePackage))
f_bintar.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_without_server
f_without_server = util.BuildFactory()
f_without_server.addStep(steps.SetProperty(property="dockerfile", value=util.Interpolate("%(kw:url)s", url=dockerfile), description="dockerfile"))
f_without_server.addStep(steps.ShellCommand(command="ls -la"))
f_without_server.addStep(downloadSourceTarball())
f_without_server.addStep(steps.ShellCommand(command="ls -la"))
f_without_server.addStep(steps.ShellCommand(command=util.Interpolate("tar -xvzf /mnt/packages/%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz --strip-components=1")))
f_without_server.addStep(steps.ShellCommand(command="ls -la"))
# build steps
f_without_server.addStep(steps.Compile(command=
    ["sh", "-c", util.Interpolate("export PATH=/usr/lib/ccache:/usr/lib64/ccache:$PATH && cmake . -DCMAKE_BUILD_TYPE=RelWithDebInfo -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_C_COMPILER=%(kw:c_compiler)s -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER=%(kw:cxx_compiler)s -DWITHOUT_SERVER=1 && make -j%(kw:jobs)s package", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'), c_compiler=util.Property('c_compiler', default='gcc'), cxx_compiler=util.Property('cxx_compiler', default='g++'))], env={'CCACHE_DIR':'/mnt/ccache'}, haltOnFailure="true"))
#    ["sh", "-c", util.Interpolate("export PATH=/usr/lib/ccache:/usr/lib64/ccache:$PATH && mkdir -p ../builddir && cd ../builddir && cmake ${OLDPWD} -DCMAKE_BUILD_TYPE=RelWithDebInfo -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_C_COMPILER=%(kw:c_compiler)s -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER=%(kw:cxx_compiler)s -DWITHOUT_SERVER=ON && cmake --build . --parallel %(kw:jobs)s --target package", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'), c_compiler=util.Property('c_compiler', default='gcc'), cxx_compiler=util.Property('cxx_compiler', default='g++'))], env={'CCACHE_DIR':'/mnt/ccache'}, haltOnFailure="true"))
# create package and upload to master
f_without_server.addStep(steps.SetPropertyFromCommand(command="basename mariadb-*-linux-*.tar.gz", property="mariadb_binary"))
#f_without_server.addStep(steps.FileUpload(workersrc=util.Interpolate("%(prop:mariadb_binary)s"), masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + "/" + '%(prop:buildername)s' + "/" + "%(prop:mariadb_binary)s"), mode=0o755, url=util.Interpolate('https://ci.mariadb.org/' + "%(prop:tarbuildnum)s" + "/" + '%(prop:buildername)s' + "/"), urlText="Download", doStepIf=savePackage))
f_without_server.addStep(steps.ShellCommand(name='save_packages', timeout=7200, haltOnFailure=True, command=util.Interpolate('mkdir -p ' + '/packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s'+ ' && sha256sum %(prop:mariadb_binary)s >> sha256sums.txt  && cp ' + '%(prop:mariadb_binary)s sha256sums.txt' + ' /packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s' + '/' +  ' && sync /packages/' + '%(prop:tarbuildnum)s'), doStepIf=savePackage))
f_without_server.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_eco_php
f_eco_php = util.BuildFactory()
f_eco_php.addStep(steps.ShellCommand(
    name="fetch_install_script",
    command=["sh", "-xc", "curl https://raw.githubusercontent.com/MariaDB/mariadb.org-tools/master/buildbot.mariadb.org/dockerfiles/ecofiles/installdb.sh -o /buildbot/installdb.sh && chmod a+x /buildbot/installdb.sh"]))
f_eco_php.addStep(steps.ShellCommand(
    name="fetch_test_script",
    command=["sh", "-xc", "curl https://raw.githubusercontent.com/MariaDB/mariadb.org-tools/master/buildbot.mariadb.org/dockerfiles/ecofiles/test-php.sh -o /buildbot/test-php.sh && chmod a+x /buildbot/test-php.sh"]))
f_eco_php.addStep(steps.ShellCommand(
    name="fetching and installing database",
    command=["sh", "-xc", util.Interpolate("/buildbot/installdb.sh \"https://ci.mariadb.org/%(prop:tarbuildnum)s/%(prop:parentbuildername)s/%(prop:mariadb_binary)s\" --plugin-load-add=auth_pam --pam_use_cleartext_plugin")]))
f_eco_php.addStep(steps.ShellCommand(
    name="test PHP-7.1",
    command=["sh", "-xc", "/buildbot/test-php.sh PHP-7.1"]))
f_eco_php.addStep(steps.ShellCommand(
    name="test PHP-8.0",
    command=["sh", "-xc", "/buildbot/test-php.sh PHP-8.0"]))
f_eco_php.addStep(steps.ShellCommand(
    name="test PHP-8.1",
    command=["sh", "-xc", "/buildbot/test-php.sh PHP-8.1"]))
f_eco_php.addStep(steps.ShellCommand(
    name="test master",
    command=["sh", "-xc", "/buildbot/test-php.sh"]))

## f_eco_dbdeployer
f_eco_dbdeployer = util.BuildFactory()
f_eco_dbdeployer.addStep(steps.ShellCommand(
    name="fetch_test_script",
    command=["sh", "-xc", "curl https://raw.githubusercontent.com/MariaDB/mariadb.org-tools/master/buildbot.mariadb.org/dockerfiles/ecofiles/test-dbdeployer.sh -o /buildbot/test-dbdeployer.sh && chmod a+x /buildbot/test-dbdeployer.sh"]))
f_eco_dbdeployer.addStep(steps.ShellCommand(
    name="download if needed latest dbdeployer",
    command=["sh", "-xc", "/buildbot/test-dbdeployer.sh dbdeployerfetch"]))
f_eco_dbdeployer.addStep(steps.ShellCommand(
    name="fetching mariadb tarball",
    command=["sh", "-xc", util.Interpolate("/buildbot/test-dbdeployer.sh init \"https://ci.mariadb.org/%(prop:tarbuildnum)s/%(prop:parentbuildername)s/%(prop:mariadb_binary)s\"")]))
f_eco_dbdeployer.addStep(steps.ShellCommand(
    name="deploy single ma",
    command=["sh", "-xc", util.Interpolate("/buildbot/test-dbdeployer.sh deploy single ma%(prop:mariadb_version)s")]))
f_eco_dbdeployer.addStep(steps.ShellCommand(
    name="deploy replication ma",
    command=["sh", "-xc", util.Interpolate("/buildbot/test-dbdeployer.sh deploy replication ma%(prop:mariadb_version)s")]))
f_eco_dbdeployer.addStep(steps.ShellCommand(
    name="global test",
    command=["sh", "-xc", "/buildbot/test-dbdeployer.sh global test"]))
f_eco_dbdeployer.addStep(steps.ShellCommand(
    name="global replication",
    command=["sh", "-xc", "/buildbot/test-dbdeployer.sh global test-replication"]))

## f_eco_pymysql
f_eco_pymysql = util.BuildFactory()
f_eco_pymysql.addStep(steps.ShellCommand(
    name="fetch_install_script",
    command=["sh", "-xc", "curl https://raw.githubusercontent.com/MariaDB/mariadb.org-tools/master/buildbot.mariadb.org/dockerfiles/ecofiles/installdb.sh -o /buildbot/installdb.sh && chmod a+x /buildbot/installdb.sh"]))
f_eco_pymysql.addStep(steps.ShellCommand(
    name="fetch_test_script",
    command=["sh", "-xc", "curl https://raw.githubusercontent.com/MariaDB/mariadb.org-tools/master/buildbot.mariadb.org/dockerfiles/ecofiles/test-pymysql.sh -o /buildbot/test-pymysql.sh && chmod a+x /buildbot/test-pymysql.sh"]))
f_eco_pymysql.addStep(steps.ShellCommand(
    name="fetching and installing database",
    command=["sh", "-xc", util.Interpolate("/buildbot/installdb.sh \"https://ci.mariadb.org/%(prop:tarbuildnum)s/%(prop:parentbuildername)s/%(prop:mariadb_binary)s\"")]))
f_eco_pymysql.addStep(steps.ShellCommand(
    name="test pymysql-main",
    command=["sh", "-xc", "/buildbot/test-pymysql.sh"]))
f_eco_pymysql.addStep(steps.ShellCommand(
    name="test pymysql-v0.7.11",
    command=["sh", "-xc", "/buildbot/test-pymysql.sh v0.7.11"]))

## f_eco_mysqljs
f_eco_mysqljs = util.BuildFactory()
f_eco_mysqljs.addStep(steps.ShellCommand(
    name="fetch_install_script",
    command=["sh", "-xc", "curl https://raw.githubusercontent.com/MariaDB/mariadb.org-tools/master/buildbot.mariadb.org/dockerfiles/ecofiles/installdb.sh -o /buildbot/installdb.sh && chmod a+x /buildbot/installdb.sh"]))
f_eco_mysqljs.addStep(steps.ShellCommand(
    name="fetch_test_script",
    command=["sh", "-xc", "curl https://raw.githubusercontent.com/MariaDB/mariadb.org-tools/master/buildbot.mariadb.org/dockerfiles/ecofiles/test-mysqljs.sh -o /buildbot/test-mysqljs.sh && chmod a+x /buildbot/test-mysqljs.sh"]))
f_eco_mysqljs.addStep(steps.ShellCommand(
    name="fetching and installing database",
    command=["sh", "-xc", util.Interpolate("/buildbot/installdb.sh \"https://ci.mariadb.org/%(prop:tarbuildnum)s/%(prop:parentbuildername)s/%(prop:mariadb_binary)s\"")]))
f_eco_mysqljs.addStep(steps.ShellCommand(
    name="test mysqljs-master",
    command=["sh", "-xc", "/buildbot/test-mysqljs.sh"]))
f_eco_mysqljs.addStep(steps.ShellCommand(
    name="test mysqljs-v2.18.1",
    command=["sh", "-xc", "/buildbot/test-mysqljs.sh v2.18.1"]))

####### BUILDERS LIST
protected_branches_mtr_additional_args = '--suite=main --skip-test="^stack_crash$|^float$|^derived_split_innodb$|^mysql_client_test$|^kill$|^processlist_not_embedded$|^sp-big$"'

c['builders'] = []

c['builders'].append(
    util.BuilderConfig(name="tarball-docker",
      workernames=["hz-bbw1-docker-tarball-debian-10", "hz-bbw4-docker-tarball-debian-10"],
      tags=["tar", "bake"],
      collapseRequests=True,
      nextBuild=nextBuild,
      factory=f_tarball))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-1804",
      workernames=workers["x64-bbw-docker-ubuntu-1804"],
      tags=["Ubuntu", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-1804-deb-autobake",
      workernames=workers["x64-bbw-docker-ubuntu-1804"],
      tags=["Ubuntu", "deb", "bake", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-2004",
      workernames=workers["x64-bbw-docker-ubuntu-2004"],
      tags=["Ubuntu", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-2004-clang11",
      workernames=workers["x64-bbw-docker-ubuntu-2004-clang"],
      tags=["Ubuntu", "quick", "clang"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'c_compiler': 'clang-11', 'cxx_compiler': 'clang++', 'mtr_additional_args': protected_branches_mtr_additional_args},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-1804-icc",
      workernames=workers["x64-bbw-docker-icc-ubuntu-1804"],
      tags=["Ubuntu", "quick", "icc", "icpc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'c_compiler': 'icc', 'cxx_compiler': 'icpc'},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-2004-deb-autobake",
      workernames=workers["bg-bbw-docker-ubuntu-2004"],
      tags=["Ubuntu", "deb", "bake", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="s390x-ubuntu-2004",
      workernames=workers["s390x-bbw-docker-ubuntu-2004"],
      tags=["Ubuntu", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="s390x-ubuntu-2004-deb-autobake",
      workernames=workers["s390x-bbw-docker-ubuntu-2004"],
      tags=["Ubuntu", "deb", "bake", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="s390x-ubuntu-2204",
      workernames=workers["s390x-bbw-docker-ubuntu-2204"],
      tags=["Ubuntu", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="s390x-ubuntu-2204-deb-autobake",
      workernames=workers["s390x-bbw-docker-ubuntu-2204"],
      tags=["Ubuntu", "deb", "bake", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="s390x-rhel-8",
      workernames=workers["s390x-bbw-docker-rhel-8"],
      tags=["RHEL", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="s390x-rhel-8-rpm-autobake",
      workernames=workers["s390x-bbw-docker-rhel-8"],
      tags=["RHEL", "rpm", "bake", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'rhel8'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="s390x-sles-15",
      workernames=workers["s390x-bbw-docker-sles-15"],
      tags=["SLES", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="s390x-sles-15-rpm-autobake",
      workernames=workers["s390x-bbw-docker-sles-15"],
      tags=["SLES", "rpm", "bake", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'sles15'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-2204",
      workernames=workers["x64-bbw-docker-ubuntu-2204"],
      tags=["Ubuntu", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-2204-deb-autobake",
      workernames=workers["x64-bbw-docker-ubuntu-2204"],
      tags=["Ubuntu", "deb", "bake", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-2110",
      workernames=workers["x64-bbw-docker-ubuntu-2110"],
      tags=["Ubuntu", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-2110-deb-autobake",
      workernames=workers["x64-bbw-docker-ubuntu-2110"],
      tags=["Ubuntu", "deb", "bake", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-2004-eco-php",
      workernames=["hz-bbw2-docker-eco-php-ubuntu-2004"],
      tags=["Ubuntu", "ecosystem", "PHP"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      factory=f_eco_php))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-2004-eco-dbdeployer",
      workernames=["hz-bbw2-docker-eco-dbdeployer-ubuntu-2004"],
      tags=["Ubuntu", "ecosystem", "dbdeployer"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      factory=f_eco_dbdeployer))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-10-eco-pymysql",
      workernames=["hz-bbw2-docker-eco-pymysql-python-3-9-slim-buster"],
      tags=["Debian", "ecosystem", "pymysql"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      factory=f_eco_pymysql))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-10-eco-mysqljs",
      workernames=["hz-bbw2-docker-eco-mysqljs-nodejs15-buster"],
      tags=["Debian", "ecosystem", "mysqljs"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      factory=f_eco_mysqljs))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-1804-bigtest",
      workernames=["bm-bbw1-docker-ubuntu-1804"],
      tags=["Ubuntu", "big", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      factory=f_big_test))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-9",
      workernames=workers["x64-bbw-docker-debian-9"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-9-deb-autobake",
      workernames=workers["x64-bbw-docker-debian-9"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="x86-debian-9",
      workernames=workers["x64-bbw-docker-debian-9-i386"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="x86-debian-9-deb-autobake",
      workernames=workers["x64-bbw-docker-debian-9-i386"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-10",
      workernames=workers["x64-bbw-docker-debian-10"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'mtr_additional_args': protected_branches_mtr_additional_args},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-10-deb-autobake",
      workernames=workers["bg-bbw-docker-debian-10"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-11",
      workernames=workers["x64-bbw-docker-debian-11"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'mtr_additional_args': protected_branches_mtr_additional_args},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-11-deb-autobake",
      workernames=workers["x64-bbw-docker-debian-11"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-sid",
      workernames=workers["x64-bbw-docker-debian-sid"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-sid-deb-autobake",
      workernames=workers["x64-bbw-docker-debian-sid"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="x86-debian-sid",
      workernames=workers["x64-bbw-docker-debian-sid-i386"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="x86-debian-sid-deb-autobake",
      workernames=workers["x64-bbw-docker-debian-sid-i386"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-rhel-7",
      workernames=workers["x64-bbw-docker-rhel-7"],
      tags=["RHEL", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-rhel-7-rpm-autobake",
      workernames=workers["x64-bbw-docker-rhel-7"],
      tags=["RHEL", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'rhel7'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-rhel-8",
      workernames=workers["x64-bbw-docker-rhel-8"],
      tags=["RHEL", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-rhel-8-rpm-autobake",
      workernames=workers["bg-bbw-docker-rhel-8"],
      tags=["RHEL", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'rhel8'},
      factory=f_rpm_autobake))


c['builders'].append(
    util.BuilderConfig(name="amd64-fedora-34",
      workernames=workers["x64-bbw-docker-fedora-34"],
      tags=["Fedora", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-fedora-34-rpm-autobake",
      workernames=workers["bg-bbw-docker-fedora-34"],
      tags=["Fedora", "rpm", "bake", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'fedora34'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-fedora-35",
      workernames=workers["x64-bbw-docker-fedora-35"],
      tags=["Fedora", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'mtr_additional_args': protected_branches_mtr_additional_args},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-fedora-35-rpm-autobake",
      workernames=workers["bg-bbw-docker-fedora-35"],
      tags=["Fedora", "rpm", "bake", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'fedora35'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-sles-12",
      workernames=workers["x64-bbw-docker-sles-12"],
      tags=["Fedora", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-sles-12-rpm-autobake",
      workernames=workers["x64-bbw-docker-sles-12"],
      tags=["Fedora", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'sles12'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-sles-15",
      workernames=workers["x64-bbw-docker-sles-15"],
      tags=["Fedora", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-sles-15-rpm-autobake",
      workernames=workers["x64-bbw-docker-sles-15"],
      tags=["Fedora", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'sles15'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-centos-7",
      workernames=workers["x64-bbw-docker-centos-7"],
      tags=["Centos", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'mtr_additional_args': protected_branches_mtr_additional_args},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-centos-7-rpm-autobake",
      workernames=workers["bg-bbw-docker-centos-7"],
      tags=["Centos", "rpm", "bake", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'centos7'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-centos-stream8",
      workernames=workers["bg-bbw-docker-centos-stream8"],
      tags=["Centos", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-centos-stream8-rpm-autobake",
      workernames=workers["bg-bbw-docker-centos-stream8"],
      tags=["Centos", "rpm", "bake", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'centos8'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-opensuse-15",
      workernames=workers["x64-bbw-docker-opensuse-15"],
      tags=["OpenSUSE", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-opensuse-15-rpm-autobake",
      workernames=workers["bg-bbw-docker-opensuse-15"],
      tags=["OpenSUSE", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'opensuse15'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-2004-fulltest",
      workernames=workers["bg-bbw-docker-ubuntu-2004"],
      tags=["Ubuntu", "full", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_full_test))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-ubuntu-1804",
      workernames=workers["p9-bbw-docker-ubuntu-1804"],
      tags=["Ubuntu", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-ubuntu-1804-deb-autobake",
      workernames=workers["p9-bbw-docker-ubuntu-1804"],
      tags=["Ubuntu", "deb", "bake", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-ubuntu-2004",
      workernames=workers["p9-bbw-docker-ubuntu-2004"],
      tags=["Ubuntu", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-ubuntu-2004-deb-autobake",
      workernames=workers["p9-bbw-docker-ubuntu-2004"],
      tags=["Ubuntu", "deb", "bake", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-ubuntu-2204",
      workernames=workers["p9-bbw-docker-ubuntu-2204"],
      tags=["Ubuntu", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-ubuntu-2204-deb-autobake",
      workernames=workers["p9-bbw-docker-ubuntu-2204"],
      tags=["Ubuntu", "deb", "bake", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-ubuntu-2110",
      workernames=workers["p9-bbw-docker-ubuntu-2110"],
      tags=["Ubuntu", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-ubuntu-2110-deb-autobake",
      workernames=workers["p9-bbw-docker-ubuntu-2110"],
      tags=["Ubuntu", "deb", "bake", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-debian-9",
      workernames=workers["p9-bbw-docker-debian-9"],
      tags=["Ubuntu", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-debian-9-deb-autobake",
      workernames=workers["p9-bbw-docker-debian-9"],
      tags=["Ubuntu", "deb", "bake", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-debian-10",
      workernames=workers["p9-bbw-docker-debian-10"],
      tags=["Ubuntu", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-debian-10-deb-autobake",
      workernames=workers["p9-bbw-docker-debian-10"],
      tags=["Ubuntu", "deb", "bake", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-debian-11",
      workernames=workers["p9-bbw-docker-debian-11"],
      tags=["Ubuntu", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-debian-11-deb-autobake",
      workernames=workers["p9-bbw-docker-debian-11"],
      tags=["Ubuntu", "deb", "bake", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-debian-sid",
      workernames=workers["p9-bbw-docker-debian-sid"],
      tags=["Ubuntu", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-debian-sid-deb-autobake",
      workernames=workers["p9-bbw-docker-debian-sid"],
      tags=["Ubuntu", "deb", "bake", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-ubuntu-1804-without-server",
      workernames=workers["p9-bbw-docker-ubuntu-1804"],
      tags=["Ubuntu", "without-server", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_without_server))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-ubuntu-2004-clang1x",
      workernames=workers["p9-bbw-docker-clang-ubuntu-2004"],
      tags=["Ubuntu", "quick", "clang-10", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'c_compiler': 'clang-10', 'cxx_compiler': 'clang++-10', 'additional_args': '-DWITHOUT_ROCKSDB=True -DWITHOUT_CONNECT=True -DCMAKE_C_FLAGS=-Wno-inconsistent-missing-override -DCMAKE_CXX_FLAGS=-Wno-inconsistent-missing-override'},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-rhel-7",
      workernames=workers["p9-bbw-docker-rhel-7"],
      tags=["RHEL", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-rhel-7-rpm-autobake",
      workernames=workers["p9-bbw-docker-rhel-7"],
      tags=["RHEL", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'rhel7'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-rhel-8",
      workernames=workers["p9-bbw-docker-rhel-8"],
      tags=["RHEL", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'mtr_additional_args': protected_branches_mtr_additional_args},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-rhel-8-rpm-autobake",
      workernames=workers["p9-bbw-docker-rhel-8"],
      tags=["RHEL", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'rhel8'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-centos-7",
      workernames=workers["p9-bbw-docker-centos-7"],
      tags=["Centos", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-centos-7-rpm-autobake",
      workernames=workers["p9-bbw-docker-centos-7"],
      tags=["Centos", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'centos7'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-1804-clang6",
      workernames=["fjord1-docker-ubuntu-1804"] + workers["x64-bbw-docker-clang-ubuntu-1804"],
      tags=["Ubuntu", "quick", "clang-6"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'c_compiler': 'clang-6.0', 'cxx_compiler': 'clang++-6.0', 'additional_args': '-DCMAKE_C_FLAGS=-Wno-inconsistent-missing-override -DCMAKE_CXX_FLAGS=-Wno-inconsistent-missing-override'},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-1804-debug",
      workernames=["fjord1-docker-ubuntu-1804"] + workers["x64-bbw-docker-clang-ubuntu-1804"],
      tags=["Ubuntu", "quick", "gcc", "debug"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'build_type': 'Debug'},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-1804-clang10",
      workernames=["fjord2-docker-ubuntu-1804"] + workers["x64-bbw-docker-clang-ubuntu-1804"],
      tags=["Ubuntu", "quick", "clang-10"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'c_compiler': 'clang-10', 'cxx_compiler': 'clang++', 'additional_args': '-DCMAKE_C_FLAGS=-Wno-inconsistent-missing-override -DCMAKE_CXX_FLAGS=-Wno-inconsistent-missing-override'},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-1804-clang10-asan",
      workernames=["fjord2-docker-ubuntu-1804"] + workers["x64-bbw-docker-clang-ubuntu-1804"],
      tags=["Ubuntu", "quick", "clang-10", "asan"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_asan_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-2004-msan",
      workernames=workers["bg-bbw-docker-msan-clang-ubuntu-2004"],
      tags=["Ubuntu", "quick", "clang-10", "msan"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_msan_build))

c['builders'].append(
    util.BuilderConfig(name="x86-ubuntu-1804",
      workernames=workers["bg-bbw-docker-x86-ubuntu-1804"],
      tags=["Ubuntu", "quick", "gcc", "32bit"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_32b_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-1804-valgrind",
      workernames=workers["bg-bbw-docker-valgrind-ubuntu-1804"] + workers['x64-bbw-docker-valgrind-ubuntu-1804'],
      tags=["Ubuntu", "quick", "gcc", "valgrind"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_valgrind_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-ubuntu-1804",
      workernames=workers["aarch64-bbw-docker-ubuntu-1804"],
      tags=["Ubuntu", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-ubuntu-1804-deb-autobake",
      workernames=workers["aarch64-bbw-docker-ubuntu-1804"],
      tags=["Ubuntu", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-ubuntu-2004",
      workernames=workers["aarch64-bbw-docker-ubuntu-2004"],
      tags=["Ubuntu", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-ubuntu-2004-deb-autobake",
      workernames=workers["aarch64-bbw-docker-ubuntu-2004"],
      tags=["Ubuntu", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-ubuntu-2204",
      workernames=workers["aarch64-bbw-docker-ubuntu-2204"],
      tags=["Ubuntu", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-ubuntu-2204-deb-autobake",
      workernames=workers["aarch64-bbw-docker-ubuntu-2204"],
      tags=["Ubuntu", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-ubuntu-2110",
      workernames=workers["aarch64-bbw-docker-ubuntu-2110"],
      tags=["Ubuntu", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-ubuntu-2110-deb-autobake",
      workernames=workers["aarch64-bbw-docker-ubuntu-2110"],
      tags=["Ubuntu", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-fedora-34",
      workernames=workers["aarch64-bbw-docker-fedora-34"],
      tags=["Fedora", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-fedora-34-rpm-autobake",
      workernames=workers["aarch64-bbw-docker-fedora-34"],
      tags=["Fedora", "rpm", "bake", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'fedora34'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-fedora-35",
      workernames=workers["aarch64-bbw-docker-fedora-35"],
      tags=["Fedora", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-fedora-35-rpm-autobake",
      workernames=workers["aarch64-bbw-docker-fedora-35"],
      tags=["Fedora", "rpm", "bake", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'fedora35'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-centos-7",
      workernames=workers["aarch64-bbw-docker-centos-7"],
      tags=["Centos", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-centos-7-rpm-autobake",
      workernames=workers["aarch64-bbw-docker-centos-7"],
      tags=["Centos", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'centos7'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-centos-stream8",
      workernames=workers["aarch64-bbw-docker-centos-stream8"],
      tags=["Centos", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-centos-stream8-rpm-autobake",
      workernames=workers["aarch64-bbw-docker-centos-stream8"],
      tags=["Centos", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'centos8'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-debian-9",
      workernames=workers["aarch64-bbw-docker-debian-9"],
      tags=["Debian", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-debian-9-deb-autobake",
      workernames=workers["aarch64-bbw-docker-debian-9"],
      tags=["Debian", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-debian-10",
      workernames=["aarch64-bbw4-docker-debian-10"],
      tags=["Debian", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'mtr_additional_args': protected_branches_mtr_additional_args},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-debian-10-deb-autobake",
      workernames=workers["aarch64-bbw-docker-debian-10"],
      tags=["Debian", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-debian-11",
      workernames=workers["aarch64-bbw-docker-debian-11"],
      tags=["Debian", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'mtr_additional_args': protected_branches_mtr_additional_args},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-debian-11-deb-autobake",
      workernames=workers["aarch64-bbw-docker-debian-11"],
      tags=["Debian", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-debian-sid",
      workernames=workers["aarch64-bbw-docker-debian-sid"],
      tags=["Debian", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-debian-sid-deb-autobake",
      workernames=workers["aarch64-bbw-docker-debian-sid"],
      tags=["Debian", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-rhel-7",
      workernames=workers["aarch64-bbw-docker-rhel-7"],
      tags=["RHEL", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-rhel-7-rpm-autobake",
      workernames=workers["aarch64-bbw-docker-rhel-7"],
      tags=["RHEL", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'rhel7'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-rhel-8",
      workernames=workers["aarch64-bbw-docker-rhel-8"],
      tags=["RHEL", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-rhel-8-rpm-autobake",
      workernames=workers["aarch64-bbw-docker-rhel-8"],
      tags=["RHEL", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'rhel8', 'mtr_additional_args': '-DPLUGIN_COLUMNSTORE=NO'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="x86-debian-9-bintar-systemd",
      workernames=workers["x64-bbw-docker-debian-9-i386"],
      tags=["Debian", "bintar", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'additional_args': '-DWITH_SYSTEMD=yes'},
      factory=f_bintar))

c['builders'].append(
    util.BuilderConfig(name="x86-debian-9-bintar-initd",
      workernames=workers["x64-bbw-docker-debian-9-i386"],
      tags=["Debian", "bintar", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'additional_args': '-DWITH_SYSTEMD=no'},
      factory=f_bintar))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-9-bintar-systemd",
      workernames=workers["x64-bbw-docker-debian-9"],
      tags=["Debian", "bintar", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'additional_args': '-DWITH_SYSTEMD=yes'},
      factory=f_bintar))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-9-bintar-initd",
      workernames=workers["x64-bbw-docker-debian-9"],
      tags=["Debian", "bintar", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'additional_args': '-DWITH_SYSTEMD=no'},
      factory=f_bintar))

c['builders'].append(
    util.BuilderConfig(name="aarch64-centos-7-bintar-systemd",
      workernames=workers["aarch64-bbw-docker-centos-7"],
      tags=["Debian", "bintar", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'additional_args': '-DWITH_SYSTEMD=yes'},
      factory=f_bintar))

c['builders'].append(
    util.BuilderConfig(name="aarch64-centos-7-bintar-initd",
      workernames=workers["aarch64-bbw-docker-centos-7"],
      tags=["Debian", "bintar", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'additional_args': '-DWITH_SYSTEMD=no'},
      factory=f_bintar))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-debian-9-bintar-systemd",
      workernames=workers["p9-bbw-docker-debian-9"],
      tags=["Ubuntu", "bintar", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'additional_args': '-DWITH_SYSTEMD=yes'},
      factory=f_bintar))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-debian-9-bintar-initd",
      workernames=workers["p9-bbw-docker-debian-9"],
      tags=["Ubuntu", "bintar", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'additional_args': '-DWITH_SYSTEMD=no'},
      factory=f_bintar))

# Add a Janitor configurator that removes old logs
c['configurators'] = [util.JanitorConfigurator(
    logHorizon=timedelta(weeks=6),
    hour=23
)]

c['logEncoding'] = 'utf-8'

c['multiMaster'] = True

c['mq'] = {  # Need to enable multimaster aware mq. Wamp is the only option for now.
    'type' : 'wamp',
    'router_url': 'ws://buildbot.mariadb.org:8085/ws',
    'realm': 'realm1',
    # valid are: none, critical, error, warn, info, debug, trace
    'wamp_debug_level' : 'info'
}

#### prometheus exporter //TEMP added Faustin
c['services'].append(reporters.Prometheus(port=9101))
