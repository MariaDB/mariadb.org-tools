# -*- python -*-
# ex: set filetype=python:

from buildbot.plugins import *
from buildbot.process.properties import Property, Properties
from buildbot.steps.shell import ShellCommand, Compile, Test, SetPropertyFromCommand
from buildbot.steps.mtrlogobserver import MTR, MtrLogObserver
from buildbot.steps.source.github import GitHub
from buildbot.process.remotecommand import RemoteCommand
from twisted.internet import defer
import sys
import docker
from datetime import timedelta

sys.setrecursionlimit(10000)

# This is the dictionary that the buildmaster pays attention to. We also use
# a shorter alias to save typing.
c = BuildmasterConfig = {}

# Load the slave, database passwords and 3rd-party tokens from an external private file, so
# that the rest of the configuration can be public.
config = { "private": { } }
exec(open("master-private.cfg").read(), config, { })

####### BUILDBOT SERVICES

# 'services' is a list of BuildbotService items like reporter targets. The
# status of each build will be pushed to these targets. buildbot/reporters/*.py
# has a variety to choose from, like IRC bots.

github_status_builders = ["amd64-centos-7", "amd64-debian-10", "amd64-fedora-33", "amd64-ubuntu-2004-clang11"]

c['services'] = []
context = util.Interpolate("buildbot/%(prop:buildername)s")
gs = reporters.GitHubStatusPush(token=config["private"]["gh_mdbci"]["access_token"],
                                context=context,
                                startDescription='Build started.',
                                endDescription='Build done.',
                                verbose=True,
                                builders=github_status_builders)
c['services'].append(gs)

####### PROJECT IDENTITY

# the 'title' string will appear at the top of this buildbot installation's
# home pages (linked to the 'titleURL').
c['title'] = "MariaDB CI"
c['titleURL'] = "https://github.com/MariaDB/server"

# the 'buildbotURL' string should point to the location where the buildbot's
# internal web server is visible. This typically uses the port number set in
# the 'www' entry below, but with an externally-visible host name which the
# buildbot cannot figure out without some help.

c['buildbotURL'] = "https://buildbot.mariadb.org/"

# Custom plugin
# exec(open("grid.py").read())

# 'protocols' contains information about protocols which master will use for
# communicating with workers. You must define at least 'port' option that workers
# could connect to your master with this protocol.
# 'port' must match the value configured into the workers (with their
# --master option)
c['protocols'] = {'pb': {'port': 9989}}

####### DB URL

c['db'] = {
    # This specifies what database buildbot uses to store its state.
    'db_url' : config["private"]["db_url"]
}

mtrDbPool = util.EqConnectionPool("MySQLdb", config["private"]["db_host"], config["private"]["db_user"], config["private"]["db_password"], config["private"]["db_mtr_db"])

####### Disable net usage reports from being sent to buildbot.net
c['buildbotNetUsageData'] = None

####### SCHEDULERS

builders_quick=["amd64-ubuntu-1804", "amd64-ubuntu-2004", "amd64-ubuntu-2104", "amd64-ubuntu-2004-icc", "amd64-ubuntu-2004-fulltest", "amd64-ubuntu-2004-gcc10", "amd64-ubuntu-2004-clang11", "amd64-ubuntu-1804-clang6", "amd64-ubuntu-1804-clang10", "amd64-ubuntu-1804-clang10-asan", "amd64-ubuntu-1804-msan", "x86-ubuntu-1804", "amd64-ubuntu-1804-valgrind", "aarch64-ubuntu-1804", "aarch64-ubuntu-2004", "aarch64-ubuntu-2104", "amd64-rhel-7", "amd64-rhel-8", "amd64-ubuntu-1804-debug", "amd64-debian-9", "x86-debian-9","amd64-debian-10", "amd64-debian-11", "amd64-debian-sid", "x86-debian-sid", "amd64-fedora-33", "amd64-fedora-34", "amd64-centos-7", "amd64-centos-8", "amd64-opensuse-15", "amd64-opensuse-42", "amd64-sles-12", "amd64-sles-15", "ppc64le-debian-9", "ppc64le-debian-10", "ppc64le-debian-11", "ppc64le-debian-sid", "ppc64le-ubuntu-1804", "ppc64le-ubuntu-2004", "ppc64le-ubuntu-2104", "ppc64le-ubuntu-2004-clang1x", "ppc64le-ubuntu-1804-without-server", "ppc64le-rhel-7", "ppc64le-rhel-8", "ppc64le-centos-7", "aarch64-fedora-33","aarch64-fedora-34", "aarch64-centos-7", "aarch64-centos-8", "aarch64-debian-10", "aarch64-debian-11", "aarch64-debian-sid", "aarch64-debian-9", "aarch64-rhel-7", "aarch64-rhel-8", "amd64-windows", "amd64-windows-packages", "x86-windows", "x86-windows-packages", "amd64-windows-compile-only", "aix", "x86-debian-9-bintar-systemd", "x86-debian-9-bintar-initd", "amd64-debian-9-bintar-systemd", "amd64-debian-9-bintar-initd", "aarch64-centos-7-bintar-systemd", "aarch64-centos-7-bintar-initd", "ppc64le-debian-9-bintar-systemd", "ppc64le-debian-9-bintar-initd", "s390x-ubuntu-2004", "s390x-rhel-8"]

builders_quick = list(filter(lambda x: x not in github_status_builders, builders_quick))

builders_autobake=["amd64-centos-7-rpm-autobake", "amd64-centos-8-rpm-autobake", "amd64-debian-9-deb-autobake", "x86-debian-9-deb-autobake", "amd64-debian-10-deb-autobake", "amd64-debian-11-deb-autobake", "amd64-debian-sid-deb-autobake", "x86-debian-sid-deb-autobake", "amd64-fedora-33-rpm-autobake", "amd64-fedora-34-rpm-autobake", "amd64-rhel-7-rpm-autobake", "amd64-rhel-8-rpm-autobake", "amd64-opensuse-15-rpm-autobake", "amd64-opensuse-42-rpm-autobake", "amd64-sles-12-rpm-autobake", "amd64-sles-15-rpm-autobake", "amd64-ubuntu-1804-deb-autobake", "amd64-ubuntu-2004-deb-autobake", "amd64-ubuntu-2104-deb-autobake", "aarch64-ubuntu-1804-deb-autobake", "aarch64-ubuntu-2004-deb-autobake", "aarch64-ubuntu-2104-deb-autobake", "ppc64le-debian-9-deb-autobake", "ppc64le-debian-10-deb-autobake", "ppc64le-debian-11-deb-autobake", "ppc64le-debian-sid-deb-autobake", "ppc64le-ubuntu-1804-deb-autobake", "ppc64le-ubuntu-2004-deb-autobake", "ppc64le-ubuntu-2104-deb-autobake", "ppc64le-centos-7-rpm-autobake", "ppc64le-rhel-7-rpm-autobake", "ppc64le-rhel-8-rpm-autobake", "aarch64-debian-10-deb-autobake", "aarch64-debian-11-deb-autobake", "aarch64-debian-sid-deb-autobake", "aarch64-debian-9-deb-autobake", "aarch64-fedora-33-rpm-autobake", "aarch64-fedora-34-rpm-autobake", "aarch64-centos-7-rpm-autobake", "aarch64-centos-8-rpm-autobake", "aarch64-rhel-7-rpm-autobake", "aarch64-rhel-8-rpm-autobake", "s390x-ubuntu-2004-deb-autobake", "s390x-rhel-8-rpm-autobake"]

builders_big=["amd64-ubuntu-1804-bigtest"]

builders_install=["amd64-ubuntu-1804-deb-autobake-install", "amd64-centos-7-rpm-autobake-install"]

builders_upgrade=["amd64-ubuntu-1804-deb-autobake-major-upgrade", "amd64-ubuntu-1804-deb-autobake-minor-upgrade", "amd64-centos-7-rpm-autobake-major-upgrade", "amd64-centos-7-rpm-autobake-minor-upgrade"]

builders_eco=["amd64-ubuntu-2004-eco-php", "amd64-debian-10-eco-pymysql", "amd64-debian-10-eco-mysqljs", "amd64-ubuntu-2004-eco-dbdeployer"]

builders_dockerlibrary=["amd64-rhel8-dockerlibrary"]
 

# Configure the Schedulers, which decide how to react to incoming changes.

branches_main=['5.5', '5.5-galera', '10.0', '10.0-galera', '10.1', '10.2', '10.3', '10.4', '10.5', '10.6']
# The trees for which we save binary packages.
savedPackageBranches= ["5.5", "10.0", "10.1", "10.2", "10.3", "10.4", "10.5", "10.6", "10.7", "bb-*-release", "bb-10.2-compatibility"]
releaseBranches = ["bb-*-release", "preview-10.*"]

# mariadb version supported platforms
supportedPlatforms = {}
supportedPlatforms["10.2"] = ['aarch64-centos-7', 'aarch64-centos-8', 'aarch64-debian-10', 'aarch64-debian-9', 'aarch64-rhel-7', 'aarch64-rhel-8', 'aarch64-ubuntu-1804', 'amd64-centos-7', 'amd64-debian-10', 'amd64-debian-9', 'amd64-fedora-33', 'amd64-opensuse-15', 'amd64-opensuse-42', 'amd64-rhel-7', 'amd64-rhel-8', 'amd64-sles-12', 'amd64-sles-15', 'amd64-ubuntu-1804', 'amd64-ubuntu-1804-clang10', 'amd64-ubuntu-1804-clang10-asan', 'amd64-ubuntu-1804-clang6', 'amd64-ubuntu-1804-valgrind', 'amd64-ubuntu-2004', 'amd64-ubuntu-2004-clang11', 'amd64-windows-compile-only', 'ppc64le-centos-7', 'ppc64le-debian-9', 'ppc64le-rhel-7', 'ppc64le-rhel-8', 'ppc64le-ubuntu-1804', 'x86-debian-9', 'x86-ubuntu-1804']
supportedPlatforms["10.3"] = ['aarch64-centos-7', 'aarch64-centos-8', 'aarch64-debian-10', 'aarch64-debian-9', 'aarch64-rhel-7', 'aarch64-rhel-8', 'aarch64-ubuntu-1804', 'aarch64-ubuntu-2004', 'aarch64-ubuntu-2010', 'amd64-centos-7', 'amd64-centos-8', 'amd64-debian-10', 'amd64-debian-9', 'amd64-fedora-33', 'amd64-opensuse-15', 'amd64-opensuse-42', 'amd64-rhel-7', 'amd64-rhel-8', 'amd64-sles-12', 'amd64-sles-15', 'amd64-ubuntu-1804', 'amd64-ubuntu-1804-clang10', 'amd64-ubuntu-1804-clang10-asan', 'amd64-ubuntu-1804-clang6', 'amd64-ubuntu-1804-debug', 'amd64-ubuntu-1804-valgrind', 'amd64-ubuntu-2004', 'amd64-ubuntu-2004-clang11', 'amd64-ubuntu-2010', 'amd64-windows-compile-only', 'ppc64le-centos-7', 'ppc64le-centos-8', 'ppc64le-debian-10', 'ppc64le-debian-9', 'ppc64le-rhel-7', 'ppc64le-rhel-8', 'ppc64le-ubuntu-1804', 'ppc64le-ubuntu-2004-clang1x', 'ppc64le-ubuntu-1804-without-server', 'ppc64le-ubuntu-2004', 'ppc64le-ubuntu-2010', 'x86-debian-9', 'x86-debian-9-bintar-systemd', 'x86-debian-9-bintar-initd', 'amd64-debian-9-bintar-systemd', 'amd64-debian-9-bintar-initd', 'aarch64-centos-7-bintar-systemd', 'aarch64-centos-7-bintar-initd', 'ppc64le-debian-9-bintar-systemd', 'ppc64le-debian-9-bintar-initd']
supportedPlatforms["10.4"] = ['aarch64-centos-7', 'aarch64-centos-8', 'aarch64-debian-10', 'aarch64-debian-9', 'aarch64-rhel-7', 'aarch64-rhel-8', 'aarch64-ubuntu-1804', 'aarch64-ubuntu-2004', 'aarch64-ubuntu-2010', 'amd64-centos-7', 'amd64-centos-8', 'amd64-debian-10', 'amd64-debian-9', 'amd64-fedora-33', 'amd64-opensuse-15', 'amd64-opensuse-42', 'amd64-rhel-7', 'amd64-rhel-8', 'amd64-sles-12', 'amd64-sles-15', 'amd64-ubuntu-1804', 'amd64-ubuntu-1804-clang10', 'amd64-ubuntu-1804-clang10-asan', 'amd64-ubuntu-1804-clang6', 'amd64-ubuntu-1804-debug', 'amd64-ubuntu-1804-valgrind', 'amd64-ubuntu-2004', 'amd64-ubuntu-2004-clang11', 'amd64-ubuntu-2010', 'amd64-windows-compile-only', 'ppc64le-centos-7', 'ppc64le-centos-8', 'ppc64le-debian-10', 'ppc64le-debian-9', 'ppc64le-rhel-7', 'ppc64le-rhel-8', 'ppc64le-ubuntu-1804', 'ppc64le-ubuntu-2004-clang1x', 'ppc64le-ubuntu-1804-without-server', 'ppc64le-ubuntu-2004', 'ppc64le-ubuntu-2010', 'x86-debian-9', 'x86-debian-9-bintar-systemd', 'x86-debian-9-bintar-initd', 'amd64-debian-9-bintar-systemd', 'amd64-debian-9-bintar-initd', 'aarch64-centos-7-bintar-systemd', 'aarch64-centos-7-bintar-initd', 'ppc64le-debian-9-bintar-systemd', 'ppc64le-debian-9-bintar-initd']
supportedPlatforms["10.5"] = ['aarch64-centos-7', 'aarch64-centos-8', 'aarch64-debian-10', 'aarch64-debian-11', 'aarch64-debian-9', 'aarch64-debian-sid', 'aarch64-fedora-33', 'aarch64-fedora-34', 'aarch64-rhel-7', 'aarch64-rhel-8', 'aarch64-ubuntu-1804', 'aarch64-ubuntu-2004', 'aarch64-ubuntu-2010', 'aarch64-ubuntu-2104', 'amd64-centos-7', 'amd64-centos-8', 'amd64-debian-10', 'amd64-debian-11', 'amd64-debian-9', 'amd64-debian-sid', 'amd64-fedora-33', 'amd64-fedora-34', 'amd64-opensuse-15', 'amd64-opensuse-42', 'amd64-rhel-7', 'amd64-rhel-8', 'amd64-sles-12', 'amd64-sles-15', 'amd64-ubuntu-1804', 'amd64-ubuntu-1804-clang10', 'amd64-ubuntu-1804-clang10-asan', 'amd64-ubuntu-1804-clang6', 'amd64-ubuntu-1804-debug', 'amd64-ubuntu-1804-msan', 'amd64-ubuntu-1804-valgrind', 'amd64-ubuntu-2004', 'amd64-ubuntu-2004-clang11', 'amd64-ubuntu-2004-fulltest', 'amd64-ubuntu-2004-gcc10', 'amd64-ubuntu-2004-icc', 'amd64-ubuntu-2010', 'amd64-ubuntu-2104', 'amd64-windows', 'amd64-windows-compile-only', 'amd64-windows-packages', 'ppc64le-centos-7', 'ppc64le-debian-10', 'ppc64le-debian-11', 'ppc64le-debian-9', 'ppc64le-debian-sid', 'ppc64le-rhel-7', 'ppc64le-rhel-8', 'ppc64le-ubuntu-1804', 'ppc64le-ubuntu-2004-clang1x', 'ppc64le-ubuntu-1804-without-server', 'ppc64le-ubuntu-2004', 'ppc64le-ubuntu-2010', 'ppc64le-ubuntu-2104', 'x86-debian-9', 'x86-debian-sid', 'x86-ubuntu-1804', 'x86-windows', 'x86-windows-packages', 'x86-debian-9-bintar-systemd', 'x86-debian-9-bintar-initd', 'amd64-debian-9-bintar-systemd', 'amd64-debian-9-bintar-initd', 'aarch64-centos-7-bintar-systemd', 'aarch64-centos-7-bintar-initd', 'ppc64le-debian-9-bintar-systemd', 'ppc64le-debian-9-bintar-initd', 'aix', 's390x-ubuntu-2004', 's390x-rhel-8']
supportedPlatforms["10.6"] = ['aarch64-centos-7', 'aarch64-centos-8', 'aarch64-debian-10', 'aarch64-debian-11', 'aarch64-debian-9', 'aarch64-debian-sid', 'aarch64-fedora-33', 'aarch64-fedora-34', 'aarch64-rhel-7', 'aarch64-rhel-8', 'aarch64-ubuntu-1804', 'aarch64-ubuntu-2004', 'aarch64-ubuntu-2010', 'aarch64-ubuntu-2104', 'amd64-centos-7', 'amd64-centos-8', 'amd64-debian-10', 'amd64-debian-11', 'amd64-debian-9', 'amd64-debian-sid', 'amd64-fedora-33', 'amd64-fedora-34', 'amd64-opensuse-15', 'amd64-opensuse-42', 'amd64-rhel-7', 'amd64-rhel-8', 'amd64-sles-12', 'amd64-sles-15', 'amd64-ubuntu-1804', 'amd64-ubuntu-1804-clang10', 'amd64-ubuntu-1804-clang10-asan', 'amd64-ubuntu-1804-clang6', 'amd64-ubuntu-1804-debug', 'amd64-ubuntu-1804-msan', 'amd64-ubuntu-1804-valgrind', 'amd64-ubuntu-2004', 'amd64-ubuntu-2004-clang11', 'amd64-ubuntu-2004-fulltest', 'amd64-ubuntu-2004-gcc10', 'amd64-ubuntu-2004-icc', 'amd64-ubuntu-2010', 'amd64-ubuntu-2104', 'amd64-windows', 'amd64-windows-compile-only', 'amd64-windows-packages', 'ppc64le-centos-7', 'ppc64le-debian-10', 'ppc64le-debian-11', 'ppc64le-debian-9', 'ppc64le-debian-sid', 'ppc64le-rhel-7', 'ppc64le-rhel-8', 'ppc64le-ubuntu-1804', 'ppc64le-ubuntu-2004-clang1x', 'ppc64le-ubuntu-1804-without-server', 'ppc64le-ubuntu-2004', 'ppc64le-ubuntu-2010', 'ppc64le-ubuntu-2104', 'x86-debian-9', 'x86-debian-sid', 'x86-ubuntu-1804', 'x86-windows', 'x86-windows-packages', 'x86-debian-9-bintar-systemd', 'x86-debian-9-bintar-initd', 'amd64-debian-9-bintar-systemd', 'amd64-debian-9-bintar-initd', 'aarch64-centos-7-bintar-systemd', 'aarch64-centos-7-bintar-initd', 'ppc64le-debian-9-bintar-systemd', 'ppc64le-debian-9-bintar-initd', 'aix', 's390x-ubuntu-2004', 's390x-rhel-8']
supportedPlatforms["10.7"] = ['aarch64-centos-7', 'aarch64-centos-8', 'aarch64-debian-10', 'aarch64-debian-11', 'aarch64-debian-9', 'aarch64-debian-sid', 'aarch64-fedora-33', 'aarch64-fedora-34', 'aarch64-rhel-7', 'aarch64-rhel-8', 'aarch64-ubuntu-1804', 'aarch64-ubuntu-2004', 'aarch64-ubuntu-2010', 'aarch64-ubuntu-2104', 'amd64-centos-7', 'amd64-centos-8', 'amd64-debian-10', 'amd64-debian-11', 'amd64-debian-9', 'amd64-debian-sid', 'amd64-fedora-33', 'amd64-fedora-34', 'amd64-opensuse-15', 'amd64-opensuse-42', 'amd64-rhel-7', 'amd64-rhel-8', 'amd64-sles-12', 'amd64-sles-15', 'amd64-ubuntu-1804', 'amd64-ubuntu-1804-clang10', 'amd64-ubuntu-1804-clang10-asan', 'amd64-ubuntu-1804-clang6', 'amd64-ubuntu-1804-debug', 'amd64-ubuntu-1804-msan', 'amd64-ubuntu-1804-valgrind', 'amd64-ubuntu-2004', 'amd64-ubuntu-2004-clang11', 'amd64-ubuntu-2004-fulltest', 'amd64-ubuntu-2004-gcc10', 'amd64-ubuntu-2004-icc', 'amd64-ubuntu-2010', 'amd64-ubuntu-2104', 'amd64-windows', 'amd64-windows-compile-only', 'amd64-windows-packages', 'ppc64le-centos-7', 'ppc64le-debian-10', 'ppc64le-debian-11', 'ppc64le-debian-9', 'ppc64le-debian-sid', 'ppc64le-rhel-7', 'ppc64le-rhel-8', 'ppc64le-ubuntu-1804', 'ppc64le-ubuntu-2004-clang1x', 'ppc64le-ubuntu-1804-without-server', 'ppc64le-ubuntu-2004', 'ppc64le-ubuntu-2010', 'ppc64le-ubuntu-2104', 'x86-debian-9', 'x86-debian-sid', 'x86-ubuntu-1804', 'x86-windows', 'x86-windows-packages', 'x86-debian-9-bintar-systemd', 'x86-debian-9-bintar-initd', 'amd64-debian-9-bintar-systemd', 'amd64-debian-9-bintar-initd', 'aarch64-centos-7-bintar-systemd', 'aarch64-centos-7-bintar-initd', 'ppc64le-debian-9-bintar-systemd', 'ppc64le-debian-9-bintar-initd', 'aix', 's390x-ubuntu-2004', 's390x-rhel-8']

# Hack to remove all github_status_builders since they are triggered separately
for k in supportedPlatforms:
    supportedPlatforms[k] = list(filter(lambda x: x not in github_status_builders, supportedPlatforms[k]))

@util.renderer
def getBranchBuilderNames(props):
    mBranch = props.getProperty("master_branch")

    return supportedPlatforms[mBranch]

@util.renderer
def getAutobakeBuilderNames(props):
    builderName = props.getProperty("parentbuildername")
    for b in builders_autobake:
        if builderName in b:
            return [b]
    return []

@util.renderer
def getBigtestBuilderNames(props):
    builderName = str(props.getProperty("parentbuildername"))

    for b in builders_big:
        if builderName in b:
            return [b]
    return []

@util.renderer
def getInstallBuilderNames(props):
    builderName = str(props.getProperty("parentbuildername"))

    for b in builders_install:
        if builderName in b:
            return [b]
    return []

@util.renderer
def getUpgradeBuilderNames(props):
    builderName = str(props.getProperty("parentbuildername"))

    builds = []
    for b in builders_upgrade:
        if builderName in b:
            builds.append(b)
    return builds

@util.renderer
def getEcoBuilderNames(props):
    builderName = str(props.getProperty("parentbuildername"))

    builds = []
    for b in builders_eco:
        if builderName in b:
            builds.append(b)
    return builds

@util.renderer
def getDockerLibraryNames(props):
    return builders_dockerlibrary[0]

def hasAutobake(props):
    builderName = props.getProperty("buildername")
    for b in builders_autobake:
        if builderName in b:
            return True
    return False

def hasBigtest(props):
    builderName = str(props.getProperty("buildername"))

    for b in builders_big:
        if builderName in b:
            return True
    return False

def hasInstall(props):
    builderName = str(props.getProperty("buildername"))

    for b in builders_install:
        if builderName in b:
            return True
    return False

def hasUpgrade(props):
    builderName = str(props.getProperty("buildername"))

    for b in builders_upgrade:
        if builderName in b:
            return True
    return False

def hasEco(props):
    builderName = str(props.getProperty("buildername"))

    for b in builders_eco:
        if builderName in b:
            return True
    return False

def hasDockerLibrary(props):
    branch = str(props.getProperty("master_branch"))
    builderName = str(props.getProperty("buildername"))

    # from https://github.com/MariaDB/mariadb-docker/blob/master/update.sh#L4-L7
    if branch == "10.2":
        dockerbase = "ubuntu-1804-deb-autobake"
    else:
        dockerbase = "ubuntu-2004-deb-autobake"

    # We only build on the above two autobakes for all architectures
    return builderName.endswith(dockerbase)

# git branch filter using fnmatch
import fnmatch
def staging_branch_fn(branch):
    return fnmatch.fnmatch(branch, 'prot-st-*')
def fnmatch_any(s, list_of_patterns):
    return any(fnmatch.fnmatch(s, p) for p in list_of_patterns)

c['schedulers'] = []

c['schedulers'].append(schedulers.Triggerable(name="s_upstream_all",
        builderNames=getBranchBuilderNames))

schedulerProtectedBranches = schedulers.Triggerable(name="s_protected_branches",
        builderNames=github_status_builders)
c['schedulers'].append(schedulerProtectedBranches)

schedulerPackages = schedulers.Triggerable(name="s_packages",
        builderNames=getAutobakeBuilderNames)
c['schedulers'].append(schedulerPackages)

schedulerBigtests = schedulers.Triggerable(name="s_bigtest",
        builderNames=getBigtestBuilderNames)
c['schedulers'].append(schedulerBigtests)

schedulerInstall = schedulers.Triggerable(name="s_install",
        builderNames=getInstallBuilderNames)
c['schedulers'].append(schedulerInstall)

schedulerUpgrade = schedulers.Triggerable(name="s_upgrade",
        builderNames=getUpgradeBuilderNames)
c['schedulers'].append(schedulerUpgrade)

schedulerEco = schedulers.Triggerable(name="s_eco",
        builderNames=getEcoBuilderNames)
c['schedulers'].append(schedulerEco)

schedulerDockerlibrary = schedulers.Triggerable(name="s_dockerlibrary",
        builderNames=getDockerLibraryNames)
c['schedulers'].append(schedulerDockerlibrary)

####### WORKERS

# The 'workers' list defines the set of recognized workers. Each element is
# a Worker object, specifying a unique worker name and password.  The same
# worker name and password must be configured on the worker.
c['workers'] = []

# Normal workers

def mkWorker(name, **kwargs):
    return worker.Worker(name, config["private"]["worker_pass"][name], **kwargs)

hz_bbw2_worker = mkWorker("hz-bbw2-ubuntu1804")
c['workers'].append(hz_bbw2_worker)

# AIX worker
aix_worker = mkWorker("aix-worker", properties={'jobs': 12})
c['workers'].append(aix_worker)

# Docker Library
dockerlibrary_worker = mkWorker("bb-rhel8-docker", properties={'jobs': 1})
c['workers'].append(dockerlibrary_worker)

# s390x RHEL8 worker
s390x_rhel_worker = mkWorker("s390x-rhel8", properties={'jobs': 5})
c['workers'].append(s390x_rhel_worker)

# LibVirt workers
c['workers'].append(worker.LibVirtWorker('buildbot-debian10',
                    config["private"]["worker_pass"]["hz-bbw2-libvirt-debian-10"],
                    util.Connection('qemu+ssh://buildbot@100.64.100.6:65001/session?socket=/run/libvirt/libvirt-sock'),
                    '/var/lib/libvirt/images/buildbot-debian10', build_wait_timeout=0, max_builds=1))

c['workers'].append(worker.LibVirtWorker('buildbot-ubuntu1804',
                    config["private"]["worker_pass"]["hz-bbw2-libvirt-debian-10"],
                    util.Connection('qemu+ssh://buildbot@100.64.100.6:65001/session?socket=/run/libvirt/libvirt-sock'),
                    '/var/lib/libvirt/images/buildbot-ubuntu1804', build_wait_timeout=0, max_builds=1))

c['workers'].append(worker.LibVirtWorker('buildbot-centos7',
                    config["private"]["worker_pass"]["hz-bbw2-libvirt-debian-10"],
                    util.Connection('qemu+ssh://buildbot@100.64.100.6:65001/session?socket=/run/libvirt/libvirt-sock'),
                    '/var/lib/libvirt/images/buildbot-centos7', build_wait_timeout=0, max_builds=1))

# Docker workers

## hz-bbw2-docker
c['workers'].append(worker.DockerLatentWorker("hz-bbw2-docker-tarball-debian-10", None,
                    docker_host=config["private"]["docker_workers"]["hz-bbw2-docker"],
                    dockerfile=open("dockerfiles/debian-10.dockerfile").read(),
                    followStartupLogs=True,
                    masterFQDN='buildbot.mariadb.org',
                    hostconfig={ 'shm_size':'1G' },
                    volumes=['/mnt/autofs/master_packages/:/packages'],
                    max_builds=1,
                    build_wait_timeout=0,
                    properties={ 'jobs':4, 'save_packages':True }))

c['workers'].append(worker.DockerLatentWorker("intel-bbw1-docker-tarball-1-debian-10", None,
                    docker_host=config["private"]["docker_workers"]["intel-bbw1-docker"],
                    dockerfile=open("dockerfiles/debian-10.dockerfile").read(),
                    followStartupLogs=True,
                    masterFQDN='100.64.100.1',
                    hostconfig={ 'shm_size':'1G' },
                    volumes=['/mnt/autofs/master_packages/:/packages'],
                    max_builds=1,
                    build_wait_timeout=0,
                    properties={ 'jobs':4, 'save_packages':True }))

c['workers'].append(worker.DockerLatentWorker("intel-bbw1-docker-tarball-2-debian-10", None,
                    docker_host=config["private"]["docker_workers"]["intel-bbw1-docker"],
                    dockerfile=open("dockerfiles/debian-10.dockerfile").read(),
                    followStartupLogs=True,
                    masterFQDN='100.64.100.1',
                    hostconfig={ 'shm_size':'1G' },
                    volumes=['/mnt/autofs/master_packages/:/packages'],
                    max_builds=1,
                    build_wait_timeout=0,
                    properties={ 'jobs':4, 'save_packages':True }))

c['workers'].append(worker.DockerLatentWorker("intel-bbw1-docker-tarball-3-debian-10", None,
                    docker_host=config["private"]["docker_workers"]["intel-bbw1-docker"],
                    dockerfile=open("dockerfiles/debian-10.dockerfile").read(),
                    followStartupLogs=True,
                    masterFQDN='100.64.100.1',
                    hostconfig={ 'shm_size':'1G' },
                    volumes=['/mnt/autofs/master_packages/:/packages'],
                    max_builds=1,
                    build_wait_timeout=0,
                    properties={ 'jobs':4, 'save_packages':True }))

c['workers'].append(worker.DockerLatentWorker("intel-bbw1-docker-tarball-4-debian-10", None,
                    docker_host=config["private"]["docker_workers"]["intel-bbw1-docker"],
                    dockerfile=open("dockerfiles/debian-10.dockerfile").read(),
                    followStartupLogs=True,
                    masterFQDN='100.64.100.1',
                    hostconfig={ 'shm_size':'1G' },
                    volumes=['/mnt/autofs/master_packages/:/packages'],
                    max_builds=1,
                    build_wait_timeout=0,
                    properties={ 'jobs':4, 'save_packages':True }))

c['workers'].append(worker.DockerLatentWorker("intel-bbw1-docker-tarball-5-debian-10", None,
                    docker_host=config["private"]["docker_workers"]["intel-bbw1-docker"],
                    dockerfile=open("dockerfiles/debian-10.dockerfile").read(),
                    followStartupLogs=True,
                    masterFQDN='100.64.100.1',
                    hostconfig={ 'shm_size':'1G' },
                    volumes=['/mnt/autofs/master_packages/:/packages'],
                    max_builds=1,
                    build_wait_timeout=0,
                    properties={ 'jobs':4, 'save_packages':True }))

c['workers'].append(worker.DockerLatentWorker("hz-bbw2-docker-eco-php-ubuntu-2004", None,
                    docker_host=config["private"]["docker_workers"]["hz-bbw2-docker"],
                    dockerfile=open("dockerfiles/eco-php-ubuntu-2004.dockerfile").read(),
                    followStartupLogs=False,
                    masterFQDN='buildbot.mariadb.org',
                    hostconfig={ 'shm_size':'6G' },
                    build_wait_timeout=0,
                    max_builds=1,
                    volumes=['/srv/buildbot/eco/code:/code', '/srv/buildbot/eco/build:/build'],
                    properties={ 'jobs':7, 'save_packages':False }))

c['workers'].append(worker.DockerLatentWorker("hz-bbw2-docker-eco-dbdeployer-ubuntu-2004", None,
                    docker_host=config["private"]["docker_workers"]["hz-bbw2-docker"],
                    dockerfile=open("dockerfiles/eco-dbdeployer-ubuntu-2004.dockerfile").read(),
                    followStartupLogs=False,
                    masterFQDN='buildbot.mariadb.org',
                    hostconfig={ 'shm_size':'6G' },
                    build_wait_timeout=0,
                    max_builds=1,
                    volumes=['/srv/buildbot/eco/dbdeployer:/dbdeployer'],
                    properties={ 'jobs':7, 'save_packages':False }))

c['workers'].append(worker.DockerLatentWorker("hz-bbw2-docker-eco-pymysql-python-3-9-slim-buster", None,
                    docker_host=config["private"]["docker_workers"]["hz-bbw2-docker"],
                    dockerfile=open("dockerfiles/eco-pymysql-python-3-9-slim-buster.dockerfile").read(),
                    followStartupLogs=False,
                    masterFQDN='buildbot.mariadb.org',
                    hostconfig={ 'shm_size':'6G' },
                    build_wait_timeout=0,
                    max_builds=1,
                    volumes=['/srv/buildbot/eco/pymysqlcode:/code'],
                    properties={ 'jobs':7, 'save_packages':False }))

c['workers'].append(worker.DockerLatentWorker("hz-bbw2-docker-eco-mysqljs-nodejs15-buster", None,
                    docker_host=config["private"]["docker_workers"]["hz-bbw2-docker"],
                    dockerfile=open("dockerfiles/eco-mysqljs-nodejs15-buster.dockerfile").read(),
                    followStartupLogs=False,
                    masterFQDN='buildbot.mariadb.org',
                    hostconfig={ 'shm_size':'6G' },
                    build_wait_timeout=0,
                    max_builds=1,
                    volumes=['/srv/buildbot/eco/mysqljscode:/code'],
                    properties={ 'jobs':7, 'save_packages':False }))

workers={}
def addWorker(worker_name_prefix, worker_id, worker_type, dockerfile, jobs=5, save_packages=False, shm_size='15G'):
    worker_name = worker_name_prefix + str(worker_id) + '-docker'
    name = worker_name + worker_type

    i = worker_id
    tls = None
    #if worker_name_prefix.startswith('aarch64'):
    #    tls = docker.tls.TLSConfig(verify=True, ca_cert='/srv/buildbot/tlscerts/ca-arm-bbw' + str(i)+ '.pem', client_cert=('/srv/buildbot/tlscerts/cert-arm-bbw' + str(i) + '.pem', '/srv/buildbot/tlscerts/key-arm-bbw' + str(i) + '.pem'))
    #else:
    #    tls = None

    if worker_name_prefix.startswith('hz'):
        b_name = 'x64-bbw'
    elif worker_name_prefix.startswith('intel'):
        b_name = 'x64-bbw'
    elif worker_name_prefix.startswith('p9'):
        b_name = 'p9-bbw'
    else:
        b_name = worker_name_prefix
    base_name = b_name + '-docker' + worker_type

    if base_name not in workers:
        workers[base_name] = [name]
    else:
        workers[base_name].append(name)

    volumes=['/srv/buildbot/ccache:/mnt/ccache', '/srv/buildbot/packages:/mnt/packages', '/mnt/autofs/master_packages/:/packages']
    # Set master FQDN - for VPN machines it should be 100.64.100.1
    fqdn = 'buildbot.mariadb.org'
    if worker_name_prefix.startswith('intel') or worker_name_prefix.startswith('bg'):
        fqdn = '100.64.100.1'
    if worker_name_prefix.startswith('p9-rhel8'):
        fqdn = '10.103.203.14'
    dockerfile_str = open("dockerfiles/" + dockerfile).read()
    if 'rhel' in worker_type and not 'download' in dockerfile:
        dockerfile_str = dockerfile_str % (config["private"]["rhel_sub"]["user"], config["private"]["rhel_sub"]["password"])
    c['workers'].append(worker.DockerLatentWorker(name, None,
                        docker_host=config["private"]["docker_workers"][worker_name],
                        dockerfile=dockerfile_str,
                        tls=tls,
                        followStartupLogs=False,
                        masterFQDN=fqdn,
                        build_wait_timeout=0,
                        max_builds=1,
                        hostconfig={ 'shm_size':shm_size},
                        volumes=volumes,
                        properties={ 'jobs':jobs, 'save_packages':save_packages }))


for w_name in ['hz-bbw', 'intel-bbw']:
    if w_name.startswith('hz'):
        jobs = 7
    else:
        jobs = 15
    if w_name == 'hz-bbw':
        for i in [2]:
            addWorker(w_name, i, '-debian-9', 'debian-9.dockerfile', jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-debian-9-i386', 'debian-9-i386.dockerfile', jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-debian-sid', 'debian-sid.dockerfile', jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-debian-sid-i386', 'debian-sid-i386.dockerfile', jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-ubuntu-1804', 'ubuntu-1804.dockerfile', jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-sles-12', 'sles-12-download.dockerfile', jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-sles-15', 'sles-15-download.dockerfile', jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-opensuse-42', 'opensuse-42.dockerfile', jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-valgrind-ubuntu-1804', "valgrind-ubuntu-1804.dockerfile", jobs=jobs, save_packages=False)
            addWorker(w_name, i, '-icc-ubuntu-2004', "icc-ubuntu-2004-download.dockerfile", jobs=jobs, save_packages=False)
            addWorker(w_name, i, '-rhel-7', "rhel-7-download.dockerfile", jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-ubuntu-2104', "ubuntu-2104.dockerfile", jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-opensuse-15', 'opensuse-15.dockerfile', jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-clang-ubuntu-1804', "clang-ubuntu-1804.dockerfile", jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-fedora-34', 'fedora-34.dockerfile', jobs=jobs, save_packages=True)
    if w_name == 'intel-bbw':
        addWorker(w_name, 1, '-centos-7', 'centos-7.dockerfile', jobs=jobs, save_packages=True)
        addWorker(w_name, 1, '-debian-10', "debian-10.dockerfile", jobs=jobs, save_packages=True)
        addWorker(w_name, 1, '-debian-11', "debian-11.dockerfile", jobs=jobs, save_packages=True)
        addWorker(w_name, 1, '-fedora-33', 'fedora-33.dockerfile', jobs=jobs, save_packages=True)
        addWorker(w_name, 1, '-rhel-8', "rhel-8.dockerfile", jobs=jobs, save_packages=True)
        addWorker(w_name, 1, '-ubuntu-2004-clang', 'clang-ubuntu-2004.dockerfile', jobs=jobs, save_packages=True)
        addWorker(w_name, 1, '-ubuntu-2004', "ubuntu-2004.dockerfile", jobs=jobs, save_packages=True)

## apexis-bbw1-docker
c['workers'].append(worker.DockerLatentWorker("fjord1-docker-ubuntu-1804", None,
                    docker_host=config["private"]["docker_workers"]["apexis-bbw1-docker"],
                    dockerfile=open("dockerfiles/clang-ubuntu-1804.dockerfile").read(),
                    followStartupLogs=False,
                    masterFQDN='buildbot.mariadb.org',
                    hostconfig={ 'shm_size':'6G' },
                    max_builds=1,
                    volumes=['/opt/mariadb-buildbot/ccache:/mnt/ccache', '/opt/mariadb-buildbot/packages:/mnt/packages'],
                    properties={ 'jobs':7, 'save_packages':False }))

c['workers'].append(worker.DockerLatentWorker("fjord2-docker-ubuntu-1804", None,
                    docker_host=config["private"]["docker_workers"]["apexis-bbw2-docker"],
                    dockerfile=open("dockerfiles/clang-ubuntu-1804.dockerfile").read(),
                    followStartupLogs=False,
                    masterFQDN='buildbot.mariadb.org',
                    hostconfig={ 'shm_size':'6G' },
                    max_builds=1,
                    volumes=['/opt/mariadb-buildbot/ccache:/mnt/ccache', '/opt/mariadb-buildbot/packages:/mnt/packages'],
                    properties={ 'jobs':7, 'save_packages':False }))

## Add Power workers
for w_name in ['p9-rhel8-bbw', 'p9-rhel7-bbw', 'p9-db-bbw']:
    jobs = 12
    addWorker(w_name, 1, '-centos-7', 'ppc-centos-7-download.dockerfile', jobs=jobs, save_packages=True, shm_size='20G')
    addWorker(w_name, 1, '-ubuntu-1804', 'ppc-ubuntu-1804.dockerfile', jobs=jobs, save_packages=True, shm_size='20G')
    addWorker(w_name, 1, '-ubuntu-2004', 'ppc-ubuntu-2004.dockerfile', jobs=jobs, save_packages=True, shm_size='20G')
    addWorker(w_name, 1, '-ubuntu-2104', 'ppc-ubuntu-2104.dockerfile', jobs=jobs, save_packages=True, shm_size='20G')
    addWorker(w_name, 1, '-debian-9', 'ppc-debian-9.dockerfile', jobs=jobs, save_packages=True, shm_size='20G')
    addWorker(w_name, 1, '-debian-10', 'ppc-debian-10.dockerfile', jobs=jobs, save_packages=True, shm_size='20G')
    addWorker(w_name, 1, '-debian-11', 'ppc-debian-11.dockerfile', jobs=jobs, save_packages=True, shm_size='20G')
    addWorker(w_name, 1, '-debian-sid', 'ppc-debian-sid.dockerfile', jobs=jobs, save_packages=True, shm_size='20G')
    addWorker(w_name, 1, '-clang-ubuntu-2004', 'ppc-clang-ubuntu-2004.dockerfile', jobs=jobs, save_packages=True, shm_size='20G')
    addWorker(w_name, 1, '-rhel-7', 'ppc-rhel-7-download.dockerfile', jobs=jobs, save_packages=True, shm_size='20G')
    addWorker(w_name, 1, '-rhel-8', 'ppc-rhel-8-download.dockerfile', jobs=jobs, save_packages=True, shm_size='20G')

## bg-bbw-docker
for i in range(1,6):
    if i == 1:
        jobs = 5
    else:
        jobs = 3

    addWorker('bg-bbw', i, '-clang-ubuntu-1804', "clang-ubuntu-1804.dockerfile", jobs=jobs, save_packages=True)
    addWorker('bg-bbw', i, '-msan-clang-ubuntu-1804', "msan-clang-ubuntu-1804.dockerfile", jobs=jobs, save_packages=False)
    addWorker('bg-bbw', i, '-valgrind-ubuntu-1804', "valgrind-ubuntu-1804.dockerfile", jobs=jobs, save_packages=False)
    addWorker('bg-bbw', i, '-fedora-33', "fedora-33.dockerfile", jobs=jobs, save_packages=True)
    addWorker('bg-bbw', i, '-fedora-34', "fedora-34.dockerfile", jobs=jobs, save_packages=True)
    addWorker('bg-bbw', i, '-opensuse-15', "opensuse-15.dockerfile", jobs=jobs, save_packages=True)
    addWorker('bg-bbw', i, '-centos-8', "centos-8.dockerfile", jobs=jobs, save_packages=True)
    addWorker('bg-bbw', i, '-x86-ubuntu-1804', "ubuntu-1804-i386.dockerfile", jobs=jobs, save_packages=False)
    addWorker('bg-bbw', i, '-ubuntu-2004', "ubuntu-2004.dockerfile", jobs=jobs, save_packages=True)
    addWorker('bg-bbw', i, '-debian-10', "debian-10.dockerfile", jobs=jobs, save_packages=True)
    addWorker('bg-bbw', i, '-rhel-8', "rhel-8.dockerfile", jobs=jobs, save_packages=True)
    addWorker('bg-bbw', i, '-centos-7', "centos-7.dockerfile", jobs=jobs, save_packages=True)
    addWorker('bg-bbw', i, '-sles-12', 'sles-12-download.dockerfile', jobs=jobs, save_packages=True)
    addWorker('bg-bbw', i, '-sles-15', 'sles-15-download.dockerfile', jobs=jobs, save_packages=True)
 
# aarch64-bbw-docker
for i in range(1, 5):
    jobs = 4
    if i == 4:
        addWorker('aarch64-bbw', i, '-debian-10', "aarch64-debian-10.dockerfile", jobs=8, save_packages=True)
        addWorker('aarch64-bbw', i, '-debian-11', "aarch64-debian-11.dockerfile", jobs=8, save_packages=True)
    else:
        addWorker('aarch64-bbw', i, '-debian-10', "aarch64-debian-10.dockerfile", jobs=jobs, save_packages=True)
        addWorker('aarch64-bbw', i, '-ubuntu-1804', "aarch64-ubuntu-1804.dockerfile", jobs=jobs, save_packages=True)
        addWorker('aarch64-bbw', i, '-ubuntu-2104', "aarch64-ubuntu-2104.dockerfile", jobs=jobs, save_packages=True)
        addWorker('aarch64-bbw', i, '-fedora-33', "aarch64-fedora-33.dockerfile", jobs=jobs, save_packages=True)
        addWorker('aarch64-bbw', i, '-fedora-34', "aarch64-fedora-34.dockerfile", jobs=jobs, save_packages=True)
        addWorker('aarch64-bbw', i, '-debian-9', "aarch64-debian-9.dockerfile", jobs=jobs, save_packages=True)
        addWorker('aarch64-bbw', i, '-ubuntu-2004', "aarch64-ubuntu-2004.dockerfile", jobs=jobs, save_packages=True)
        addWorker('aarch64-bbw', i, '-debian-sid', "aarch64-debian-sid.dockerfile", jobs=jobs, save_packages=True)
        addWorker('aarch64-bbw', i, '-rhel-8', "rhel-8.dockerfile", jobs=jobs, save_packages=True)
    if i == 2:
        addWorker('aarch64-bbw', i, '-centos-7', "aarch64-centos-7.dockerfile", jobs=jobs, save_packages=True)
        addWorker('aarch64-bbw', i, '-rhel-7', "aarch64-rhel-7-download.dockerfile", jobs=jobs, save_packages=True)
        addWorker('aarch64-bbw', i, '-centos-8', "aarch64-centos-8.dockerfile", jobs=8, save_packages=True)

addWorker('s390x-bbw', 1, '-ubuntu-2004', "s390x-ubuntu-2004.dockerfile", jobs=8, save_packages=True)

# Small hack to only run protected branches on the dedicated worker
workers['aarch64-bbw-docker-debian-10'].remove('aarch64-bbw4-docker-debian-10')

## windows-bbw1-docker
windows_worker = mkWorker("bbw1-windows", max_builds=1, properties={'jobs': 64, 'save_packages': True})
c['workers'].append(windows_worker)
windows_worker = mkWorker("hz-bbw2-windows", max_builds=1, properties={'jobs': 12, 'save_packages': True})
c['workers'].append(windows_worker)
'''
c['workers'].append(worker.DockerLatentWorker("bbw1-docker-windows-1809", None,
                    docker_host=config["private"]["docker_workers"]["windows-bbw1-docker"],
                    dockerfile=open("dockerfiles/windows-download.dockerfile").read(),
                    tls=docker.tls.TLSConfig(verify=True, ca_cert='/srv/buildbot/tlscerts/ca-win.pem', client_cert=('/srv/buildbot/tlscerts/cert-win.pem', '/srv/buildbot/tlscerts/key-win.pem')),
                    followStartupLogs=True,
                    masterFQDN='100.64.100.1',
                    hostconfig={ 'shm_size':'6G' },
                    max_builds=1,
                    #volumes=['C:\packages:C:\packages'],
                    properties={ 'jobs':2, 'save_packages':True }))

c['workers'].append(worker.DockerLatentWorker("bbw2-docker-windows-1809", None,
                    docker_host=config["private"]["docker_workers"]["windows-bbw2-docker"],
                    dockerfile=open("dockerfiles/windows-download.dockerfile").read(),
                    followStartupLogs=True,
                    masterFQDN='100.64.100.1',
                    hostconfig={ 'shm_size':'6G' },
                    max_builds=1,
                    #volumes=['C:\packages:C:\packages'],
                    properties={ 'jobs':12, 'save_packages':True }))
'''

## bm-bbw1-docker
c['workers'].append(worker.DockerLatentWorker("bm-bbw1-docker-ubuntu-1804", None,
                    docker_host=config["private"]["docker_workers"]["bm-bbw1-docker"],
                    dockerfile=open("dockerfiles/ubuntu-1804.dockerfile").read(),
                    followStartupLogs=False,
                    masterFQDN='buildbot.mariadb.org',
                    hostconfig={ 'shm_size':'20G' },
                    max_builds=1,
                    volumes=['/srv/buildbot/ccache:/mnt/ccache', '/mnt/autofs/master_packages:/packages'],
                    properties={ 'jobs': 2, 'save_packages':False }))

####### BUILDERS

# The 'builders' list defines the Builders, which tell Buildbot how to perform a build:
# what steps, and which workers can execute them.  Note that any particular build will
# only take place on one worker.


# Priority filter based on saved package branches
def nextBuild(bldr, requests):
    for r in requests:
        if fnmatch_any(r.sources[""].branch, releaseBranches):
            return r
    for r in requests:
        if fnmatch_any(r.sources[""].branch, savedPackageBranches):
            return r
    return requests[0]

class FakeBuild(object):
    properties = Properties()

class FakeStep(object):
    build = FakeBuild()

@defer.inlineCallbacks
def shell(command, worker, builder):
    args = {
        'command': command,
        'logEnviron': False,
        'workdir': "/srv/buildbot/worker",
        'want_stdout': False,
        'want_stderr': False,
    }
    cmd = RemoteCommand('shell', args, stdioLogName=None)
    cmd.worker = worker
    yield cmd.run(FakeStep(), worker.conn, builder.name)
    return cmd.rc

@defer.inlineCallbacks
def canStartBuild(builder, wfb, request):
    worker=wfb.worker
    return True
    # check worker load over the last 5 minutes
    rc = yield shell(
        'test "$(cut -d" " -f2 /proc/loadavg | cut -d. -f1)" -le "$(( $(nproc) / 2 ))"',
        worker, builder)
    if rc != 0:
        log.msg('loadavg is too high to take new builds',
                system=repr(worker))
        worker.putInQuarantine()
        return False

    worker.quarantine_timeout = 180
    worker.putInQuarantine()
    worker.resetQuarantine()
    return True

# Save packages for current branch?
def savePackage(step):
    return step.getProperty("save_packages") and
           (fnmatch_any(step.getProperty("branch"), savedPackageBranches) or
           str(step.getProperty("branch")).startswith('preview-') and str(step.getProperty("buildername")).endswith('ubuntu-2004-deb-autobake'))

# ls2list gets the output of ls and returns a list with the files and directories
def ls2list(rc, stdout, stderr):
    lsFilenames = []

    for l in stdout.strip().split('\n'):
        if l != "":
            lsFilenames.append(l.strip())

    return { 'packages' : lsFilenames }

# ls2string gets the output of ls and returns a space delimited string with the files and directories
def ls2string(rc, stdout, stderr):
    lsFilenames = []

    for l in stdout.strip().split('\n'):
        if l != "":
            lsFilenames.append(l.strip())

    return { 'packages' : " ".join(lsFilenames) }

# checks if the list of files is empty
def hasFiles(step):
  if len(step.getProperty("packages")) < 1:
    return False
  else:
    return True

def filterBranch(step):
  if '10.5' in step.getProperty("branch"):
        return False
  if '10.6' in step.getProperty("branch"):
        return False
  return True

# check if branch is a staging branch
def isStagingBranch(step):
  if staging_branch_fn(step.getProperty("branch")):
    return True
  else:
    return False

# returns true if build is succeeding
def ifStagingSucceeding(step):
  if isStagingBranch(step):
    step.setProperty("build_results", step.build.results)
    return step.build.results in ('SUCCESS', 'WARNINGS')
  else:
    return False

# set step's waitForFinish to True if staging branch
def waitIfStaging(step):
  if isStagingBranch(step):
    step.waitForFinish = True
  return True

def downloadSourceTarball():
    return ShellCommand(
             name="fetch_tarball",
             description="fetching source tarball",
             descriptionDone="fetching source tarball...done",
             haltOnFailure=True,
             command=["bash", "-xc", util.Interpolate("""
  d=/mnt/packages/
  f="%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz"
  find $d -type f -mtime +2 -delete -ls
  for i in `seq 1 10`;
  do
    if flock "$d$f" wget -cO "$d$f" "https://ci.mariadb.org/%(prop:tarbuildnum)s/%(prop:mariadb_version)s.tar.gz"; then
        break
    else
        sleep $i
    fi
  done
""")])

def downloadSourceTarballAIX():
    return ShellCommand(
             name="fetch_tarball",
             description="fetching source tarball",
             descriptionDone="fetching source tarball...done",
             haltOnFailure=True,
             command=["bash", "-xc", util.Interpolate("""
  d=/mnt/packages/
  f="%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz"
  find $d -type f -mtime +2 -delete -ls
  for i in `seq 1 10`;
  do
    if wget -cO "$d$f" "https://ci.mariadb.org/%(prop:tarbuildnum)s/%(prop:mariadb_version)s.tar.gz"; then
        break
    else
        sleep $i
    fi
  done
""")])


# curl fails range-bytes download miserably due to https://github.com/curl/curl/issues/1163
# what I tried:
# flock "$d$f" curl --fail -C - -o "$d$f" "https://ci.mariadb.org/%(prop:tarbuildnum)s/%(prop:mariadb_version)s.tar.gz"
# ret=$? ; test $ret -eq 22 || test $ret -eq 0

def moveMTRLogs():
    return """
parallel=$(expr %(kw:jobs)s \* 2)

mkdir -p /buildbot/logs
for ((mtr=0; mtr<=parallel; mtr++)); do
    for mysqld in {1..4}; do
        if [ $mtr = 0 ]; then
            logname="mysqld."$mysqld".err"
            filename="mysql-test/var/log/mysqld."$mysqld".err"
        else
            logname="mysqld."$mysqld".err."$mtr
            filename="mysql-test/var/"$mtr"/log/mysqld."$mysqld".err"
        fi
        if [ -e $filename ]; then
            cp $filename /buildbot/logs/$logname
        fi
    done
done
"""

def getHTMLLogString():
    return """
echo '<!DOCTYPE html>
<html>
<body>' >> /buildbot/mysql_logs.html

echo '<a href="https://ci.mariadb.org/%(prop:tarbuildnum)s/logs/%(prop:buildername)s/">mysqld* log dir</a><br>' >> /buildbot/mysql_logs.html

echo '</body>
</html>' >> /buildbot/mysql_logs.html"""

def downloadDebs():
    return ShellCommand(
              name="fetch_debs",
              description="fetching debs",
              descriptionDone="fetching debs...done",
              haltOnFailure=True,
              command=["sh", "-xc", util.Interpolate("""
  mkdir -p debs/binary debs/source
  wget -r -np -nH --cut-dirs=2 -A *.deb "https://ci.mariadb.org/%(prop:tarbuildnum)s/%(prop:parentbuildername)s/debs/binary/" -P .
""")])

def dpkgDeb():
    return ShellCommand(
            name="dpkg-scanpackages/sources",
            haltOnFailure=True,
            command=["sh", "-xc", util.Interpolate("""
    mkdir -p debs/binary debs/source
    find .. -maxdepth 1 -type f \( -name \*.deb -o -name \*.ddeb \) -exec cp {} debs/binary/ \;
    find .. -maxdepth 1 -type f \( -name \*.dsc -o -name \*.*z \) -exec cp {} debs/source/ \;
    mv ../*buildinfo ../*changes debs/
    cd debs
    ( dpkg-scanpackages binary /dev/null && dpkg-scanpackages --type ddeb binary /dev/null  )| gzip -9c > Packages.gz
    dpkg-scansources source /dev/null | gzip -9c > Sources.gz
    cd ..
    find debs -type f -exec sha256sum {} \; | sort > sha256sums.txt
""")], doStepIf=lambda step: hasFiles(step) and savePackage(step))

def downloadRpms():
    return ShellCommand(
              name="fetch_rpms",
              description="fetching rpms",
              descriptionDone="fetching rpms...done",
              haltOnFailure=True,
              command=["sh", "-xc", util.Interpolate("""
  mkdir -p debs/binary debs/source
  wget -r -np -nH --cut-dirs=2 -A *.rpm "https://ci.mariadb.org/%(prop:tarbuildnum)s/%(prop:parentbuildername)s/rpms/" -P .
""")])


@util.renderer
def mtrJobsMultiplier(props):
    jobs = props.getProperty('jobs', default=20)
    return jobs * 2

@util.renderer
def dockerfile(props):
    worker = props.getProperty('workername')
    return "https://github.com/MariaDB/mariadb.org-tools/tree/master/buildbot.mariadb.org/dockerfiles/" + "-".join(worker.split('-')[-2:]) + '.dockerfile'

@util.renderer
def getArch(props):
    buildername = props.getProperty('buildername')
    return buildername.split('-')[0]

DEVELOPMENT_BRANCH="10.7"
RELEASABLE_BRANCHES="5.5 10.0 10.1 10.2 10.3 10.4 10.5 10.6 bb-5.5-release bb-10.0-release bb-10.1-release bb-10.2-release bb-10.3-release bb-10.4-release bb-10.5-release bb-10.6-release"

def getRpmUpgradeStep():
     return Test(
        name="upgrade",
        haltOnFailure=True,
        description=["testing", "upgrade"],
        descriptionDone=["test", "upgrade"],
        env={'test_mode': util.Property('test_mode'),
             'test_type': util.Property('test_type'),
             'branch':    util.Property('branch'),
             'major_version':  util.Property('major_version'),
             'arch':   util.Property('arch'),
             'distro': util.Property('version_name'),
             'systemdCapability':  util.Property('systemdCapability'),
             'is_main_tree':  util.Property('is_main_tree'),
             'tarbuildnum' : util.Property('buildnumber'),
             'releaseable_branches':  RELEASABLE_BRANCHES,
             'development_branch': DEVELOPMENT_BRANCH
             },
        command=['./rpm-upgrade.sh'])
	
def getRpmInstallStep():
     return Test(
        name="install",
        haltOnFailure=True,
        description=["testing", "install"],
        descriptionDone=["test", "install"],
        env={'branch':    util.Property('branch'),
             'systemdCapability':  util.Property('systemdCapability'),
             'tarbuildnum' : util.Property('buildnumber'),
             'arch':   util.Property('arch')
             },
        command=['./rpm-install.sh'])

def getDebGaleraStep(port):

    def if_run_galera_test(step):
        if step.getProperty("sst_mode") == "off":
            return False
        return True
        if not branch_is_10_1_or_later(step):
            return False
        if step.getProperty("branch") == 'bb-10.2-compatibility':
            return False
        if sst_mode == 'xtrabackup-v2':
            if branch_is_10_3_or_later(step):
                return False # because of "The redo log was created with MariaDB 10.3.6"
            if branch_is_10_2_or_later(step):
                return False # because of MDEV-12289, this might be fixable
            if arch not in ['x86', 'i386', 'amd64', 'x86_64']:
                return False # no xtrabackup for other architectures
            if arch in ['x86', 'i386'] and version_name in ['artful','stretch']:
                return False # no 32-bit debs for ubuntu stable and debian 9
        return True

    return Test(
        name="galera",
        warningPattern="Test warning:.*",
        description=["testing", "galera", "SST"],
        descriptionDone=["galera", "SST"],
        timeout=300,
        logfiles={"daemon": "/var/log/daemon.log", "syslog": "/var/log/syslog", "node1": "/var/lib/node1/node1.err", "node2": "/var/lib/node2/node2.err", "node3": "/var/lib/node3/node3.err", "mysqld.1.err": "/home/buildbot/var/log/mysqld.1.err", "mysqld.2.err": "/home/buildbot/var/log/mysqld.2.err", "mysqld.3.err": "/home/buildbot/var/log/mysqld.3.err", "node1.mariabackup.prepare": "/home/buildbot/mariabackup_logs/node1.mariabackup.prepare.log", "node2.mariabackup.prepare": "/home/buildbot/mariabackup_logs/node2.mariabackup.prepare.log", "node3.mariabackup.prepare": "/home/buildbot/mariabackup_logs/node3.mariabackup.prepare.log", "node1.mariabackup.move": "/home/buildbot/mariabackup_logs/node1.mariabackup.move.log", "node2.mariabackup.move": "/home/buildbot/mariabackup_logs/node2.mariabackup.move.log", "node3.mariabackup.move": "/home/buildbot/mariabackup_logs/node3.mariabackup.move.log", "node1.mariabackup.backup": "/home/buildbot/mariabackup_logs/node1.mariabackup.backup.log", "node2.mariabackup.backup": "/home/buildbot/mariabackup_logs/node2.mariabackup.backup.log", "node4.mariabackup.backup": "/home/buildbot/mariabackup_logs/node4.mariabackup.backup.log"},
        doStepIf=if_run_galera_test,
        env={'version_name':    util.Property('version_name'),
             'sst_mode':  util.Property('sst_mode'),
             'tarbuildnum' : util.Property('buildnumber'),
             'arch':   util.Property('arch')
             },
        command=["./deb-galera.sh"]
    )

def getDebMinorUpgradeStep():
     return Test(
        name="upgrade",
        haltOnFailure=True,
        description=["testing", "upgrade"],
        descriptionDone=["test", "upgrade"],
        env={'test_mode': util.Property('test_mode'),
             'test_type': util.Property('test_type'),
             'branch':    util.Property('branch'),
             'arch':   util.Property('arch'),
             'dist_name': util.Property('dist_name'),
             'version_name': util.Property('version_name'),
             'major_version':  util.Property('major_version'),
             'systemdCapability':  util.Property('systemdCapability'),
             'tarbuildnum' : util.Property('buildnumber'),
             'needsGalera':  util.Property('needsGalera'),
             'releaseable_branches':  RELEASABLE_BRANCHES,
             'development_branch': DEVELOPMENT_BRANCH
             },
        command=['./deb-minor-upgrade.sh'])

def getDebMajorUpgradeStep():
     return Test(
        name="upgrade",
        haltOnFailure=True,
        description=["testing", "upgrade"],
        descriptionDone=["test", "upgrade"],
        env={'test_mode': util.Property('test_mode'),
             'test_type': util.Property('test_type'),
             'branch':    util.Property('branch'),
             'arch':   util.Property('arch'),
             'dist_name': util.Property('dist_name'),
             'version_name': util.Property('version_name'),
             'major_version':  util.Property('major_version'),
             'mariadb_version':  util.Property('mariadb_version'),
             'systemdCapability':  util.Property('systemdCapability'),
             'needsGalera':  util.Property('needsGalera'),
             'tarbuildnum' : util.Property('buildnumber'),
             'releaseable_branches':  RELEASABLE_BRANCHES,
             'development_branch': DEVELOPMENT_BRANCH
             },
        command=['./deb-major-upgrade.sh'])

def getDebInstallStep():
     return Test(
        name="install",
        haltOnFailure=True,
        description=["testing", "install"],
        descriptionDone=["test", "install"],
        env={'test_mode': util.Property('test_mode'),
             'test_type': util.Property('test_type'),
             'branch':    util.Property('branch'),
             'arch':   util.Property('arch'),
             'dist_name': util.Property('dist_name'),
             'version_name': util.Property('version_name'),
             'major_version':  util.Property('major_version'),
             'mariadb_version':  util.Property('mariadb_version'),
             'systemdCapability':  util.Property('systemdCapability'),
             'needsGalera':  util.Property('needsGalera'),
             'tarbuildnum' : util.Property('buildnumber'),
             'releaseable_branches':  RELEASABLE_BRANCHES,
             'development_branch': DEVELOPMENT_BRANCH
             },
        command=['./deb-install.sh'])

def getScript(scriptname):
    return steps.ShellCommand(
      name=f"fetch_{scriptname}",
      command=['sh', '-xc', f"curl https://raw.githubusercontent.com/MariaDB/mariadb.org-tools/master/buildbot.mariadb.org/scripts/{scriptname} -o {scriptname} && chmod a+x {scriptname}"])

####### FACTORY CODE

## f_tarball - create source tarball
f_tarball = util.BuildFactory()
f_tarball.addStep(steps.SetProperty(property="dockerfile", value=util.Interpolate("%(kw:url)s", url=dockerfile), description="dockerfile"))
f_tarball.addStep(steps.ShellCommand(command=["echo", " revision: ", util.Property('revision')]))
f_tarball.addStep(steps.GitHub(
  repourl=util.Property('repository'),
  mode='full',
  method='clobber',
  workdir='build/server',
  shallow=True,
  submodules=True
))
f_tarball.addStep(steps.Compile(command=["cmake","../server"], workdir='build/mkdist', description="cmake"))
f_tarball.addStep(steps.Compile(command=["make", "dist"], workdir='build/mkdist', description="make dist"))
f_tarball.addStep(steps.SetPropertyFromCommand(property="mariadb_version", command="basename mariadb-*.tar.gz .tar.gz", workdir="build/mkdist"))
f_tarball.addStep(steps.SetPropertyFromCommand(property="master_branch", command=util.Interpolate("echo " + "%(prop:mariadb_version)s" + " | cut -d'-' -f 2 | cut -d'.' -f 1,2")))
f_tarball.addStep(steps.ShellCommand(command=util.Interpolate("mkdir -p %(prop:buildnumber)s/logs"), workdir="build/mkdist"))
f_tarball.addStep(steps.ShellCommand(command=util.Interpolate("sha256sum %(prop:mariadb_version)s" + ".tar.gz >> " + " %(prop:buildnumber)s" + "/sha256sums.txt" + " && mv %(prop:mariadb_version)s" +".tar.gz" + " %(prop:buildnumber)s"), workdir="build/mkdist"))
f_tarball.addStep(steps.SetPropertyFromCommand(command="ls -1 *.tar.gz", extract_fn=ls2list, workdir=util.Interpolate("build/mkdist/" + "%(prop:buildnumber)s")))
#f_tarball.addStep(steps.DirectoryUpload(workersrc=util.Interpolate('%(prop:builddir)s' + '/build/mkdist/' + '%(prop:buildnumber)s'),
#    masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:buildnumber)s'), url=util.Interpolate('https://ci.mariadb.org/' + "%(prop:buildnumber)s"), urlText="Download", doStepIf=hasFiles))
f_tarball.addStep(steps.ShellCommand(name='save_packages', haltOnFailure=True, command=util.Interpolate('cp -r ' + '%(prop:builddir)s' + '/build/mkdist/' + '%(prop:buildnumber)s' + ' /packages && sync /packages/' + '%(prop:buildnumber)s')))
f_tarball.addStep(steps.Trigger(schedulerNames=['s_protected_branches'], waitForFinish=False, updateSourceStamp=False, doStepIf=waitIfStaging,
    set_properties={"tarbuildnum" : Property("buildnumber"), "mariadb_version" : Property("mariadb_version"), "master_branch" : Property("master_branch")}))
f_tarball.addStep(steps.Trigger(schedulerNames=['s_upstream_all'], waitForFinish=False, updateSourceStamp=False,
    set_properties={"tarbuildnum" : Property("buildnumber"), "mariadb_version" : Property("mariadb_version"), "master_branch" : Property("master_branch")}))
f_tarball.addStep(steps.SetPropertyFromCommand(command=util.Interpolate("echo " + "prot-" + "%(prop:master_branch)s"), property="master_staging_branch"))
f_tarball.addStep(steps.ShellSequence( commands=[
    util.ShellArg(command="git config --global user.email '" + config["private"]["gh_mdbci"]["email"] + "'"),
    util.ShellArg(command="git config --global user.name '" + config["private"]["gh_mdbci"]["name"] + "'"),
    util.ShellArg(command="git remote set-url origin https://" + config["private"]["gh_mdbci"]["push_access_token"] + ":x-oauth-basic@github.com/cvicentiu/server"),
    util.ShellArg(command=util.Interpolate("git fetch origin %(prop:master_staging_branch)s && git branch %(prop:master_staging_branch)s FETCH_HEAD && git checkout %(prop:master_staging_branch)s && git checkout %(prop:branch)s && git pull --unshallow"), logfile="rebase"),
    util.ShellArg(command=["bash", "-xc", util.Interpolate("if git checkout %(prop:master_staging_branch)s && git merge --ff-only %(prop:branch)s; then git push --set-upstream origin %(prop:master_staging_branch)s; else  if git checkout %(prop:branch)s && [[ $(git --no-pager log --merges %(prop:master_staging_branch)s..%(prop:branch)s | wc -l) -ne 0 ]]; then exit 1; else git rebase %(prop:master_staging_branch)s && git push --force; fi fi")], logfile="rebase")],
    workdir="build/server", haltOnFailure="true", doStepIf=lambda step: isStagingBranch(step)))
#f_tarball.addStep(steps.ShellSequence( commands=[
#    util.ShellArg(command=util.Interpolate("git checkout " + "%(prop:staging_branch)s"), logfile="rebase"),
#    util.ShellArg(command=util.Interpolate("git merge %(prop:branch)s"), logfile="rebase")], workdir="build/server", haltOnFailure="true", doStepIf=ifStagingSucceeding))
f_tarball.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_quick_build
f_quick_build = util.BuildFactory()
f_quick_build.addStep(steps.SetProperty(property="dockerfile", value=util.Interpolate("%(kw:url)s", url=dockerfile), description="dockerfile"))
f_quick_build.addStep(downloadSourceTarball())
f_quick_build.addStep(steps.ShellCommand(command=util.Interpolate("tar -xvzf /mnt/packages/%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz --strip-components=1")))
f_quick_build.addStep(steps.ShellCommand(name="create html log file", command=['bash', '-c', util.Interpolate(getHTMLLogString(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
# build steps
f_quick_build.addStep(steps.Compile(command=
    ["sh", "-c", util.Interpolate("export PATH=/usr/lib/ccache:/usr/lib64/ccache:$PATH && cmake . -DCMAKE_BUILD_TYPE=%(kw:build_type)s -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_C_COMPILER=%(kw:c_compiler)s -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER=%(kw:cxx_compiler)s -DPLUGIN_TOKUDB=NO -DPLUGIN_MROONGA=NO -DPLUGIN_SPIDER=NO -DPLUGIN_OQGRAPH=NO -DPLUGIN_PERFSCHEMA=%(kw:perf_schema)s -DPLUGIN_SPHINX=NO %(kw:additional_args)s && make -j%(kw:jobs)s package", perf_schema=util.Property('perf_schema', default='YES'), build_type=util.Property('build_type', default='RelWithDebInfo'), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'), c_compiler=util.Property('c_compiler', default='gcc'), cxx_compiler=util.Property('cxx_compiler', default='g++'), additional_args=util.Property('additional_args', default='') )], env={'CCACHE_DIR':'/mnt/ccache'}, haltOnFailure="true"))

f_quick_build.addStep(steps.MTR(logfiles={"mysqld*": "/buildbot/mysql_logs.html"}, command=
    ["sh", "-c", util.Interpolate("cd mysql-test && exec perl mysql-test-run.pl --verbose-restart --force --retry=3 --max-save-core=1 --max-save-datadir=1 --max-test-fail=20 --mem --parallel=$(expr %(kw:jobs)s \* 2) %(kw:mtr_additional_args)s", mtr_additional_args=util.Property('mtr_additional_args', default=''), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=7200, haltOnFailure="true", parallel=mtrJobsMultiplier, dbpool=mtrDbPool, autoCreateTables=True))
f_quick_build.addStep(steps.ShellCommand(name="move mysqld log files", alwaysRun=True, command=['bash', '-c', util.Interpolate(moveMTRLogs(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
f_quick_build.addStep(steps.DirectoryUpload(name="save mysqld log files", compress="bz2", alwaysRun=True,  workersrc='/buildbot/logs/', masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + '/logs/' + '%(prop:buildername)s' )))
## trigger packages
f_quick_build.addStep(steps.Trigger(schedulerNames=['s_packages'], waitForFinish=False, updateSourceStamp=False, alwaysRun=True,
    set_properties={"parentbuildername": Property('buildername'), "tarbuildnum" : Property("tarbuildnum"), "mariadb_version" : Property("mariadb_version"), "master_branch" : Property("master_branch")}, doStepIf=hasAutobake))
## trigger bigtest
f_quick_build.addStep(steps.Trigger(schedulerNames=['s_bigtest'], waitForFinish=False, updateSourceStamp=False,
    set_properties={"parentbuildername": Property('buildername'), "tarbuildnum" : Property("tarbuildnum"), "mariadb_version" : Property("mariadb_version"), "master_branch" : Property("master_branch")}, doStepIf=hasBigtest))
# create package and upload to master
f_quick_build.addStep(steps.SetPropertyFromCommand(command="basename mariadb-*-linux-*.tar.gz", property="mariadb_binary", doStepIf=savePackage))
f_quick_build.addStep(steps.ShellCommand(name='save_packages', timeout=7200, haltOnFailure=True, command=util.Interpolate('mkdir -p ' + '/packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s'+ ' && sha256sum %(prop:mariadb_binary)s >> sha256sums.txt  && cp ' + '%(prop:mariadb_binary)s sha256sums.txt' + ' /packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s' + '/' +  ' && sync /packages/' + '%(prop:tarbuildnum)s'), doStepIf=savePackage))
f_quick_build.addStep(steps.Trigger(name='eco', schedulerNames=['s_eco'], waitForFinish=False, updateSourceStamp=False, set_properties={"parentbuildername": Property("buildername"), "tarbuildnum" : Property("tarbuildnum"), "mariadb_binary": Property("mariadb_binary"), "mariadb_version" : Property("mariadb_version"), "master_branch" : Property("master_branch"), "parentbuildername": Property("buildername")}, doStepIf=lambda step: savePackage(step) and hasEco(step)))
f_quick_build.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_32b_quick_build
f_32b_quick_build = util.BuildFactory()
f_32b_quick_build.addStep(steps.SetProperty(property="dockerfile", value=util.Interpolate("%(kw:url)s", url=dockerfile), description="dockerfile"))
f_32b_quick_build.addStep(downloadSourceTarball())
f_32b_quick_build.addStep(steps.ShellCommand(command=util.Interpolate("tar -xvzf /mnt/packages/%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz --strip-components=1")))
f_32b_quick_build.addStep(steps.ShellCommand(name="create html log file", command=['bash', '-c', util.Interpolate(getHTMLLogString(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
# build steps
f_32b_quick_build.addStep(steps.Compile(command=
    ["sh", "-c", util.Interpolate("export PATH=/usr/lib/ccache:/usr/lib64/ccache:$PATH && cmake . -DCMAKE_SYSTEM_LIBRARY_PATH=/usr/lib/i386-linux-gnu/ -DCMAKE_LIBRARY_PATH=/usr/lib/i386-linux-gnu/ -DCMAKE_FIND_ROOT_PATH=/usr/lib/i386-linux-gnu -DCMAKE_LIBRARY_ARCHITECTURE=i386 -DCMAKE_BUILD_TYPE=RelWithDebInfo -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_C_COMPILER=gcc -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER=g++ -DWITH_EMBEDDED_SERVER=OFF -DWITH_SAFEMALLOC=OFF -DWITH_WSREP=OFF -DPLUGIN_ARCHIVE=NO -DPLUGIN_TOKUDB=NO -DPLUGIN_MROONGA=NO -DPLUGIN_SPIDER=NO -DPLUGIN_OQGRAPH=NO -DPLUGIN_CONNECT=NO -DPLUGIN_SPHINX=NO -DWITH_SSL=bundled -DWITH_ZLIB=system -DCMAKE_C_FLAGS=-m32 -DCMAKE_CXX_FLAGS=-m32 && make -j%(kw:jobs)s package", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)') )], env={'CCACHE_DIR':'/mnt/ccache'}, haltOnFailure="true"))

f_32b_quick_build.addStep(steps.MTR(logfiles={"mysqld*": "/buildbot/mysql_logs.html"}, command=
    ["sh", "-c", util.Interpolate("cd mysql-test && exec perl mysql-test-run.pl --verbose-restart --force --retry=3 --max-save-core=1 --max-save-datadir=1 --max-test-fail=20 --mem --parallel=$(expr %(kw:jobs)s \* 2)", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=7200, haltOnFailure="true", parallel=mtrJobsMultiplier, dbpool=mtrDbPool, autoCreateTables=True))
f_32b_quick_build.addStep(steps.ShellCommand(name="move mysqld log files", alwaysRun=True, command=['bash', '-c', util.Interpolate(moveMTRLogs(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
f_32b_quick_build.addStep(steps.DirectoryUpload(name="save mysqld log files", compress="bz2", alwaysRun=True,  workersrc='/buildbot/logs/', masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + '/logs/' + '%(prop:buildername)s' )))
# create package and upload to master
f_32b_quick_build.addStep(steps.SetPropertyFromCommand(command="basename mariadb-*-linux-*.tar.gz", property="mariadb_binary"))
#f_32b_quick_build.addStep(steps.ShellCommand(name='save_packages', timeout=7200, haltOnFailure=True, command=util.Interpolate('mkdir -p ' + '/packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s'+ ' && sha256sum %(prop:mariadb_binary)s >> sha256sums.txt  && cp ' + '%(prop:mariadb_binary)s sha256sums.txt' + ' /packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s' + '/' +  ' && sync /packages/' + '%(prop:tarbuildnum)s'), doStepIf=savePackage))
f_32b_quick_build.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_asan_build
f_asan_build = util.BuildFactory()
f_asan_build.addStep(steps.SetProperty(property="dockerfile", value=util.Interpolate("%(kw:url)s", url=dockerfile), description="dockerfile"))
f_asan_build.addStep(downloadSourceTarball())
f_asan_build.addStep(steps.ShellCommand(command=util.Interpolate("tar -xvzf /mnt/packages/%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz --strip-components=1")))
f_asan_build.addStep(steps.ShellCommand(name="create html log file", command=['bash', '-c', util.Interpolate(getHTMLLogString(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
# build steps
f_asan_build.addStep(steps.ShellCommand(command='echo "leak:libtasn1\nleak:libgnutls\nleak:libgmp" > mysql-test/lsan.supp', doStepIf=filterBranch))
f_asan_build.addStep(steps.ShellCommand(command='cat mysql-test/lsan.supp', doStepIf=filterBranch))
f_asan_build.addStep(steps.Compile(command=
    ["sh", "-c", util.Interpolate('cmake . -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DCMAKE_C_COMPILER=clang-10 -DCMAKE_CXX_COMPILER=clang++ -DCMAKE_C_FLAGS="-O2 -msse4.2 -Wno-unused-command-line-argument -fdebug-macro -Wno-inconsistent-missing-override" -DCMAKE_CXX_FLAGS="-O2 -msse4.2 -Wno-unused-command-line-argument -fdebug-macro -Wno-inconsistent-missing-override" -DCMAKE_EXPORT_COMPILE_COMMANDS=ON -DCMAKE_BUILD_TYPE=Debug -DWITH_ASAN=YES -DPLUGIN_TOKUDB=NO -DPLUGIN_MROONGA=NO -DPLUGIN_OQGRAPH=NO -DPLUGIN_ROCKSDB=NO -DPLUGIN_CONNECT=NO -DWITH_SAFEMALLOC=OFF -DWITH_ZLIB=bundled -DWITH_SSL=bundled -DWITH_PCRE=system && make -j%(kw:jobs)s package', jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], haltOnFailure="true"))
f_asan_build.addStep(steps.MTR(logfiles={"mysqld*": "/buildbot/mysql_logs.html"}, command=
    ["sh", "-c", util.Interpolate('cd mysql-test && MTR_FEEDBACK_PLUGIN=1 ASAN_OPTIONS="abort_on_error=1" LSAN_OPTIONS="print_suppressions=0,suppressions=`pwd`/lsan.supp" perl mysql-test-run.pl --verbose-restart --force --retry=3 --max-save-core=1 --max-save-datadir=1 --max-test-fail=20 --mem --parallel=$(expr %(kw:jobs)s \* 2)', jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=7200, haltOnFailure="true", parallel=mtrJobsMultiplier, dbpool=mtrDbPool, autoCreateTables=True))
f_asan_build.addStep(steps.ShellCommand(name="move mysqld log files", alwaysRun=True, command=['bash', '-c', util.Interpolate(moveMTRLogs(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
f_asan_build.addStep(steps.DirectoryUpload(name="save mysqld log files", compress="bz2", alwaysRun=True,  workersrc='/buildbot/logs/', masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + '/logs/' + '%(prop:buildername)s' )))
f_asan_build.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_msan_build
f_msan_build = util.BuildFactory()
f_msan_build.addStep(steps.SetProperty(property="dockerfile", value=util.Interpolate("%(kw:url)s", url=dockerfile), description="dockerfile"))
f_msan_build.addStep(steps.ShellCommand(name="create html log file", command=['bash', '-c', util.Interpolate(getHTMLLogString(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
f_msan_build.addStep(downloadSourceTarball())
f_msan_build.addStep(steps.ShellCommand(command=util.Interpolate("tar -xvzf /mnt/packages/%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz --strip-components=1")))
# build steps
f_msan_build.addStep(steps.ShellCommand(command='ls /mariadb/llvm-toolchain-10-10.0.1/libc++msan/lib'))
f_msan_build.addStep(steps.Compile(command=
    ["bash", "-xc", util.Interpolate('cmake -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DCMAKE_C_COMPILER=clang-10 -DCMAKE_CXX_COMPILER=clang++-10 -DCMAKE_C_FLAGS="-O3 -march=native -mtune=native -Wno-unused-command-line-argument -fdebug-macro" -DCMAKE_CXX_FLAGS="-stdlib=libc++ -O3 -march=native -mtune=native -Wno-unused-command-line-argument -fdebug-macro" -DWITH_EMBEDDED_SERVER=OFF -DWITH_UNIT_TESTS=OFF -DCMAKE_BUILD_TYPE=Debug -DHAVE_LIBAIO_H=0 -DCMAKE_DISABLE_FIND_PACKAGE_{URING,LIBAIO}=1 -DWITH_INNODB_BZIP2=OFF -DWITH_INNODB_LZ4=OFF -DWITH_INNODB_LZMA=OFF -DWITH_INNODB_LZO=OFF -DWITH_INNODB_SNAPPY=OFF -DPLUGIN_ARCHIVE=NO -DPLUGIN_TOKUDB=NO -DPLUGIN_MROONGA=NO -DPLUGIN_OQGRAPH=NO -DPLUGIN_ROCKSDB=NO -DPLUGIN_CONNECT=NO -DPLUGIN_SPIDER=NO -DWITH_SAFEMALLOC=OFF -DWITH_ZLIB=bundled -DWITH_SSL=bundled -DWITH_PCRE=bundled -DWITH_MSAN=ON -DWITH_DBUG_TRACE=OFF && make -j%(kw:jobs)s package', jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], haltOnFailure="true"))
f_msan_build.addStep(steps.MTR(logfiles={"mysqld*": "/buildbot/mysql_logs.html"}, command=
    ["bash", "-xc", util.Interpolate('cd mysql-test && LD_LIBRARY_PATH=/mariadb/llvm-toolchain-10-10.0.1/libc++msan/lib MSAN_OPTIONS=abort_on_error=1 ./mtr --big-test --force --retry=0 --max-test-fail=40 --parallel=$(expr %(kw:jobs)s \* 2)', jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=7200, haltOnFailure="true", parallel=mtrJobsMultiplier, dbpool=mtrDbPool, autoCreateTables=True))
f_msan_build.addStep(steps.ShellCommand(name="move mysqld log files", alwaysRun=True, command=['bash', '-c', util.Interpolate(moveMTRLogs(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
f_msan_build.addStep(steps.DirectoryUpload(name="save mysqld log files", compress="bz2", alwaysRun=True,  workersrc='/buildbot/logs/', masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + '/logs/' + '%(prop:buildername)s' )))
f_msan_build.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_valgrind_build
f_valgrind_build = util.BuildFactory()
f_valgrind_build.addStep(steps.SetProperty(property="dockerfile", value=util.Interpolate("%(kw:url)s", url=dockerfile), description="dockerfile"))
f_valgrind_build.addStep(steps.ShellCommand(name="create html log file", command=['bash', '-c', util.Interpolate(getHTMLLogString(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
f_valgrind_build.addStep(downloadSourceTarball())
f_valgrind_build.addStep(steps.ShellCommand(command=util.Interpolate("tar -xvzf /mnt/packages/%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz --strip-components=1")))
# build steps
f_valgrind_build.addStep(steps.Compile(command=
    ["sh", "-c", util.Interpolate('cmake . -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DENABLE_ASSEMBLER=1 -DWITH_EXTRA_CHARSETS=complex -DENABLE_THREAD_SAFE_CLIENT=1 -DWITH_BIG_TABLES=1 -DWITH_PLUGIN_ARIA=1 -DWITH_ARIA_TMP_TABLES=1 -DWITH_JEMALLOC=NO=1 -DCMAKE_BUILD_TYPE=Debug -DSECURITY_HARDENED=OFF -DWITH_VALGRIND=1 -DWITH_SSL=bundled -DWITH_MAX=AUTO -DWITH_EMBEDDED_SERVER=1 -DWITH_LIBEVENT=bundled -DPLUGIN_PLUGIN_FILE_KEY_MANAGEMENT=NO -DPLUGIN_ROCKSDB=DYNAMIC -DPLUGIN_TEST_SQL_DISCOVERY=DYNAMIC -DPLUGIN_TOKUDB=NO -DPLUGIN_ROCKSDB=NO -DENABLE_LOCAL_INFILE=1 && make -j%(kw:jobs)s package', jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], haltOnFailure="true"))
f_valgrind_build.addStep(steps.MTR(logfiles={"mysqld*": "/buildbot/mysql_logs.html"}, command=
    ["sh", "-c", util.Interpolate('cd mysql-test && perl mysql-test-run.pl --valgrind="--leak-check=summary --gen-suppressions=yes --num-callers=10" --skip-test=encryption*  --force --retry=0 --max-save-core=1 --max-save-datadir=1 --max-test-fail=20 --parallel=$(expr %(kw:jobs)s \* 2)', jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=7200, haltOnFailure="true", parallel=mtrJobsMultiplier, dbpool=mtrDbPool, autoCreateTables=True))
f_valgrind_build.addStep(steps.ShellCommand(name="move mysqld log files", alwaysRun=True, command=['bash', '-c', util.Interpolate(moveMTRLogs(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
f_valgrind_build.addStep(steps.DirectoryUpload(name="save mysqld log files", compress="bz2", alwaysRun=True,  workersrc='/buildbot/logs/', masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + '/logs/' + '%(prop:buildername)s' )))
f_valgrind_build.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_big_test
f_big_test = util.BuildFactory()
f_big_test.addStep(steps.SetProperty(property="dockerfile", value=util.Interpolate("%(kw:url)s", url=dockerfile), description="dockerfile"))
f_big_test.addStep(steps.ShellCommand(name="create html log file", command=['bash', '-c', util.Interpolate(getHTMLLogString(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
# get the source tarball and extract it
f_big_test.addStep(steps.FileDownload(mastersrc=util.Interpolate("/srv/buildbot/packages/" + "%(prop:tarbuildnum)s" + "/" + "%(prop:mariadb_version)s" + ".tar.gz"),
    workerdest=util.Interpolate("%(prop:mariadb_version)s" + ".tar.gz")))
f_big_test.addStep(steps.ShellCommand(command=util.Interpolate("tar -xvzf " + "%(prop:mariadb_version)s" + ".tar.gz --strip-components=1")))
# build steps
f_big_test.addStep(steps.Compile(command=
    ["sh", "-c", util.Interpolate("export PATH=/usr/lib/ccache:/usr/lib64/ccache:$PATH && cmake . -DCMAKE_BUILD_TYPE=RelWithDebInfo  -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DPLUGIN_ROCKSDB=NO -DPLUGIN_TOKUDB=NO -DPLUGIN_MROONGA=NO -DPLUGIN_SPIDER=NO -DPLUGIN_OQGRAPH=NO -DPLUGIN_SPHINX=NO && make -j%(kw:jobs)s VERBOSE=1 package", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], env={'CCACHE_DIR':'/mnt/ccache'}))
f_big_test.addStep(steps.MTR(logfiles={"mysqld*": "/buildbot/mysql_logs.html"}, command=
    ["sh", "-c", util.Interpolate("cd mysql-test && exec perl mysql-test-run.pl --verbose-restart --force --retry=3 --max-save-core=1 --max-save-datadir=1 --max-test-fail=20 --big --big --mem --parallel=$(expr %(kw:jobs)s \* 2) --skip-test=archive.archive-big", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=10800, dbpool=mtrDbPool, parallel=mtrJobsMultiplier))
f_big_test.addStep(steps.ShellCommand(name="move mysqld log files", alwaysRun=True, command=['bash', '-c', util.Interpolate(moveMTRLogs(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
f_big_test.addStep(steps.DirectoryUpload(name="save mysqld log files", compress="bz2", alwaysRun=True,  workersrc='/buildbot/logs/', masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + '/logs/' + '%(prop:buildername)s' )))
# create package and upload to master
f_big_test.addStep(steps.SetPropertyFromCommand(command="basename mariadb-*-linux-*.tar.gz", property="mariadb_binary"))
#f_big_test.addStep(steps.ShellCommand(name='save_packages', timeout=7200, haltOnFailure=True, command=util.Interpolate('mkdir -p ' + '/packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s'+ ' && sha256sum %(prop:mariadb_binary)s >> sha256sums.txt  && cp ' + '%(prop:mariadb_binary)s sha256sums.txt' + ' /packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s' + '/' +  ' && sync /packages/' + '%(prop:tarbuildnum)s'), doStepIf=savePackage))
f_big_test.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_full_test
f_full_test = util.BuildFactory()
f_full_test.addStep(steps.SetProperty(property="dockerfile", value=util.Interpolate("%(kw:url)s", url=dockerfile), description="dockerfile"))
# get the source tarball and extract it
f_full_test.addStep(steps.FileDownload(mastersrc=util.Interpolate("/srv/buildbot/packages/" + "%(prop:tarbuildnum)s" + "/" + "%(prop:mariadb_version)s" + ".tar.gz"),
    workerdest=util.Interpolate("%(prop:mariadb_version)s" + ".tar.gz")))
f_full_test.addStep(steps.ShellCommand(command=util.Interpolate("tar -xvzf " + "%(prop:mariadb_version)s" + ".tar.gz --strip-components=1")))
# build steps
f_full_test.addStep(steps.Compile(command=
    ["sh", "-c", util.Interpolate("export PATH=/usr/lib/ccache:/usr/lib64/ccache:$PATH && cmake . -DBUILD_CONFIG=mysql_release -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DWITH_SSL=system -DWITH_JEMALLOC=auto -DWITH_EMBEDDED_SERVER=1 -DHAVE_EMBEDDED_PRIVILEGE_CONTROL=1 -DWITH_LIBARCHIVE=ON -Wno-dev && make -j%(kw:jobs)s VERBOSE=1 package", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], env={'CCACHE_DIR':'/mnt/ccache'}))
f_full_test.addStep(steps.MTR(addLogs=True, name="test emb", command=
    ["sh", "-c", util.Interpolate("cd mysql-test && MTR_FEEDBACK_PLUGIN=1 perl mysql-test-run.pl  --verbose-restart --force --retry=3 --max-save-core=0 --max-save-datadir=1 --mem --embedded-server --parallel=$(expr %(kw:jobs)s \* 2)", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=10800, dbpool=mtrDbPool, parallel=mtrJobsMultiplier))
f_full_test.addStep(steps.MTR(addLogs=True, name="test n", command=
    ["sh", "-c", util.Interpolate("cd mysql-test && MTR_FEEDBACK_PLUGIN=1 perl mysql-test-run.pl  --verbose-restart --force --retry=3 --max-save-core=0 --max-save-datadir=1 --mem --parallel=$(expr %(kw:jobs)s \* 2)", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=10800, dbpool=mtrDbPool, parallel=mtrJobsMultiplier))
f_full_test.addStep(steps.MTR(addLogs=True, name="test p", command=
    ["sh", "-c", util.Interpolate("cd mysql-test && MTR_FEEDBACK_PLUGIN=1 perl mysql-test-run.pl  --verbose-restart --force --retry=3 --max-save-core=0 --max-save-datadir=1 --mem --ps-protocol --parallel=$(expr %(kw:jobs)s \* 2)", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=10800, dbpool=mtrDbPool, parallel=mtrJobsMultiplier))
f_full_test.addStep(steps.MTR(addLogs=True, name="test ps-embedded", command=
    ["sh", "-c", util.Interpolate("cd mysql-test && MTR_FEEDBACK_PLUGIN=1 perl mysql-test-run.pl  --verbose-restart --force --retry=3 --max-save-core=0 --max-save-datadir=1 --ps --embedded --mem --parallel=$(expr %(kw:jobs)s \* 2)", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=10800, dbpool=mtrDbPool, parallel=mtrJobsMultiplier))
f_full_test.addStep(steps.MTR(addLogs=True, name="test xtra", command=
    ["sh", "-c", util.Interpolate("cd mysql-test && MTR_FEEDBACK_PLUGIN=1 perl mysql-test-run.pl  --verbose-restart --force --retry=3 --max-save-core=0 --max-save-datadir=1 --mem --suite=funcs_1,funcs_2,stress,jp --big --testcase-timeout=120 --mysqld=--open-files-limit=0 --mysqld=--log-warnings=1 --parallel=$(expr %(kw:jobs)s \* 2)", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=10800, dbpool=mtrDbPool, parallel=mtrJobsMultiplier))
f_full_test.addStep(steps.MTR(addLogs=True, name="test engines", command=
    ["sh", "-c", util.Interpolate("cd mysql-test && MTR_FEEDBACK_PLUGIN=1 perl mysql-test-run.pl  --verbose-restart --force --retry=3 --max-save-core=0 --max-save-datadir=1 --mem --suite=spider,spider/bg,engines/funcs,engines/iuds --big --testcase-timeout=120 --mysqld=--open-files-limit=0 --mysqld=--log-warnings=1 --parallel=$(expr %(kw:jobs)s \* 2)", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=10800, dbpool=mtrDbPool, parallel=mtrJobsMultiplier))
f_full_test.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_deb_autobake
f_deb_autobake = util.BuildFactory()
f_deb_autobake.addStep(steps.SetProperty(property="dockerfile", value=util.Interpolate("%(kw:url)s", url=dockerfile), description="dockerfile"))
f_deb_autobake.addStep(downloadSourceTarball())
f_deb_autobake.addStep(steps.ShellCommand(command=util.Interpolate("tar -xvzf /mnt/packages/%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz --strip-components=1")))
# build steps
f_deb_autobake.addStep(steps.Compile(logfiles={'CMakeCache.txt': './builddir/CMakeCache.txt'}, command=["debian/autobake-deb.sh"],
    env={'CCACHE_DIR':'/mnt/ccache', 'DEB_BUILD_OPTIONS':util.Interpolate('parallel=%(kw:jobs)s', jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))}, description="autobake-deb.sh"))
# upload binaries
f_deb_autobake.addStep(steps.SetPropertyFromCommand(command="find .. -maxdepth 1 -type f", extract_fn=ls2string))
#f_deb_autobake.addStep(steps.MultipleFileUpload(workersrcs=util.Property('packages'),
#    masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s'), mode=0o755, url=util.Interpolate('https://ci.mariadb.org/' + "%(prop:tarbuildnum)s" + "/" + '%(prop:buildername)s' + "/"), doStepIf=lambda step: hasFiles(step) and savePackage(step)))
#f_deb_autobake.addStep(steps.ShellCommand(name='save_packages', haltOnFailure=True, command=util.Interpolate('mkdir -p ' + '/packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s'+ ' && cp ' + '%(prop:packages)s' + ' /packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s' + '/' +  ' && sync /packages/' + '%(prop:tarbuildnum)s'), doStepIf=lambda step: hasFiles(step) and savePackage(step)))
f_deb_autobake.addStep(dpkgDeb())
#f_deb_autobake.addStep(steps.MultipleFileUpload(workersrcs=['debs/Packages.gz', 'debs/Sources.gz'],
#    masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s'), mode=0o755, url=util.Interpolate('https://ci.mariadb.org/' + "%(prop:tarbuildnum)s" + "/" + '%(prop:buildername)s' + "/"), doStepIf=lambda step: hasFiles(step) and savePackage(step)))
f_deb_autobake.addStep(steps.ShellCommand(name='save_packages', timeout=7200, haltOnFailure=True, command=util.Interpolate('mkdir -p ' + '/packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s'+ ' && cp -r debs/ sha256sums.txt /packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s' + '/' +  ' && sync /packages/' + '%(prop:tarbuildnum)s'), doStepIf=lambda step: hasFiles(step) and savePackage(step)))
f_deb_autobake.addStep(steps.Trigger(name='install', schedulerNames=['s_install'], waitForFinish=True, updateSourceStamp=False,
    set_properties={"tarbuildnum" : Property("tarbuildnum"), "mariadb_version" : Property("mariadb_version"), "master_branch" : Property("master_branch"), "parentbuildername": Property("buildername"), "sst_mode": "off"}, doStepIf=lambda step: hasInstall(step) and savePackage(step) and hasFiles(step)))
f_deb_autobake.addStep(steps.Trigger(name='galera-sst-mariabackup', schedulerNames=['s_install'], waitForFinish=True, updateSourceStamp=False,
    set_properties={"tarbuildnum" : Property("tarbuildnum"), "mariadb_version" : Property("mariadb_version"), "master_branch" : Property("master_branch"), "parentbuildername": Property("buildername"), "sst_mode": "mariabackup"}, doStepIf=lambda step: hasInstall(step) and savePackage(step) and hasFiles(step)))
f_deb_autobake.addStep(steps.Trigger(name='galera-sst-mysqldump', schedulerNames=['s_install'], waitForFinish=True, updateSourceStamp=False,
    set_properties={"tarbuildnum" : Property("tarbuildnum"), "mariadb_version" : Property("mariadb_version"), "master_branch" : Property("master_branch"), "parentbuildername": Property("buildername"), "sst_mode": "mysqldump"}, doStepIf=lambda step: hasInstall(step) and savePackage(step) and hasFiles(step)))
f_deb_autobake.addStep(steps.Trigger(name='galera-sst-rsync', schedulerNames=['s_install'], waitForFinish=True, updateSourceStamp=False,
    set_properties={"tarbuildnum" : Property("tarbuildnum"), "mariadb_version" : Property("mariadb_version"), "master_branch" : Property("master_branch"), "parentbuildername": Property("buildername"), "sst_mode": "rsync"}, doStepIf=lambda step: hasInstall(step) and savePackage(step) and hasFiles(step)))
f_deb_autobake.addStep(steps.Trigger(name='major-minor-upgrade', schedulerNames=['s_upgrade'], waitForFinish=True, updateSourceStamp=False,
    set_properties={"tarbuildnum" : Property("tarbuildnum"), "mariadb_version" : Property("mariadb_version"), "master_branch" : Property("master_branch"), "parentbuildername": Property("buildername")}, doStepIf=lambda step: hasUpgrade(step) and savePackage(step) and hasFiles(step)))
f_deb_autobake.addStep(steps.Trigger(name='dockerlibrary', schedulerNames=['s_dockerlibrary'], waitForFinish=False, updateSourceStamp=False,
    set_properties={"tarbuildnum" : Property("tarbuildnum"), "mariadb_version" : Property("mariadb_version"), "master_branch" : Property("master_branch"), "parentbuildername": Property("buildername")}, doStepIf=lambda step: savePackage(step) and hasDockerLibrary(step)))
f_deb_autobake.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_deb_install
f_deb_install = util.BuildFactory()
f_deb_install.addStep(downloadDebs())
f_deb_install.addStep(getScript('deb-install.sh'))
f_deb_install.addStep(getDebInstallStep())
f_deb_install.addStep(getScript('deb-galera.sh'))
f_deb_install.addStep(getDebGaleraStep("2223"))
f_deb_install.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_deb_major_upgrade
f_deb_major_upgrade = util.BuildFactory()
f_deb_major_upgrade.addStep(downloadDebs())
f_deb_major_upgrade.addStep(steps.SetPropertyFromCommand(name="major_version", property="major_version", command=util.Interpolate("sh -c \"echo '%(prop:branch)s' | sed -e \\\"s/.*\\\\(5\\\\.5\\\\|10\\\\.[0-9]\\\\).*/\\\\1/\\\"\"")))
f_deb_major_upgrade.addStep(getScript('deb-major-upgrade.sh'))
f_deb_major_upgrade.addStep(getDebMajorUpgradeStep())
f_deb_major_upgrade.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_deb_minor_upgrade
f_deb_minor_upgrade = util.BuildFactory()
f_deb_minor_upgrade.addStep(downloadDebs())
f_deb_minor_upgrade.addStep(steps.SetPropertyFromCommand(name="major_version", property="major_version", command=util.Interpolate("sh -c \"echo '%(prop:branch)s' | sed -e \\\"s/.*\\\\(5\\\\.5\\\\|10\\\\.[0-9]\\\\).*/\\\\1/\\\"\"")))
f_deb_minor_upgrade.addStep(getScript('deb-minor-upgrade.sh'))
f_deb_minor_upgrade.addStep(getDebMinorUpgradeStep())
f_deb_minor_upgrade.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_rpm_autobake
f_rpm_autobake= util.BuildFactory()
f_rpm_autobake.addStep(steps.SetProperty(property="dockerfile", value=util.Interpolate("%(kw:url)s", url=dockerfile), description="dockerfile"))
f_rpm_autobake.workdir=f_rpm_autobake.workdir + "/padding_for_CPACK_RPM_BUILD_SOURCE_DIRS_PREFIX/"
f_rpm_autobake.addStep(steps.ShellCommand(name='fetch packages for MariaDB-compat', command=["sh", "-c", util.Interpolate('wget -cO ../MariaDB-shared-5.3.%(kw:arch)s.rpm "https://ci.mariadb.org/helper_files/mariadb-shared-5.3-%(kw:arch)s.rpm" && wget -cO ../MariaDB-shared-10.1.%(kw:arch)s.rpm "https://ci.mariadb.org/helper_files/mariadb-shared-10.1-kvm-rpm-%(kw:rpm_type)s-%(kw:arch)s.rpm"', arch=getArch, rpm_type=util.Property('rpm_type'))]))
f_rpm_autobake.addStep(downloadSourceTarball())
f_rpm_autobake.addStep(steps.ShellCommand(command=util.Interpolate("tar -xvzf /mnt/packages/%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz --strip-components=1")))
f_rpm_autobake.addStep(steps.ShellCommand(command="ls .."))
# build steps
f_rpm_autobake.addStep(steps.ShellCommand(logfiles={'CMakeCache.txt': 'CMakeCache.txt'}, name="cmake", command=
    ["sh", "-c", util.Interpolate("export PATH=/usr/lib/ccache:/usr/lib64/ccache:$PATH && cmake . -DBUILD_CONFIG=mysql_release -DRPM=%(kw:rpm_type)s -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER_LAUNCHER=ccache  %(kw:mtr_additional_args)s", mtr_additional_args=util.Property('mtr_additional_args', default=''), rpm_type=util.Property('rpm_type'))], env={'CCACHE_DIR':'/mnt/ccache'}, description="cmake"))
f_rpm_autobake.addStep(steps.Compile(command=
    ["sh", "-xc", util.Interpolate("""
        mkdir -p rpms srpms
        if grep -qw CPACK_RPM_SOURCE_PKG_BUILD_PARAMS CPackSourceConfig.cmake; then
            make package_source
            mv *.src.rpm srpms/
        fi
        export PATH=/usr/lib/ccache:/usr/lib64/ccache:$PATH && make -j %(kw:jobs)s package
    """, jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], env={'CCACHE_DIR':'/mnt/ccache'}, description="make package"))
# list rpm contents
f_rpm_autobake.addStep(steps.ShellCommand(command=
    ['sh', '-c', 'for rpm in *.rpm; do echo $rpm ; rpm -q --qf "[%{FILEMODES:perms} %{FILEUSERNAME} %{FILEGROUPNAME} .%-36{FILENAMES}\n]" $rpm; echo "------------------------------------------------"; done'], description="list rpm contents"))
# upload binaries
f_rpm_autobake.addStep(steps.SetPropertyFromCommand(command="ls -1 *.rpm", extract_fn=ls2string))
f_rpm_autobake.addStep(steps.ShellCommand(command=
    ["bash", "-xc", util.Interpolate("""
        if [ -e MariaDB-shared-10.1.*.rpm ]; then
           rm MariaDB-shared-10.1.*.rpm
        fi
        cp `ls -1 *.rpm` rpms/
        find srpms -type f -exec sha256sum {} \; | sort > sha256sums.txt
        find rpms -type f -exec sha256sum {} \; | sort >> sha256sums.txt
    """)]))
#f_rpm_autobake.addStep(steps.MultipleFileUpload(workersrcs=util.Property('packages'),
#    masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s'), mode=0o755, url=util.Interpolate('https://ci.mariadb.org/' + "%(prop:tarbuildnum)s" + "/" + '%(prop:buildername)s' + "/"), doStepIf=lambda step: hasFiles(step) and savePackage(step)))
f_rpm_autobake.addStep(steps.ShellCommand(name='save_packages', timeout=7200, haltOnFailure=True, command=util.Interpolate('mkdir -p ' + '/packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s'+ ' && cp -r rpms srpms sha256sums.txt' + ' /packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s' + '/' +  ' && sync /packages/' + '%(prop:tarbuildnum)s'), doStepIf=lambda step: hasFiles(step) and savePackage(step)))
f_rpm_autobake.addStep(steps.Trigger(name='install', schedulerNames=['s_install'], waitForFinish=True, updateSourceStamp=False,
    set_properties={"tarbuildnum" : Property("tarbuildnum"), "mariadb_version" : Property("mariadb_version"), "master_branch" : Property("master_branch"), "parentbuildername": Property("buildername")}, doStepIf=lambda step: hasInstall(step) and savePackage(step) and hasFiles(step)))
f_rpm_autobake.addStep(steps.Trigger(name='major-minor-upgrade', schedulerNames=['s_upgrade'], waitForFinish=True, updateSourceStamp=False,
    set_properties={"tarbuildnum" : Property("tarbuildnum"), "mariadb_version" : Property("mariadb_version"), "master_branch" : Property("master_branch"), "parentbuildername": Property("buildername")}, doStepIf=lambda step: hasUpgrade(step) and savePackage(step) and hasFiles(step)))
f_rpm_autobake.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_rpm_install
f_rpm_install = util.BuildFactory()
f_rpm_install.addStep(downloadRpms())
f_rpm_install.addStep(getScript('rpm-install.sh'))
f_rpm_install.addStep(getRpmInstallStep())
f_rpm_install.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_rpm_upgrade
f_rpm_upgrade = util.BuildFactory()
f_rpm_upgrade.addStep(steps.SetPropertyFromCommand(name="major_version", property="major_version", command=util.Interpolate("sh -c \"echo '%(prop:branch)s' | sed -e \\\"s/.*\\\\(5\\\\.5\\\\|10\\\\.[0-9]\\\\).*/\\\\1/\\\"\"")))
f_rpm_upgrade.addStep(downloadRpms())
f_rpm_upgrade.addStep(getScript('rpm-upgrade.sh'))
f_rpm_upgrade.addStep(getRpmUpgradeStep())
f_rpm_upgrade.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_quick_build
f_bintar = util.BuildFactory()
f_bintar.addStep(downloadSourceTarball())
f_bintar.addStep(steps.ShellCommand(command=util.Interpolate("tar -xvzf /mnt/packages/%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz --strip-components=1")))
f_bintar.addStep(steps.ShellCommand(name="create html log file", command=['bash', '-c', util.Interpolate(getHTMLLogString(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
# build steps
f_bintar.addStep(steps.Compile(command=
    ["sh", "-c", util.Interpolate("export PATH=/usr/lib/ccache:/usr/lib64/ccache:$PATH && cmake . -DBUILD_CONFIG=mysql_release -DWITH_READLINE=1 -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER_LAUNCHER=ccache %(kw:additional_args)s  && make -j%(kw:jobs)s package", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'), additional_args=util.Property('additional_args', default=''))], env={'CCACHE_DIR':'/mnt/ccache'}, haltOnFailure="true"))

#f_bintar.addStep(steps.MTR(logfiles={"mysqld*": "/buildbot/mysql_logs.html"}, command=
#    ["sh", "-c", util.Interpolate("cd mysql-test && exec perl mysql-test-run.pl --verbose-restart --force --retry=3 --max-save-core=1 --max-save-datadir=1 --max-test-fail=20 --mem --parallel=$(expr %(kw:jobs)s \* 2)", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=7200, haltOnFailure="true", parallel=mtrJobsMultiplier, dbpool=mtrDbPool, autoCreateTables=True))
#f_bintar.addStep(steps.ShellCommand(name="move mysqld log files", alwaysRun=True, command=['bash', '-c', util.Interpolate(moveMTRLogs(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
#f_bintar.addStep(steps.DirectoryUpload(name="save mysqld log files", compress="bz2", alwaysRun=True,  workersrc='/buildbot/logs/', masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + '/logs/' + '%(prop:buildername)s' )))
# create package and upload to master
f_bintar.addStep(steps.SetPropertyFromCommand(command="basename mariadb-*-linux-*.tar.gz", property="mariadb_binary", doStepIf=savePackage))
f_bintar.addStep(steps.ShellCommand(name='save_packages', timeout=7200, haltOnFailure=True, command=util.Interpolate('mkdir -p ' + '/packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s'+ ' && sha256sum %(prop:mariadb_binary)s >> sha256sums.txt  && cp ' + '%(prop:mariadb_binary)s sha256sums.txt' + ' /packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s' + '/' +  ' && sync /packages/' + '%(prop:tarbuildnum)s'), doStepIf=savePackage))
f_bintar.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_without_server
f_without_server = util.BuildFactory()
f_without_server.addStep(steps.SetProperty(property="dockerfile", value=util.Interpolate("%(kw:url)s", url=dockerfile), description="dockerfile"))
f_without_server.addStep(steps.ShellCommand(command="ls -la"))
f_without_server.addStep(downloadSourceTarball())
f_without_server.addStep(steps.ShellCommand(command="ls -la"))
f_without_server.addStep(steps.ShellCommand(command=util.Interpolate("tar -xvzf /mnt/packages/%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz --strip-components=1")))
f_without_server.addStep(steps.ShellCommand(command="ls -la"))
# build steps
f_without_server.addStep(steps.Compile(command=
    ["sh", "-c", util.Interpolate("export PATH=/usr/lib/ccache:/usr/lib64/ccache:$PATH && cmake . -DCMAKE_BUILD_TYPE=RelWithDebInfo -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_C_COMPILER=%(kw:c_compiler)s -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER=%(kw:cxx_compiler)s -DWITHOUT_SERVER=1 && make -j%(kw:jobs)s package", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'), c_compiler=util.Property('c_compiler', default='gcc'), cxx_compiler=util.Property('cxx_compiler', default='g++'))], env={'CCACHE_DIR':'/mnt/ccache'}, haltOnFailure="true"))
#    ["sh", "-c", util.Interpolate("export PATH=/usr/lib/ccache:/usr/lib64/ccache:$PATH && mkdir -p ../builddir && cd ../builddir && cmake ${OLDPWD} -DCMAKE_BUILD_TYPE=RelWithDebInfo -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_C_COMPILER=%(kw:c_compiler)s -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER=%(kw:cxx_compiler)s -DWITHOUT_SERVER=ON && cmake --build . --parallel %(kw:jobs)s --target package", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'), c_compiler=util.Property('c_compiler', default='gcc'), cxx_compiler=util.Property('cxx_compiler', default='g++'))], env={'CCACHE_DIR':'/mnt/ccache'}, haltOnFailure="true"))
# create package and upload to master
f_without_server.addStep(steps.SetPropertyFromCommand(command="basename mariadb-*-linux-*.tar.gz", property="mariadb_binary"))
#f_without_server.addStep(steps.FileUpload(workersrc=util.Interpolate("%(prop:mariadb_binary)s"), masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + "/" + '%(prop:buildername)s' + "/" + "%(prop:mariadb_binary)s"), mode=0o755, url=util.Interpolate('https://ci.mariadb.org/' + "%(prop:tarbuildnum)s" + "/" + '%(prop:buildername)s' + "/"), urlText="Download", doStepIf=savePackage))
f_without_server.addStep(steps.ShellCommand(name='save_packages', timeout=7200, haltOnFailure=True, command=util.Interpolate('mkdir -p ' + '/packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s'+ ' && sha256sum %(prop:mariadb_binary)s >> sha256sums.txt  && cp ' + '%(prop:mariadb_binary)s sha256sums.txt' + ' /packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s' + '/' +  ' && sync /packages/' + '%(prop:tarbuildnum)s'), doStepIf=savePackage))
f_without_server.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_macos_10_13
'''
f_macos_10_13 = util.BuildFactory()
f_macos_10_13.addStep(steps.Git(repourl=util.Property('repository'), mode='incremental'))
f_macos_10_13.addStep(steps.Compile(command=
    ["sh", "-c", "cmake . -DCMAKE_BUILD_TYPE=RelWithDebInfo -DWITH_ASAN=ON -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl/ -DOPENSSL_LIBRARIES=/usr/local/opt/openssl/lib -DPLUGIN_TOKUDB=NO -DPLUGIN_MROONGA=NO -DPLUGIN_SPIDER=NO -DPLUGIN_OQGRAPH=NO -DPLUGIN_PERFSCHEMA=NO -DPLUGIN_SPHINX=NO && make -j$(getconf _NPROCESSORS_ONLN) VERBOSE=1"]))
f_macos_10_13.addStep(steps.MTR(command=
    ["sh", "-c", "cd mysql-test && exec perl mysql-test-run.pl  --verbose-restart --force --retry=3  --max-save-core=1 --max-save-datadir=1 --parallel=$(getconf _NPROCESSORS_ONLN)"], timeout=7200))
'''

## f_windows
f_windows = util.BuildFactory()
f_windows.addStep(steps.ShellCommand(name="stop_processes", command="taskkill /im mysqltest /f || ver>nul", alwaysRun=True))
f_windows.addStep(steps.ShellCommand(name="unlock_file_handles", command=["dojob", "unlock_handles.bat"], alwaysRun=True))
f_windows.addStep(steps.ShellCommand(name="removedirs", command=["dojob", '"', "powershell", "-command", "Remove-Item", '"$pwd\*"', "-Recurse", "-Force", '"'], alwaysRun=True))
f_windows.addStep(steps.ShellCommand(name="create tmp dir", command="mkdir tmpdir"))
f_windows.addStep(steps.ShellCommand(
             name="fetch_tarball",
             description="fetching source tarball",
             descriptionDone="fetching source tarball...done",
             haltOnFailure=True,
             command=["dojob", '"', "powershell", "-command", "Start-BitsTransfer", "-Source", util.Interpolate("https://ci.mariadb.org/%(prop:tarbuildnum)s/%(prop:mariadb_version)s.tar.gz"), "-Destination", util.Interpolate("%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz"), '"']))
f_windows.addStep(steps.ShellCommand(name="unpack tarball", env={'TMP': util.Interpolate("D:\\Buildbot\\%(prop:buildername)s\\build\\tmpdir"), 'TEMP': util.Interpolate("D:\\Buildbot\\%(prop:buildername)s\\build\\tmpdir")}, command=["dojob", '"', util.Interpolate("tar -xvzf %(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz --strip-components=1"), '"']))
f_windows.addStep(steps.Compile(name="cmake", env={'TMP': util.Interpolate("D:\\Buildbot\\%(prop:buildername)s\\build\\tmpdir"), 'TEMP': util.Interpolate("D:\\Buildbot\\%(prop:buildername)s\\build\\tmpdir")}, command=["dojob", '"', util.Interpolate("C:\VCTools\Common7\Tools\VsDevCmd.bat -arch=%(kw:arch)s && cmake . -A %(kw:arch_cmake)s -DPLUGIN_ROCKSDB=NO -DMYSQL_MAINTAINER_MODE=ERR -Wno-dev", arch=util.Property('arch', default='x64'), arch_cmake=util.Property('arch_cmake', default='x64')), '"']))
f_windows.addStep(steps.Compile(name="compile", env={'TMP': util.Interpolate("D:\\Buildbot\\%(prop:buildername)s\\build\\tmpdir"), 'TEMP': util.Interpolate("D:\\Buildbot\\%(prop:buildername)s\\build\\tmpdir")}, command=["dojob", '"', util.Interpolate("C:\VCTools\Common7\Tools\VsDevCmd.bat -arch=%(kw:arch)s && cmake --build . --verbose --config Debug -- -m", arch=util.Property('arch', default='x64')), '"'], timeout=7200))
f_windows.addStep(steps.MTR(addLogs=True, name="test nm", env={'TMP': util.Interpolate("D:\\Buildbot\\%(prop:buildername)s\\build\\tmpdir"), 'TEMP': util.Interpolate("D:\\Buildbot\\%(prop:buildername)s\\build\\tmpdir")}, command=["dojob", '"', util.Interpolate("C:\VCTools\Common7\Tools\VsDevCmd.bat -arch=%(kw:arch)s && cd mysql-test && perl mysql-test-run.pl --verbose-restart --force --suite-timeout=120 --max-test-fail=10 --retry=3 --suite=vcol,gcol,perfschema,main,innodb,versioning,plugins,mariabackup,roles,auth_gssapi,rocksdb --parallel=%(kw:jobs)s %(kw:mtr_additional_args)s && cd ..", mtr_additional_args=util.Property('mtr_additional_args', default=''), jobs=util.Property('jobs', default=4), arch=util.Property('arch', default='x64')), '"'], timeout=7200, haltOnFailure="true", parallel=mtrJobsMultiplier, dbpool=mtrDbPool, autoCreateTables=True))
f_windows.addStep(steps.MTR(addLogs=True, name="extra", env={'TMP': util.Interpolate("D:\\Buildbot\\%(prop:buildername)s\\build\\tmpdir"), 'TEMP': util.Interpolate("D:\\Buildbot\\%(prop:buildername)s\\build\\tmpdir")}, command=["dojob", '"', util.Interpolate("C:\VCTools\Common7\Tools\VsDevCmd.bat -arch=%(kw:arch)s && cd mysql-test && perl mysql-test-run.pl  --verbose-restart --force  --testcase-timeout=45 --suite-timeout=600  --retry=3 --suites=connect --parallel=%(kw:jobs)s %(kw:mtr_additional_args)s", mtr_additional_args=util.Property('mtr_additional_args', default=''), jobs=util.Property('jobs', default=4), arch=util.Property('arch', default='x64')), '"'], timeout=7200, haltOnFailure="true", parallel=mtrJobsMultiplier, dbpool=mtrDbPool, autoCreateTables=True))
f_windows.addStep(steps.ShellCommand(name="cleanup", command=["dojob", '"', "powershell", "-command", "Remove-Item", '"$pwd\*"', "-Recurse", "-Force", '"'], alwaysRun=True))

## f_windows_compile
f_windows_compile = util.BuildFactory()
f_windows_compile.addStep(steps.SetProperty(property="dockerfile", value=util.Interpolate("%(kw:url)s", url=dockerfile), description="dockerfile"))
f_windows_compile.addStep(steps.ShellCommand(
             name="fetch_tarball",
             description="fetching source tarball",
             descriptionDone="fetching source tarball...done",
             haltOnFailure=True,
             command=["powershell", "-command", "Start-BitsTransfer", "-Source", util.Interpolate("https://ci.mariadb.org/%(prop:tarbuildnum)s/%(prop:mariadb_version)s.tar.gz"), "-Destination", util.Interpolate("%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz")]))
f_windows_compile.addStep(steps.ShellCommand(name="unpack tarball", command=util.Interpolate("tar -xvzf %(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz --strip-components=1")))
f_windows_compile.addStep(steps.Compile(name="cmake", command=util.Interpolate("C:\VCTools\Common7\Tools\VsDevCmd.bat -arch=%(kw:arch)s && cmake . -A %(kw:arch_cmake)s -DPLUGIN_ROCKSDB=NO -DMYSQL_MAINTAINER_MODE=ERR -Wno-dev", arch=util.Property('arch', default='x64'), arch_cmake=util.Property('arch_cmake', default='x64')))) 
f_windows_compile.addStep(steps.Compile(name="compile", command=util.Interpolate("C:\VCTools\Common7\Tools\VsDevCmd.bat -arch=%(kw:arch)s && cmake --build . --config Debug", arch=util.Property('arch', default='x64')), timeout=7200))
f_windows_compile.addStep(steps.ShellCommand(name="cleanup", command=["powershell", "-command", "Remove-Item", '"$pwd\*"', "-Recurse", "-Force"], alwaysRun=True))

## f_windows_msi
f_windows_msi = util.BuildFactory()
f_windows_msi.addStep(steps.ShellCommand(name="stop_processes", command="taskkill /im mysqltest /f || ver>nul", alwaysRun=True))
f_windows_msi.addStep(steps.ShellCommand(name="unlock_file_handles", command=["dojob", "unlock_handles.bat"], alwaysRun=True, workdir=util.Interpolate("D:\\Buildbot\\%(prop:buildername)s")))
f_windows_msi.addStep(steps.ShellCommand(name="removedirs", command=["dojob", '"', "powershell", "-command", "Remove-Item", '"$pwd\*"', "-Recurse", "-Force", '"'], alwaysRun=True))
f_windows_msi.addStep(steps.ShellCommand(name="create tmp dir", command="mkdir tmpdir"))
f_windows_msi.addStep(steps.ShellCommand(
             name="fetch_tarball",
             description="fetching source tarball",
             descriptionDone="fetching source tarball...done",
             haltOnFailure=True,
             command=["dojob", '"', "powershell", "-command", "Start-BitsTransfer", "-Source", util.Interpolate("https://ci.mariadb.org/%(prop:tarbuildnum)s/%(prop:mariadb_version)s.tar.gz"), "-Destination", util.Interpolate("%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz"), '"']))
f_windows_msi.addStep(steps.ShellCommand(name="unpack tarball", command=["dojob", '"', util.Interpolate("tar -xvzf %(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz --strip-components=1"), '"']))
f_windows_msi.addStep(steps.Compile(name="cmake", env={'TMP': util.Interpolate("D:\\Buildbot\\%(prop:buildername)s\\build\\tmpdir"), 'TEMP': util.Interpolate("D:\\Buildbot\\%(prop:buildername)s\\build\\tmpdir")}, command=["dojob", '"', util.Interpolate('C:\VCTools\Common7\Tools\VsDevCmd.bat -arch=%(kw:arch)s && cmake . -G "Visual Studio 16 2019" -A %(kw:arch_cmake)s  -DBUILD_CONFIG=mysql_release -DWITH_THIRD_PARTY=HeidiSQL -DWITH_EMBEDDED_SERVER=0 -DSIGNCODE=ON -DWITH_UNIT_TESTS=0 -DMYSQL_MAINTAINER_MODE=ERR', arch=util.Property('arch', default='x64'), arch_cmake=util.Property('arch_cmake', default='x64')), '"']))
f_windows_msi.addStep(steps.Compile(name="compile", env={'TMP': util.Interpolate("D:\\Buildbot\\%(prop:buildername)s\\build\\tmpdir"), 'TEMP': util.Interpolate("D:\\Buildbot\\%(prop:buildername)s\\build\\tmpdir")}, command=["dojob", '"', util.Interpolate("C:\VCTools\Common7\Tools\VsDevCmd.bat -arch=%(kw:arch)s && cmake --build  .  --verbose --config RelWithDebInfo -- -m", arch=util.Property('arch', default='x64')), '"'], timeout=3600))
f_windows_msi.addStep(steps.Compile(name="package", env={'TMP': util.Interpolate("D:\\Buildbot\\%(prop:buildername)s\\build\\tmpdir"), 'TEMP': util.Interpolate("D:\\Buildbot\\%(prop:buildername)s\\build\\tmpdir")}, command=["dojob", '"', util.Interpolate("C:\VCTools\Common7\Tools\VsDevCmd.bat -arch=%(kw:arch)s && cmake --build  .  --config RelWithDebInfo --target win_package && cmake --build  .  --config RelWithDebInfo --target MSI", arch=util.Property('arch', default='x64')), '"'], timeout=3600))
f_windows_msi.addStep(steps.MTR(addLogs=True, name="test nm", env={'TMP': util.Interpolate("D:\\Buildbot\\%(prop:buildername)s\\build\\tmpdir"), 'TEMP': util.Interpolate("D:\\Buildbot\\%(prop:buildername)s\\build\\tmpdir")}, command=["dojob", '"', util.Interpolate("C:\VCTools\Common7\Tools\VsDevCmd.bat -arch=%(kw:arch)s && cd mysql-test && perl mysql-test-run.pl --verbose-restart --force --suite-timeout=120 --max-test-fail=10 --retry=3 --suite=vcol,gcol,perfschema,main,innodb,versioning,plugins,mariabackup,roles,auth_gssapi,rocksdb --parallel=%(kw:jobs)s %(kw:mtr_additional_args)s && cd ..", mtr_additional_args=util.Property('mtr_additional_args', default=''), jobs=util.Property('jobs', default=4), arch=util.Property('arch', default='x64')), '"'], timeout=7200, haltOnFailure="true", parallel=mtrJobsMultiplier, dbpool=mtrDbPool, autoCreateTables=True))
f_windows_msi.addStep(steps.MTR(addLogs=True, name="extra", env={'TMP': util.Interpolate("D:\\Buildbot\\%(prop:buildername)s\\build\\tmpdir"), 'TEMP': util.Interpolate("D:\\Buildbot\\%(prop:buildername)s\\build\\tmpdir")}, command=["dojob", '"', util.Interpolate("C:\VCTools\Common7\Tools\VsDevCmd.bat -arch=%(kw:arch)s && cd mysql-test && perl mysql-test-run.pl  --verbose-restart --force  --testcase-timeout=45 --suite-timeout=600  --retry=3 --suites=connect --parallel=%(kw:jobs)s %(kw:mtr_additional_args)s", mtr_additional_args=util.Property('mtr_additional_args', default=''), jobs=util.Property('jobs', default=4), arch=util.Property('arch', default='x64')), '"'], timeout=7200, haltOnFailure="true", parallel=mtrJobsMultiplier, dbpool=mtrDbPool, autoCreateTables=True))
# create package and upload to master
f_windows_msi.addStep(steps.ShellCommand(command='dojob "dir"'))
f_windows_msi.addStep(steps.ShellCommand(name="sha256sums", command=["powershell", "-command", 'Get-ChildItem .\* -Include @("*.msi", "*.zip") | Get-FileHash | Select-Object Hash, @{Name="Name";Expression={[System.IO.Path]::GetFileName($_.Path)}} | Format-Table -HideTableHeaders | Out-File sha256sums.txt']))
f_windows_msi.addStep(steps.SetPropertyFromCommand(command=["dojob", '"', 'dir /b *.msi *.zip', '"'], extract_fn=ls2list))
f_windows_msi.addStep(steps.MultipleFileUpload(workersrcs=util.Property("packages"), masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + "/" + '%(prop:buildername)s' + "/"), mode=0o755, url=util.Interpolate('https://ci.mariadb.org/' + "%(prop:tarbuildnum)s" + "/" + '%(prop:buildername)s' + "/"), doStepIf=savePackage))
f_windows_msi.addStep(steps.FileUpload(workersrc="sha256sums.txt", masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + "/" + '%(prop:buildername)s' + "/sha256sums.txt"), mode=0o755, url=util.Interpolate('https://ci.mariadb.org/' + "%(prop:tarbuildnum)s" + "/" + '%(prop:buildername)s' + "/"), doStepIf=savePackage))
f_windows_msi.addStep(steps.ShellCommand(name="cleanup", command=["dojob", '"', "powershell", "-command", "Remove-Item", '"$pwd\*"', "-Recurse", "-Force", '"'], alwaysRun=True))

## f_eco_php
f_eco_php = util.BuildFactory()
f_eco_php.addStep(steps.ShellCommand(
    name="fetch_install_script",
    command=["sh", "-xc", "curl https://raw.githubusercontent.com/MariaDB/mariadb.org-tools/master/buildbot.mariadb.org/dockerfiles/ecofiles/installdb.sh -o /buildbot/installdb.sh && chmod a+x /buildbot/installdb.sh"]))
f_eco_php.addStep(steps.ShellCommand(
    name="fetch_test_script",
    command=["sh", "-xc", "curl https://raw.githubusercontent.com/MariaDB/mariadb.org-tools/master/buildbot.mariadb.org/dockerfiles/ecofiles/test-php.sh -o /buildbot/test-php.sh && chmod a+x /buildbot/test-php.sh"]))
f_eco_php.addStep(steps.ShellCommand(
    name="fetching and installing database",
    command=["sh", "-xc", util.Interpolate("/buildbot/installdb.sh \"https://ci.mariadb.org/%(prop:tarbuildnum)s/%(prop:parentbuildername)s/%(prop:mariadb_binary)s\" --plugin-load-add=auth_pam --pam_use_cleartext_plugin")]))
f_eco_php.addStep(steps.ShellCommand(
    name="test PHP-7.1",
    command=["sh", "-xc", "/buildbot/test-php.sh PHP-7.1"]))
f_eco_php.addStep(steps.ShellCommand(
    name="test PHP-8.0",
    command=["sh", "-xc", "/buildbot/test-php.sh PHP-8.0"]))

## f_eco_dbdeployer
f_eco_dbdeployer = util.BuildFactory()
f_eco_dbdeployer.addStep(steps.ShellCommand(
    name="fetch_test_script",
    command=["sh", "-xc", "curl https://raw.githubusercontent.com/MariaDB/mariadb.org-tools/master/buildbot.mariadb.org/dockerfiles/ecofiles/test-dbdeployer.sh -o /buildbot/test-dbdeployer.sh && chmod a+x /buildbot/test-dbdeployer.sh"]))
f_eco_dbdeployer.addStep(steps.ShellCommand(
    name="download if needed latest dbdeployer",
    command=["sh", "-xc", "/buildbot/test-dbdeployer.sh dbdeployerfetch"]))
f_eco_dbdeployer.addStep(steps.ShellCommand(
    name="fetching mariadb tarball",
    command=["sh", "-xc", util.Interpolate("/buildbot/test-dbdeployer.sh init \"https://ci.mariadb.org/%(prop:tarbuildnum)s/%(prop:parentbuildername)s/%(prop:mariadb_binary)s\"")]))
f_eco_dbdeployer.addStep(steps.ShellCommand(
    name="deploy single ma",
    command=["sh", "-xc", util.Interpolate("/buildbot/test-dbdeployer.sh deploy single ma%(prop:mariadb_version)s")]))
f_eco_dbdeployer.addStep(steps.ShellCommand(
    name="deploy replication ma",
    command=["sh", "-xc", util.Interpolate("/buildbot/test-dbdeployer.sh deploy replication ma%(prop:mariadb_version)s")]))
f_eco_dbdeployer.addStep(steps.ShellCommand(
    name="global test",
    command=["sh", "-xc", "/buildbot/test-dbdeployer.sh global test"]))
f_eco_dbdeployer.addStep(steps.ShellCommand(
    name="global replication",
    command=["sh", "-xc", "/buildbot/test-dbdeployer.sh global test-replication"]))

## f_eco_pymysql
f_eco_pymysql = util.BuildFactory()
f_eco_pymysql.addStep(steps.ShellCommand(
    name="fetch_install_script",
    command=["sh", "-xc", "curl https://raw.githubusercontent.com/MariaDB/mariadb.org-tools/master/buildbot.mariadb.org/dockerfiles/ecofiles/installdb.sh -o /buildbot/installdb.sh && chmod a+x /buildbot/installdb.sh"]))
f_eco_pymysql.addStep(steps.ShellCommand(
    name="fetch_test_script",
    command=["sh", "-xc", "curl https://raw.githubusercontent.com/MariaDB/mariadb.org-tools/master/buildbot.mariadb.org/dockerfiles/ecofiles/test-pymysql.sh -o /buildbot/test-pymysql.sh && chmod a+x /buildbot/test-pymysql.sh"]))
f_eco_pymysql.addStep(steps.ShellCommand(
    name="fetching and installing database",
    command=["sh", "-xc", util.Interpolate("/buildbot/installdb.sh \"https://ci.mariadb.org/%(prop:tarbuildnum)s/%(prop:parentbuildername)s/%(prop:mariadb_binary)s\"")]))
f_eco_pymysql.addStep(steps.ShellCommand(
    name="test pymysql-main",
    command=["sh", "-xc", "/buildbot/test-pymysql.sh"]))
f_eco_pymysql.addStep(steps.ShellCommand(
    name="test pymysql-v0.7.11",
    command=["sh", "-xc", "/buildbot/test-pymysql.sh v0.7.11"]))

## f_eco_mysqljs
f_eco_mysqljs = util.BuildFactory()
f_eco_mysqljs.addStep(steps.ShellCommand(
    name="fetch_install_script",
    command=["sh", "-xc", "curl https://raw.githubusercontent.com/MariaDB/mariadb.org-tools/master/buildbot.mariadb.org/dockerfiles/ecofiles/installdb.sh -o /buildbot/installdb.sh && chmod a+x /buildbot/installdb.sh"]))
f_eco_mysqljs.addStep(steps.ShellCommand(
    name="fetch_test_script",
    command=["sh", "-xc", "curl https://raw.githubusercontent.com/MariaDB/mariadb.org-tools/master/buildbot.mariadb.org/dockerfiles/ecofiles/test-mysqljs.sh -o /buildbot/test-mysqljs.sh && chmod a+x /buildbot/test-mysqljs.sh"]))
f_eco_mysqljs.addStep(steps.ShellCommand(
    name="fetching and installing database",
    command=["sh", "-xc", util.Interpolate("/buildbot/installdb.sh \"https://ci.mariadb.org/%(prop:tarbuildnum)s/%(prop:parentbuildername)s/%(prop:mariadb_binary)s\"")]))
f_eco_mysqljs.addStep(steps.ShellCommand(
    name="test mysqljs-master",
    command=["sh", "-xc", "/buildbot/test-mysqljs.sh"]))
f_eco_mysqljs.addStep(steps.ShellCommand(
    name="test mysqljs-v2.18.1",
    command=["sh", "-xc", "/buildbot/test-mysqljs.sh v2.18.1"]))

# f_dockerlibrary
f_dockerlibrary = util.BuildFactory()
f_dockerlibrary.addStep(steps.ShellCommand(
    name="Update Fetch/Test Script",
    command=["sh", "-xc", "curl https://raw.githubusercontent.com/MariaDB/mariadb.org-tools/master/buildbot.mariadb.org/scripts/docker-library-build-and-test.sh -o docker-library-build-and-test.sh && chmod a+x docker-library-build-and-test.sh"]))
f_dockerlibrary.addStep(steps.ShellCommand(
    name="building and test docker library image for MariaDB",
    command=["bash", "-xc", util.Interpolate("./docker-library-build-and-test.sh \"%(prop:tarbuildnum)s\" \"%(prop:mariadb_version)s\" \"%(prop:parentbuildername)s\" \"%(prop:revision)s\" \"%(prop:branch)s\"")]))

## f_aix
f_aix = util.BuildFactory()
f_aix.addStep(downloadSourceTarballAIX())
f_aix.addStep(steps.ShellCommand(command=util.Interpolate("tar -xvzf /mnt/packages/%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz")))
f_aix.addStep(steps.ShellCommand(name="create html log file", command=['bash', '-c', util.Interpolate(getHTMLLogString(), jobs=util.Property('jobs', default='6'))]))
f_aix.addStep(steps.ShellCommand(name="fetch build script", command=['/opt/freeware/bin/curl', '--etag-compare', 'aix-script-tag', '--etag-save', 'aix-script-tag', 'https://raw.githubusercontent.com/MariaDB/mariadb.org-tools/master/buildbot.mariadb.org/scripts/aix-build-and-test.sh', '--output', 'aix-build-and-test.sh']))
# build steps
f_aix.addStep(steps.Compile(command=
    ["sh", "-c", util.Interpolate("chmod a+x ./aix-build-and-test.sh && ./aix-build-and-test.sh build %(prop:mariadb_version)s %(kw:build_type)s %(kw:jobs)s", build_type=util.Property('build_type', default='RelWithDebInfo'))], haltOnFailure="true"))
f_aix.addStep(steps.MTR(logfiles={"mysqld*": "/buildbot/mysql_logs.html"}, command=
    ["sh", "-c", util.Interpolate("./aix-build-and-test.sh test")], timeout=7200, haltOnFailure="true", parallel=mtrJobsMultiplier, dbpool=mtrDbPool, autoCreateTables=True))
f_aix.addStep(steps.ShellCommand(name="move mariadb log files", alwaysRun=True, command=['bash', '-c', util.Interpolate(moveMTRLogs(), jobs=util.Property('jobs', default='24'))]))
f_aix.addStep(steps.DirectoryUpload(name="save mariadb log files", compress="bz2", alwaysRun=True,  workersrc='/buildbot/logs/', masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + '/logs/' + '%(prop:buildername)s' )))
f_aix.addStep(steps.ShellCommand(name="cleanup", command="./aix-build-and-test.sh clean", alwaysRun=True))



####### LOCKS
main_master_lock = util.MasterLock('main_master_lock', maxCount=30)

hz_bbw2_lock = util.MasterLock('hz_bbw2_lock', maxCount=7)
intel_bbw1_lock = util.MasterLock('intel_bbw1_lock', maxCount=18)
p9_rhel8_bbw1_lock = util.MasterLock('p9_rhel8_bbw1_lock', maxCount=4)
p9_rhel7_bbw1_lock = util.MasterLock('p9_rhel7_bbw1_lock', maxCount=2)
p9_db_bbw1_lock = util.MasterLock('p9_db_bbw1_lock', maxCount=5)
aarch_bbw1_lock = util.MasterLock('aarch64_bbw1_lock', maxCount=2)
aarch_bbw2_lock = util.MasterLock('aarch64_bbw2_lock', maxCount=2)
aarch_bbw3_lock = util.MasterLock('aarch64_bbw3_lock', maxCount=2)
aarch_bbw4_lock = util.MasterLock('aarch64_bbw4_lock', maxCount=2)
apexis_bbw1_lock = util.MasterLock('apexis_bbw1_lock', maxCount=1)
apexis_bbw2_lock = util.MasterLock('apexis_bbw2_lock', maxCount=1)
bg_bbw1_lock = util.MasterLock('bg_bbw1_lock', maxCount=3)
bg_bbw2_lock = util.MasterLock('bg_bbw2_lock', maxCount=2)
bg_bbw3_lock = util.MasterLock('bg_bbw3_lock', maxCount=2)
bg_bbw4_lock = util.MasterLock('bg_bbw4_lock', maxCount=2)
bg_bbw5_lock = util.MasterLock('bg_bbw5_lock', maxCount=2)
win_bbw1_lock = util.MasterLock('win_bbw1_lock', maxCount=1)
win_bbw2_lock = util.MasterLock('win_bbw2_lock', maxCount=4)
s390x_bbw1_lock = util.MasterLock('s390x_bbw1_lock', maxCount=1)

@util.renderer
def getLocks(props):
    worker_name = props.getProperty('workername', default=None)
    builder_name = props.getProperty('buildername', default=None)
    assert worker_name is not None
    assert builder_name is not None

    if builder_name in github_status_builders or builder_name in builders_install or builder_name in builders_upgrade:
        locks = []
    else:
        locks = [main_master_lock.access('counting')]

    if 'hz-bbw2-docker' in worker_name:
        locks = locks + [hz_bbw2_lock.access('counting')]
    if 'intel-bbw1-docker' in worker_name:
        locks = locks + [intel_bbw1_lock.access('counting')]
    if 'p9-rhel8-bbw1-docker' in worker_name:
        locks = locks + [p9_rhel8_bbw1_lock.access('counting')]
    if 'p9-rhel7-bbw1-docker' in worker_name:
        locks = locks + [p9_rhel7_bbw1_lock.access('counting')]
    if 'p9-db-bbw1-docker' in worker_name:
        locks = locks + [p9_db_bbw1_lock.access('counting')]
    if 'aarch64-bbw1-docker' in worker_name:
        locks = locks + [aarch_bbw1_lock.access('counting')]
    if 'aarch64-bbw2-docker' in worker_name:
        locks = locks + [aarch_bbw2_lock.access('counting')]
    if 'aarch64-bbw3-docker' in worker_name:
        locks = locks + [aarch_bbw3_lock.access('counting')]
    if 'aarch64-bbw4-docker' in worker_name:
        locks = locks + [aarch_bbw4_lock.access('counting')]
    if 'fjord1-docker' in worker_name:
        locks = locks + [apexis_bbw1_lock.access('counting')]
    if 'fjord2-docker' in worker_name:
        locks = locks + [apexis_bbw2_lock.access('counting')]
    if 'bg-bbw1-docker' in worker_name:
        locks = locks + [bg_bbw1_lock.access('counting')]
    if 'bg-bbw2-docker' in worker_name:
        locks = locks + [bg_bbw2_lock.access('counting')]
    if 'bg-bbw3-docker' in worker_name:
        locks = locks + [bg_bbw3_lock.access('counting')]
    if 'bg-bbw4-docker' in worker_name:
        locks = locks + [bg_bbw4_lock.access('counting')]
    if 'bg-bbw5-docker' in worker_name:
        locks = locks + [bg_bbw5_lock.access('counting')]
    if 'bbw1-docker-windows' in worker_name:
        locks = locks + [win_bbw1_lock.access('counting')]
    if 'bbw2-docker-windows' in worker_name:
        locks = locks + [win_bbw2_lock.access('counting')]
    if 's390x-docker' in worker_name:
        locks = locks + [s390x_bbw1_lock.access('counting')]

    return locks

protected_branches_mtr_additional_args = '--suite=main --skip-test="^stack_crash$|^float$|^derived_split_innodb$|^mysql_client_test$|^kill$|^processlist_not_embedded$|^sp-big$"'

####### BUILDERS LIST
c['builders'] = []

'''
 c['builders'].append(
    util.BuilderConfig(name="macos-10-13",
      workernames=["shinnok-bbw1-macos"],
      factory=f_macos_10_13))
'''

c['builders'].append(
    util.BuilderConfig(name="tarball-docker",
      workernames=["intel-bbw1-docker-tarball-1-debian-10",  "intel-bbw1-docker-tarball-2-debian-10",  "intel-bbw1-docker-tarball-3-debian-10", "intel-bbw1-docker-tarball-4-debian-10", "intel-bbw1-docker-tarball-5-debian-10"],
      tags=["tar", "bake"],
      collapseRequests=True,
      nextBuild=nextBuild,
      factory=f_tarball))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-1804",
      workernames=workers["x64-bbw-docker-ubuntu-1804"],
      tags=["Ubuntu", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-1804-deb-autobake",
      workernames=workers["x64-bbw-docker-ubuntu-1804"],
      tags=["Ubuntu", "deb", "bake", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-1804-deb-autobake-install",
      workernames=["buildbot-ubuntu1804"],
      tags=["Ubuntu", "deb", "install", "kvm"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      properties={'systemdCapability': 'yes', 'needsGalera': 'yes', 'dist_name': 'ubuntu', 'version_name': 'bionic', 'arch': 'amd64'},
      factory=f_deb_install))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-1804-deb-autobake-major-upgrade",
      workernames=["buildbot-ubuntu1804"],
      tags=["Ubuntu", "deb", "upgrade", "kvm"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      properties={'systemdCapability': 'yes', 'needsGalera': 'yes', 'dist_name': 'ubuntu', 'version_name': 'bionic', 'arch': 'amd64', 'test_mode': 'server', "test_type": "major"},
      factory=f_deb_major_upgrade))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-1804-deb-autobake-minor-upgrade",
      workernames=["buildbot-ubuntu1804"],
      tags=["Ubuntu", "deb", "upgrade", "kvm"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      properties={'systemdCapability': 'yes', 'needsGalera': 'yes', 'dist_name': 'ubuntu', 'version_name': 'bionic', 'arch': 'amd64', 'test_mode': 'all', "test_type": "minor"},
      factory=f_deb_minor_upgrade))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-2004",
      workernames=workers["x64-bbw-docker-ubuntu-2004"],
      tags=["Ubuntu", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-2004-clang11",
      workernames=workers["x64-bbw-docker-ubuntu-2004-clang"],
      tags=["Ubuntu", "quick", "clang"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'c_compiler': 'clang-11', 'cxx_compiler': 'clang++', 'mtr_additional_args': protected_branches_mtr_additional_args},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-2004-gcc10",
      workernames=workers["bg-bbw-docker-ubuntu-2004"],
      tags=["Ubuntu", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'c_compiler': 'gcc-10', 'cxx_compiler': 'g++-10'},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-2004-icc",
      workernames=workers["x64-bbw-docker-icc-ubuntu-2004"],
      tags=["Ubuntu", "quick", "icc", "icpc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'c_compiler': 'icc', 'cxx_compiler': 'icpc'},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-2004-deb-autobake",
      workernames=workers["bg-bbw-docker-ubuntu-2004"],
      tags=["Ubuntu", "deb", "bake", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="s390x-ubuntu-2004",
      workernames=workers["s390x-bbw-docker-ubuntu-2004"],
      tags=["Ubuntu", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="s390x-ubuntu-2004-deb-autobake",
      workernames=workers["s390x-bbw-docker-ubuntu-2004"],
      tags=["Ubuntu", "deb", "bake", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="s390x-rhel-8",
      workernames=["s390x-rhel8"],
      tags=["RHEL", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="s390x-rhel-8-rpm-autobake",
      workernames=["s390x-rhel8"],
      tags=["RHEL", "rpm", "bake", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-2104",
      workernames=workers["x64-bbw-docker-ubuntu-2104"],
      tags=["Ubuntu", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-2104-deb-autobake",
      workernames=workers["x64-bbw-docker-ubuntu-2104"],
      tags=["Ubuntu", "deb", "bake", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-2004-eco-php",
      workernames=["hz-bbw2-docker-eco-php-ubuntu-2004"],
      tags=["Ubuntu", "ecosystem", "PHP"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      factory=f_eco_php))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-2004-eco-dbdeployer",
      workernames=["hz-bbw2-docker-eco-dbdeployer-ubuntu-2004"],
      tags=["Ubuntu", "ecosystem", "dbdeployer"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      factory=f_eco_dbdeployer))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-10-eco-pymysql",
      workernames=["hz-bbw2-docker-eco-pymysql-python-3-9-slim-buster"],
      tags=["Debian", "ecosystem", "pymysql"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      factory=f_eco_pymysql))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-10-eco-mysqljs",
      workernames=["hz-bbw2-docker-eco-mysqljs-nodejs15-buster"],
      tags=["Debian", "ecosystem", "mysqljs"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      factory=f_eco_mysqljs))

c['builders'].append(
    util.BuilderConfig(name="amd64-rhel8-dockerlibrary",
      workernames=["bb-rhel8-docker"],
      tags=["RHEL"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      factory=f_dockerlibrary))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-1804-bigtest",
      workernames=["bm-bbw1-docker-ubuntu-1804"],
      tags=["Ubuntu", "big", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      factory=f_big_test))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-9",
      workernames=workers["x64-bbw-docker-debian-9"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-9-deb-autobake",
      workernames=workers["x64-bbw-docker-debian-9"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="x86-debian-9",
      workernames=workers["x64-bbw-docker-debian-9-i386"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="x86-debian-9-deb-autobake",
      workernames=workers["x64-bbw-docker-debian-9-i386"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-10",
      workernames=workers["x64-bbw-docker-debian-10"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'mtr_additional_args': protected_branches_mtr_additional_args},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-10-deb-autobake",
      workernames=workers["bg-bbw-docker-debian-10"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-11",
      workernames=workers["x64-bbw-docker-debian-11"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'mtr_additional_args': protected_branches_mtr_additional_args},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-11-deb-autobake",
      workernames=workers["x64-bbw-docker-debian-11"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-sid",
      workernames=workers["x64-bbw-docker-debian-sid"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-sid-deb-autobake",
      workernames=workers["x64-bbw-docker-debian-sid"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="x86-debian-sid",
      workernames=workers["x64-bbw-docker-debian-sid-i386"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="x86-debian-sid-deb-autobake",
      workernames=workers["x64-bbw-docker-debian-sid-i386"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-rhel-7",
      workernames=workers["x64-bbw-docker-rhel-7"],
      tags=["RHEL", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-rhel-7-rpm-autobake",
      workernames=workers["x64-bbw-docker-rhel-7"],
      tags=["RHEL", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'rhel7'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-rhel-8",
      workernames=workers["x64-bbw-docker-rhel-8"],
      tags=["RHEL", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-rhel-8-rpm-autobake",
      workernames=workers["bg-bbw-docker-rhel-8"],
      tags=["RHEL", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'rhel8'},
      factory=f_rpm_autobake))


c['builders'].append(
    util.BuilderConfig(name="amd64-fedora-33",
      workernames=workers["x64-bbw-docker-fedora-33"],
      tags=["Fedora", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'mtr_additional_args': protected_branches_mtr_additional_args},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-fedora-33-rpm-autobake",
      workernames=workers["bg-bbw-docker-fedora-33"],
      tags=["Fedora", "rpm", "bake", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'fedora33'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-fedora-34",
      workernames=workers["x64-bbw-docker-fedora-34"],
      tags=["Fedora", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-fedora-34-rpm-autobake",
      workernames=workers["bg-bbw-docker-fedora-34"],
      tags=["Fedora", "rpm", "bake", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'fedora34'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-sles-12",
      workernames=workers["x64-bbw-docker-sles-12"],
      tags=["Fedora", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-sles-12-rpm-autobake",
      workernames=workers["x64-bbw-docker-sles-12"],
      tags=["Fedora", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'sles12'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-sles-15",
      workernames=workers["x64-bbw-docker-sles-15"],
      tags=["Fedora", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-sles-15-rpm-autobake",
      workernames=workers["x64-bbw-docker-sles-15"],
      tags=["Fedora", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'sles15'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-centos-7",
      workernames=workers["x64-bbw-docker-centos-7"],
      tags=["Centos", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'mtr_additional_args': protected_branches_mtr_additional_args},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-centos-7-rpm-autobake",
      workernames=workers["bg-bbw-docker-centos-7"],
      tags=["Centos", "rpm", "bake", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'centos7'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-centos-7-rpm-autobake-install",
      workernames=["buildbot-centos7"],
      tags=["Centos", "rpm", "install"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      properties={'systemdCapability': 'yes', 'needsGalera': 'yes', 'version_name': '7', 'arch': 'centos74-amd64'},
      factory=f_rpm_install))

c['builders'].append(
    util.BuilderConfig(name="amd64-centos-7-rpm-autobake-major-upgrade",
      workernames=["buildbot-centos7"],
      tags=["Centos", "rpm", "upgrade"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      properties={'systemdCapability': 'yes', 'needsGalera': 'yes', 'version_name': 'centos7', 'arch': 'amd64', "test_type": "major", "test_mode": "server"},
      factory=f_rpm_upgrade))

c['builders'].append(
    util.BuilderConfig(name="amd64-centos-7-rpm-autobake-minor-upgrade",
      workernames=["buildbot-centos7"],
      tags=["Centos", "rpm", "upgrade"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      properties={'systemdCapability': 'yes', 'needsGalera': 'yes', 'version_name': 'centos7', 'arch': 'amd64', "test_type": "minor", "test_mode": "server"},
      factory=f_rpm_upgrade))


c['builders'].append(
    util.BuilderConfig(name="amd64-centos-8",
      workernames=workers["bg-bbw-docker-centos-8"],
      tags=["Centos", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-centos-8-rpm-autobake",
      workernames=workers["bg-bbw-docker-centos-8"],
      tags=["Centos", "rpm", "bake", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'centos8'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-opensuse-15",
      workernames=workers["x64-bbw-docker-opensuse-15"],
      tags=["OpenSUSE", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-opensuse-15-rpm-autobake",
      workernames=workers["bg-bbw-docker-opensuse-15"],
      tags=["OpenSUSE", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'opensuse15'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-opensuse-42",
      workernames=workers["x64-bbw-docker-opensuse-42"],
      tags=["OpenSUSE", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-opensuse-42-rpm-autobake",
      workernames=workers["x64-bbw-docker-opensuse-42"],
      tags=["OpenSUSE", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'opensuse42'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-2004-fulltest",
      workernames=workers["bg-bbw-docker-ubuntu-2004"],
      tags=["Ubuntu", "full", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_full_test))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-ubuntu-1804",
      workernames=workers["p9-bbw-docker-ubuntu-1804"],
      tags=["Ubuntu", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-ubuntu-1804-deb-autobake",
      workernames=workers["p9-bbw-docker-ubuntu-1804"],
      tags=["Ubuntu", "deb", "bake", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-ubuntu-2004",
      workernames=workers["p9-bbw-docker-ubuntu-2004"],
      tags=["Ubuntu", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-ubuntu-2004-deb-autobake",
      workernames=workers["p9-bbw-docker-ubuntu-2004"],
      tags=["Ubuntu", "deb", "bake", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-ubuntu-2104",
      workernames=workers["p9-bbw-docker-ubuntu-2104"],
      tags=["Ubuntu", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-ubuntu-2104-deb-autobake",
      workernames=workers["p9-bbw-docker-ubuntu-2104"],
      tags=["Ubuntu", "deb", "bake", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-debian-9",
      workernames=workers["p9-bbw-docker-debian-9"],
      tags=["Ubuntu", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-debian-9-deb-autobake",
      workernames=workers["p9-bbw-docker-debian-9"],
      tags=["Ubuntu", "deb", "bake", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-debian-10",
      workernames=workers["p9-bbw-docker-debian-10"],
      tags=["Ubuntu", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-debian-10-deb-autobake",
      workernames=workers["p9-bbw-docker-debian-10"],
      tags=["Ubuntu", "deb", "bake", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-debian-11",
      workernames=workers["p9-bbw-docker-debian-11"],
      tags=["Ubuntu", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-debian-11-deb-autobake",
      workernames=workers["p9-bbw-docker-debian-11"],
      tags=["Ubuntu", "deb", "bake", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-debian-sid",
      workernames=workers["p9-bbw-docker-debian-sid"],
      tags=["Ubuntu", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-debian-sid-deb-autobake",
      workernames=workers["p9-bbw-docker-debian-sid"],
      tags=["Ubuntu", "deb", "bake", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-ubuntu-1804-without-server",
      workernames=workers["p9-bbw-docker-ubuntu-1804"],
      tags=["Ubuntu", "without-server", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_without_server))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-ubuntu-2004-clang1x",
      workernames=workers["p9-bbw-docker-clang-ubuntu-2004"],
      tags=["Ubuntu", "quick", "clang-10", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'c_compiler': 'clang-10', 'cxx_compiler': 'clang++-10', 'additional_args': '-DWITHOUT_ROCKSDB=True -DWITHOUT_CONNECT=True -DCMAKE_C_FLAGS=-Wno-inconsistent-missing-override -DCMAKE_CXX_FLAGS=-Wno-inconsistent-missing-override'},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-rhel-7",
      workernames=workers["p9-bbw-docker-rhel-7"],
      tags=["RHEL", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-rhel-7-rpm-autobake",
      workernames=workers["p9-bbw-docker-rhel-7"],
      tags=["RHEL", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'rhel7'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-rhel-8",
      workernames=workers["p9-bbw-docker-rhel-8"],
      tags=["RHEL", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'mtr_additional_args': protected_branches_mtr_additional_args},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-rhel-8-rpm-autobake",
      workernames=workers["p9-bbw-docker-rhel-8"],
      tags=["RHEL", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'rhel8'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-centos-7",
      workernames=workers["p9-bbw-docker-centos-7"],
      tags=["Centos", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-centos-7-rpm-autobake",
      workernames=workers["p9-bbw-docker-centos-7"],
      tags=["Centos", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'centos7'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-1804-clang6",
      workernames=["fjord1-docker-ubuntu-1804"] + workers["x64-bbw-docker-clang-ubuntu-1804"],
      tags=["Ubuntu", "quick", "clang-6"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'c_compiler': 'clang-6.0', 'cxx_compiler': 'clang++-6.0', 'additional_args': '-DCMAKE_C_FLAGS=-Wno-inconsistent-missing-override -DCMAKE_CXX_FLAGS=-Wno-inconsistent-missing-override'},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-1804-debug",
      workernames=["fjord1-docker-ubuntu-1804"] + workers["x64-bbw-docker-clang-ubuntu-1804"],
      tags=["Ubuntu", "quick", "gcc", "debug"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'build_type': 'Debug'},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-1804-clang10",
      workernames=["fjord2-docker-ubuntu-1804"] + workers["x64-bbw-docker-clang-ubuntu-1804"],
      tags=["Ubuntu", "quick", "clang-10"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'c_compiler': 'clang-10', 'cxx_compiler': 'clang++', 'additional_args': '-DCMAKE_C_FLAGS=-Wno-inconsistent-missing-override -DCMAKE_CXX_FLAGS=-Wno-inconsistent-missing-override'},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-1804-clang10-asan",
      workernames=["fjord2-docker-ubuntu-1804"] + workers["x64-bbw-docker-clang-ubuntu-1804"],
      tags=["Ubuntu", "quick", "clang-10", "asan"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_asan_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-1804-msan",
      workernames=workers["bg-bbw-docker-msan-clang-ubuntu-1804"],
      tags=["Ubuntu", "quick", "clang-10", "msan"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_msan_build))

c['builders'].append(
    util.BuilderConfig(name="x86-ubuntu-1804",
      workernames=workers["bg-bbw-docker-x86-ubuntu-1804"],
      tags=["Ubuntu", "quick", "gcc", "32bit"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_32b_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-1804-valgrind",
      workernames=workers["bg-bbw-docker-valgrind-ubuntu-1804"] + workers['x64-bbw-docker-valgrind-ubuntu-1804'],
      tags=["Ubuntu", "quick", "gcc", "valgrind"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_valgrind_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-ubuntu-1804",
      workernames=workers["aarch64-bbw-docker-ubuntu-1804"],
      tags=["Ubuntu", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-ubuntu-1804-deb-autobake",
      workernames=workers["aarch64-bbw-docker-ubuntu-1804"],
      tags=["Ubuntu", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-ubuntu-2004",
      workernames=workers["aarch64-bbw-docker-ubuntu-2004"],
      tags=["Ubuntu", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-ubuntu-2004-deb-autobake",
      workernames=workers["aarch64-bbw-docker-ubuntu-2004"],
      tags=["Ubuntu", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-ubuntu-2104",
      workernames=workers["aarch64-bbw-docker-ubuntu-2104"],
      tags=["Ubuntu", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-ubuntu-2104-deb-autobake",
      workernames=workers["aarch64-bbw-docker-ubuntu-2104"],
      tags=["Ubuntu", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-fedora-33",
      workernames=workers["aarch64-bbw-docker-fedora-33"],
      tags=["Fedora", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-fedora-33-rpm-autobake",
      workernames=workers["aarch64-bbw-docker-fedora-33"],
      tags=["Fedora", "rpm", "bake", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'fedora33'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-fedora-34",
      workernames=workers["aarch64-bbw-docker-fedora-34"],
      tags=["Fedora", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-fedora-34-rpm-autobake",
      workernames=workers["aarch64-bbw-docker-fedora-34"],
      tags=["Fedora", "rpm", "bake", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'fedora34'},
      factory=f_rpm_autobake))



c['builders'].append(
    util.BuilderConfig(name="aarch64-centos-7",
      workernames=workers["aarch64-bbw-docker-centos-7"],
      tags=["Centos", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-centos-7-rpm-autobake",
      workernames=workers["aarch64-bbw-docker-centos-7"],
      tags=["Centos", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'centos7'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-centos-8",
      workernames=workers["aarch64-bbw-docker-centos-8"],
      tags=["Centos", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-centos-8-rpm-autobake",
      workernames=workers["aarch64-bbw-docker-centos-8"],
      tags=["Centos", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'centos8'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-debian-9",
      workernames=workers["aarch64-bbw-docker-debian-9"],
      tags=["Debian", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-debian-9-deb-autobake",
      workernames=workers["aarch64-bbw-docker-debian-9"],
      tags=["Debian", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-debian-10",
      workernames=["aarch64-bbw4-docker-debian-10"],
      tags=["Debian", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'mtr_additional_args': protected_branches_mtr_additional_args},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-debian-10-deb-autobake",
      workernames=workers["aarch64-bbw-docker-debian-10"],
      tags=["Debian", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-debian-11",
      workernames=["aarch64-bbw4-docker-debian-11"],
      tags=["Debian", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'mtr_additional_args': protected_branches_mtr_additional_args},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-debian-11-deb-autobake",
      workernames=workers["aarch64-bbw-docker-debian-11"],
      tags=["Debian", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-debian-sid",
      workernames=workers["aarch64-bbw-docker-debian-sid"],
      tags=["Debian", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-debian-sid-deb-autobake",
      workernames=workers["aarch64-bbw-docker-debian-sid"],
      tags=["Debian", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-rhel-7",
      workernames=workers["aarch64-bbw-docker-rhel-7"],
      tags=["RHEL", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-rhel-7-rpm-autobake",
      workernames=workers["aarch64-bbw-docker-rhel-7"],
      tags=["RHEL", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'rhel7'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-rhel-8",
      workernames=workers["aarch64-bbw-docker-rhel-8"],
      tags=["RHEL", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-rhel-8-rpm-autobake",
      workernames=workers["aarch64-bbw-docker-rhel-8"],
      tags=["RHEL", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'rhel8', 'mtr_additional_args': '-DPLUGIN_COLUMNSTORE=NO'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="x86-debian-9-bintar-systemd",
      workernames=workers["x64-bbw-docker-debian-9-i386"],
      tags=["Debian", "bintar", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'additional_args': '-DWITH_SYSTEMD=yes'},
      factory=f_bintar))

c['builders'].append(
    util.BuilderConfig(name="x86-debian-9-bintar-initd",
      workernames=workers["x64-bbw-docker-debian-9-i386"],
      tags=["Debian", "bintar", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'additional_args': '-DWITH_SYSTEMD=no'},
      factory=f_bintar))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-9-bintar-systemd",
      workernames=workers["x64-bbw-docker-debian-9"],
      tags=["Debian", "bintar", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'additional_args': '-DWITH_SYSTEMD=yes'},
      factory=f_bintar))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-9-bintar-initd",
      workernames=workers["x64-bbw-docker-debian-9"],
      tags=["Debian", "bintar", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'additional_args': '-DWITH_SYSTEMD=no'},
      factory=f_bintar))

c['builders'].append(
    util.BuilderConfig(name="aarch64-centos-7-bintar-systemd",
      workernames=workers["aarch64-bbw-docker-centos-7"],
      tags=["Debian", "bintar", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'additional_args': '-DWITH_SYSTEMD=yes'},
      factory=f_bintar))

c['builders'].append(
    util.BuilderConfig(name="aarch64-centos-7-bintar-initd",
      workernames=workers["aarch64-bbw-docker-centos-7"],
      tags=["Debian", "bintar", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'additional_args': '-DWITH_SYSTEMD=no'},
      factory=f_bintar))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-debian-9-bintar-systemd",
      workernames=workers["p9-bbw-docker-debian-9"],
      tags=["Ubuntu", "bintar", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'additional_args': '-DWITH_SYSTEMD=yes'},
      factory=f_bintar))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-debian-9-bintar-initd",
      workernames=workers["p9-bbw-docker-debian-9"],
      tags=["Ubuntu", "bintar", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'additional_args': '-DWITH_SYSTEMD=no'},
      factory=f_bintar))

c['builders'].append(
    util.BuilderConfig(name="amd64-windows",
      workernames=["bbw1-windows"],
      tags=["Windows", "quick"],
      collapseRequests=True,
      nextBuild=nextBuild,
      factory=f_windows))

c['builders'].append(
    util.BuilderConfig(name="amd64-windows-compile-only",
      workernames=["hz-bbw2-windows"],
      tags=["Windows", "quick", "compile"],
      collapseRequests=True,
      nextBuild=nextBuild,
      factory=f_windows_compile))

c['builders'].append(
    util.BuilderConfig(name="amd64-windows-packages",
      workernames=["bbw1-windows"],
      tags=["Windows", "packages", "zip"],
      collapseRequests=True,
      nextBuild=nextBuild,
      factory=f_windows_msi))

c['builders'].append(
    util.BuilderConfig(name="x86-windows",
      workernames=["bbw1-windows"],
      tags=["Windows", "quick"],
      collapseRequests=True,
      nextBuild=nextBuild,
      properties={'arch': 'x86', 'arch_cmake': 'Win32'},
      factory=f_windows))

c['builders'].append(
    util.BuilderConfig(name="x86-windows-packages",
      workernames=["bbw1-windows"],
      tags=["Windows", "packages", "zip"],
      collapseRequests=True,
      nextBuild=nextBuild,
      properties={'arch': 'x86', 'arch_cmake': 'Win32'},
      factory=f_windows_msi))

c['builders'].append(
    util.BuilderConfig(name="aix",
      workernames=['aix-worker'],
      tags=["AIX", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      factory=f_aix))

# Add a Janitor configurator that removes old logs
c['configurators'] = [util.JanitorConfigurator(
    logHorizon=timedelta(weeks=6),
    hour=23
)]

c['logEncoding'] = 'utf-8'

c['multiMaster'] = True

c['mq'] = {  # Need to enable multimaster aware mq. Wamp is the only option for now.
    'type' : 'wamp',
    'router_url': 'ws://buildbot.mariadb.org:8085/ws',
    'realm': 'realm1',
    # valid are: none, critical, error, warn, info, debug, trace
    'wamp_debug_level' : 'info'
}

#### prometheus exporter //TEMP added Faustin
c['services'].append(reporters.Prometheus(port=9101))
