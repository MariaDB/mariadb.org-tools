# -*- python -*-
# ex: set filetype=python:

from buildbot.plugins import *
from buildbot.process.properties import Property, Properties
from buildbot.steps.shell import ShellCommand, Compile, Test, SetPropertyFromCommand
from buildbot.steps.mtrlogobserver import MTR, MtrLogObserver
from buildbot.steps.source.github import GitHub
from buildbot.process.remotecommand import RemoteCommand
from twisted.internet import defer
import sys
import docker
from datetime import timedelta

sys.setrecursionlimit(10000)

RELEASABLE_BRANCHES="5.5 10.0 10.1 10.2 10.3 10.4 10.5 10.6 bb-5.5-release bb-10.0-release bb-10.1-release bb-10.2-release bb-10.3-release bb-10.4-release bb-10.5-release bb-10.6-release"

# This is the dictionary that the buildmaster pays attention to. We also use
# a shorter alias to save typing.
c = BuildmasterConfig = {}

# Load the slave, database passwords and 3rd-party tokens from an external private file, so
# that the rest of the configuration can be public.
config = { "private": { } }
exec(open("master-private.cfg").read(), config, { })

####### BUILDBOT SERVICES

# 'services' is a list of BuildbotService items like reporter targets. The
# status of each build will be pushed to these targets. buildbot/reporters/*.py
# has a variety to choose from, like IRC bots.

github_status_builders = ["amd64-centos-7", "amd64-debian-10", "amd64-fedora-33", "amd64-ubuntu-2004-clang11"]

c['services'] = []
context = util.Interpolate("buildbot/%(prop:buildername)s")
gs = reporters.GitHubStatusPush(token=config["private"]["gh_mdbci"]["access_token"],
                                context=context,
                                startDescription='Build started.',
                                endDescription='Build done.',
                                verbose=True,
                                builders=github_status_builders)
c['services'].append(gs)

####### PROJECT IDENTITY

# the 'title' string will appear at the top of this buildbot installation's
# home pages (linked to the 'titleURL').
c['title'] = "MariaDB CI"
c['titleURL'] = "https://github.com/MariaDB/server"

# the 'buildbotURL' string should point to the location where the buildbot's
# internal web server is visible. This typically uses the port number set in
# the 'www' entry below, but with an externally-visible host name which the
# buildbot cannot figure out without some help.

c['buildbotURL'] = "https://buildbot.mariadb.org/"

# Custom plugin
# exec(open("grid.py").read())

# 'protocols' contains information about protocols which master will use for
# communicating with workers. You must define at least 'port' option that workers
# could connect to your master with this protocol.
# 'port' must match the value configured into the workers (with their
# --master option)
c['protocols'] = {'pb': {'port': 9989}}

####### DB URL

c['db'] = {
    # This specifies what database buildbot uses to store its state.
    'db_url' : config["private"]["db_url"]
}

mtrDbPool = util.EqConnectionPool("MySQLdb", config["private"]["db_host"], config["private"]["db_user"], config["private"]["db_password"], config["private"]["db_mtr_db"])

####### Disable net usage reports from being sent to buildbot.net
c['buildbotNetUsageData'] = None

####### SCHEDULERS

builders_quick=["amd64-ubuntu-1804", "amd64-ubuntu-2004", "amd64-ubuntu-2010", "amd64-ubuntu-2104", "amd64-ubuntu-2004-icc", "amd64-ubuntu-2004-fulltest", "amd64-ubuntu-2004-gcc10", "amd64-ubuntu-2004-clang11", "amd64-ubuntu-1804-clang6", "amd64-ubuntu-1804-clang10", "amd64-ubuntu-1804-clang10-asan", "amd64-ubuntu-1804-msan", "x86-ubuntu-1804", "amd64-ubuntu-1804-valgrind", "aarch64-ubuntu-1804", "aarch64-ubuntu-2004", "aarch64-ubuntu-2010", "aarch64-ubuntu-2104", "amd64-rhel-7", "amd64-rhel-8", "amd64-ubuntu-1804-debug", "amd64-debian-9", "x86-debian-9","amd64-debian-10", "amd64-debian-11", "amd64-debian-sid", "x86-debian-sid", "amd64-fedora-33", "amd64-fedora-34", "amd64-centos-7", "amd64-centos-8", "amd64-opensuse-15", "amd64-opensuse-42", "amd64-sles-12", "amd64-sles-15", "ppc64le-debian-9", "ppc64le-debian-10", "ppc64le-debian-11", "ppc64le-debian-sid", "ppc64le-ubuntu-1804", "ppc64le-ubuntu-2004", "ppc64le-ubuntu-2104", "ppc64le-ubuntu-2010", "ppc64le-ubuntu-1804-clang6", "ppc64le-ubuntu-1804-clang10", "ppc64le-ubuntu-1804-without-server", "ppc64le-rhel-7", "ppc64le-rhel-8", "ppc64le-centos-7", "aarch64-fedora-33","aarch64-fedora-34", "aarch64-centos-7", "aarch64-centos-8", "aarch64-debian-10", "aarch64-debian-11", "aarch64-debian-sid", "aarch64-debian-9", "aarch64-rhel-7", "aarch64-rhel-8", "amd64-windows", "amd64-windows-packages", "x86-windows", "x86-windows-packages", "amd64-windows-compile-only", "aix", "x86-debian-9-bintar-systemd", "x86-debian-9-bintar-initd", "amd64-debian-9-bintar-systemd", "amd64-debian-9-bintar-initd", "aarch64-centos-7-bintar-systemd", "aarch64-centos-7-bintar-initd", "ppc64le-debian-9-bintar-systemd", "ppc64le-debian-9-bintar-initd", "s390x-ubuntu-2004"]

builders_quick = list(filter(lambda x: x not in github_status_builders, builders_quick))

builders_autobake=["amd64-centos-7-rpm-autobake", "amd64-centos-8-rpm-autobake", "amd64-debian-9-deb-autobake", "x86-debian-9-deb-autobake", "amd64-debian-10-deb-autobake", "amd64-debian-11-deb-autobake", "amd64-debian-sid-deb-autobake", "x86-debian-sid-deb-autobake", "amd64-fedora-33-rpm-autobake", "amd64-fedora-34-rpm-autobake", "amd64-rhel-7-rpm-autobake", "amd64-rhel-8-rpm-autobake", "amd64-opensuse-15-rpm-autobake", "amd64-opensuse-42-rpm-autobake", "amd64-sles-12-rpm-autobake", "amd64-sles-15-rpm-autobake", "amd64-ubuntu-1804-deb-autobake", "amd64-ubuntu-2004-deb-autobake", "amd64-ubuntu-2010-deb-autobake", "amd64-ubuntu-2104-deb-autobake", "aarch64-ubuntu-1804-deb-autobake", "aarch64-ubuntu-2004-deb-autobake", "aarch64-ubuntu-2010-deb-autobake", "aarch64-ubuntu-2104-deb-autobake", "ppc64le-debian-9-deb-autobake", "ppc64le-debian-10-deb-autobake", "ppc64le-debian-11-deb-autobake", "ppc64le-debian-sid-deb-autobake", "ppc64le-ubuntu-1804-deb-autobake", "ppc64le-ubuntu-2004-deb-autobake", "ppc64le-ubuntu-2104-deb-autobake", "ppc64le-ubuntu-2010-deb-autobake", "ppc64le-centos-7-rpm-autobake", "ppc64le-rhel-7-rpm-autobake", "ppc64le-rhel-8-rpm-autobake", "aarch64-debian-10-deb-autobake", "aarch64-debian-11-deb-autobake", "aarch64-debian-sid-deb-autobake", "aarch64-debian-9-deb-autobake", "aarch64-fedora-33-rpm-autobake", "aarch64-fedora-34-rpm-autobake", "aarch64-centos-7-rpm-autobake", "aarch64-centos-8-rpm-autobake", "aarch64-rhel-7-rpm-autobake", "aarch64-rhel-8-rpm-autobake", "s390x-ubuntu-2004-deb-autobake"]

builders_big=["amd64-ubuntu-1804-bigtest"]

builders_install=["amd64-ubuntu-1804-deb-autobake-install", "amd64-centos-7-rpm-autobake-install"]

builders_upgrade=["amd64-ubuntu-1804-deb-autobake-major-upgrade", "amd64-ubuntu-1804-deb-autobake-minor-upgrade", "amd64-centos-7-rpm-autobake-major-upgrade", "amd64-centos-7-rpm-autobake-minor-upgrade"]

builders_eco=["amd64-ubuntu-2004-eco-php", "amd64-debian-10-eco-pymysql", "amd64-debian-10-eco-mysqljs", "amd64-ubuntu-2004-eco-dbdeployer"]

builders_dockerlibrary=["amd64-rhel8-dockerlibrary"]
 

# Configure the Schedulers, which decide how to react to incoming changes.

branches_main=['5.5', '5.5-galera', '10.0', '10.0-galera', '10.1', '10.2', '10.3', '10.4', '10.5', '10.6']
# The trees for which we save binary packages.
savedPackageBranches= ["5.5", "10.0", "10.1", "10.2", "10.3", "10.4", "10.5", "10.6", "10.7", "bb-*-release", "bb-10.2-compatibility"]
releaseBranches = ["bb-*-release"]

# mariadb version supported platforms
supportedPlatforms = {}
supportedPlatforms["10.2"] = ['aarch64-centos-7', 'aarch64-centos-8', 'aarch64-debian-10', 'aarch64-debian-9', 'aarch64-rhel-7', 'aarch64-rhel-8', 'aarch64-ubuntu-1804', 'amd64-centos-7', 'amd64-debian-10', 'amd64-debian-9', 'amd64-fedora-33', 'amd64-opensuse-15', 'amd64-opensuse-42', 'amd64-rhel-7', 'amd64-rhel-8', 'amd64-sles-12', 'amd64-sles-15', 'amd64-ubuntu-1804', 'amd64-ubuntu-1804-clang10', 'amd64-ubuntu-1804-clang10-asan', 'amd64-ubuntu-1804-clang6', 'amd64-ubuntu-1804-valgrind', 'amd64-ubuntu-2004', 'amd64-ubuntu-2004-clang11', 'amd64-windows-compile-only', 'ppc64le-centos-7', 'ppc64le-debian-9', 'ppc64le-rhel-7', 'ppc64le-rhel-8', 'ppc64le-ubuntu-1804', 'ppc64le-ubuntu-1804-clang10', 'x86-debian-9', 'x86-ubuntu-1804']
supportedPlatforms["10.3"] = ['aarch64-centos-7', 'aarch64-centos-8', 'aarch64-debian-10', 'aarch64-debian-9', 'aarch64-rhel-7', 'aarch64-rhel-8', 'aarch64-ubuntu-1804', 'aarch64-ubuntu-2004', 'aarch64-ubuntu-2010', 'amd64-centos-7', 'amd64-centos-8', 'amd64-debian-10', 'amd64-debian-9', 'amd64-fedora-33', 'amd64-opensuse-15', 'amd64-opensuse-42', 'amd64-rhel-7', 'amd64-rhel-8', 'amd64-sles-12', 'amd64-sles-15', 'amd64-ubuntu-1804', 'amd64-ubuntu-1804-clang10', 'amd64-ubuntu-1804-clang10-asan', 'amd64-ubuntu-1804-clang6', 'amd64-ubuntu-1804-debug', 'amd64-ubuntu-1804-valgrind', 'amd64-ubuntu-2004', 'amd64-ubuntu-2004-clang11', 'amd64-ubuntu-2010', 'amd64-windows-compile-only', 'ppc64le-centos-7', 'ppc64le-centos-8', 'ppc64le-debian-10', 'ppc64le-debian-9', 'ppc64le-rhel-7', 'ppc64le-rhel-8', 'ppc64le-ubuntu-1804', 'ppc64le-ubuntu-1804-clang10', 'ppc64le-ubuntu-1804-clang6', 'ppc64le-ubuntu-1804-without-server', 'ppc64le-ubuntu-2004', 'ppc64le-ubuntu-2010', 'x86-debian-9', 'x86-debian-9-bintar-systemd', 'x86-debian-9-bintar-initd', 'amd64-debian-9-bintar-systemd', 'amd64-debian-9-bintar-initd', 'aarch64-centos-7-bintar-systemd', 'aarch64-centos-7-bintar-initd', 'ppc64le-debian-9-bintar-systemd', 'ppc64le-debian-9-bintar-initd']
supportedPlatforms["10.4"] = ['aarch64-centos-7', 'aarch64-centos-8', 'aarch64-debian-10', 'aarch64-debian-9', 'aarch64-rhel-7', 'aarch64-rhel-8', 'aarch64-ubuntu-1804', 'aarch64-ubuntu-2004', 'aarch64-ubuntu-2010', 'amd64-centos-7', 'amd64-centos-8', 'amd64-debian-10', 'amd64-debian-9', 'amd64-fedora-33', 'amd64-opensuse-15', 'amd64-opensuse-42', 'amd64-rhel-7', 'amd64-rhel-8', 'amd64-sles-12', 'amd64-sles-15', 'amd64-ubuntu-1804', 'amd64-ubuntu-1804-clang10', 'amd64-ubuntu-1804-clang10-asan', 'amd64-ubuntu-1804-clang6', 'amd64-ubuntu-1804-debug', 'amd64-ubuntu-1804-valgrind', 'amd64-ubuntu-2004', 'amd64-ubuntu-2004-clang11', 'amd64-ubuntu-2010', 'amd64-windows-compile-only', 'ppc64le-centos-7', 'ppc64le-centos-8', 'ppc64le-debian-10', 'ppc64le-debian-9', 'ppc64le-rhel-7', 'ppc64le-rhel-8', 'ppc64le-ubuntu-1804', 'ppc64le-ubuntu-1804-clang10', 'ppc64le-ubuntu-1804-clang6', 'ppc64le-ubuntu-1804-without-server', 'ppc64le-ubuntu-2004', 'ppc64le-ubuntu-2010', 'x86-debian-9', 'x86-debian-9-bintar-systemd', 'x86-debian-9-bintar-initd', 'amd64-debian-9-bintar-systemd', 'amd64-debian-9-bintar-initd', 'aarch64-centos-7-bintar-systemd', 'aarch64-centos-7-bintar-initd', 'ppc64le-debian-9-bintar-systemd', 'ppc64le-debian-9-bintar-initd']
supportedPlatforms["10.5"] = ['aarch64-centos-7', 'aarch64-centos-8', 'aarch64-debian-10', 'aarch64-debian-11', 'aarch64-debian-9', 'aarch64-debian-sid', 'aarch64-fedora-33', 'aarch64-fedora-34', 'aarch64-rhel-7', 'aarch64-rhel-8', 'aarch64-ubuntu-1804', 'aarch64-ubuntu-2004', 'aarch64-ubuntu-2010', 'aarch64-ubuntu-2104', 'amd64-centos-7', 'amd64-centos-8', 'amd64-debian-10', 'amd64-debian-11', 'amd64-debian-9', 'amd64-debian-sid', 'amd64-fedora-33', 'amd64-fedora-34', 'amd64-opensuse-15', 'amd64-opensuse-42', 'amd64-rhel-7', 'amd64-rhel-8', 'amd64-sles-12', 'amd64-sles-15', 'amd64-ubuntu-1804', 'amd64-ubuntu-1804-clang10', 'amd64-ubuntu-1804-clang10-asan', 'amd64-ubuntu-1804-clang6', 'amd64-ubuntu-1804-debug', 'amd64-ubuntu-1804-msan', 'amd64-ubuntu-1804-valgrind', 'amd64-ubuntu-2004', 'amd64-ubuntu-2004-clang11', 'amd64-ubuntu-2004-fulltest', 'amd64-ubuntu-2004-gcc10', 'amd64-ubuntu-2004-icc', 'amd64-ubuntu-2010', 'amd64-ubuntu-2104', 'amd64-windows', 'amd64-windows-compile-only', 'amd64-windows-packages', 'ppc64le-centos-7', 'ppc64le-debian-10', 'ppc64le-debian-11', 'ppc64le-debian-9', 'ppc64le-debian-sid', 'ppc64le-rhel-7', 'ppc64le-rhel-8', 'ppc64le-ubuntu-1804', 'ppc64le-ubuntu-1804-clang10', 'ppc64le-ubuntu-1804-clang6', 'ppc64le-ubuntu-1804-without-server', 'ppc64le-ubuntu-2004', 'ppc64le-ubuntu-2010', 'ppc64le-ubuntu-2104', 'x86-debian-9', 'x86-debian-sid', 'x86-ubuntu-1804', 'x86-windows', 'x86-windows-packages', 'x86-debian-9-bintar-systemd', 'x86-debian-9-bintar-initd', 'amd64-debian-9-bintar-systemd', 'amd64-debian-9-bintar-initd', 'aarch64-centos-7-bintar-systemd', 'aarch64-centos-7-bintar-initd', 'ppc64le-debian-9-bintar-systemd', 'ppc64le-debian-9-bintar-initd', 'aix', 's390x-ubuntu-2004']
supportedPlatforms["10.6"] = ['aarch64-centos-7', 'aarch64-centos-8', 'aarch64-debian-10', 'aarch64-debian-11', 'aarch64-debian-9', 'aarch64-debian-sid', 'aarch64-fedora-33', 'aarch64-fedora-34', 'aarch64-rhel-7', 'aarch64-rhel-8', 'aarch64-ubuntu-1804', 'aarch64-ubuntu-2004', 'aarch64-ubuntu-2010', 'aarch64-ubuntu-2104', 'amd64-centos-7', 'amd64-centos-8', 'amd64-debian-10', 'amd64-debian-11', 'amd64-debian-9', 'amd64-debian-sid', 'amd64-fedora-33', 'amd64-fedora-34', 'amd64-opensuse-15', 'amd64-opensuse-42', 'amd64-rhel-7', 'amd64-rhel-8', 'amd64-sles-12', 'amd64-sles-15', 'amd64-ubuntu-1804', 'amd64-ubuntu-1804-clang10', 'amd64-ubuntu-1804-clang10-asan', 'amd64-ubuntu-1804-clang6', 'amd64-ubuntu-1804-debug', 'amd64-ubuntu-1804-msan', 'amd64-ubuntu-1804-valgrind', 'amd64-ubuntu-2004', 'amd64-ubuntu-2004-clang11', 'amd64-ubuntu-2004-fulltest', 'amd64-ubuntu-2004-gcc10', 'amd64-ubuntu-2004-icc', 'amd64-ubuntu-2010', 'amd64-ubuntu-2104', 'amd64-windows', 'amd64-windows-compile-only', 'amd64-windows-packages', 'ppc64le-centos-7', 'ppc64le-debian-10', 'ppc64le-debian-11', 'ppc64le-debian-9', 'ppc64le-debian-sid', 'ppc64le-rhel-7', 'ppc64le-rhel-8', 'ppc64le-ubuntu-1804', 'ppc64le-ubuntu-1804-clang10', 'ppc64le-ubuntu-1804-clang6', 'ppc64le-ubuntu-1804-without-server', 'ppc64le-ubuntu-2004', 'ppc64le-ubuntu-2010', 'ppc64le-ubuntu-2104', 'x86-debian-9', 'x86-debian-sid', 'x86-ubuntu-1804', 'x86-windows', 'x86-windows-packages', 'x86-debian-9-bintar-systemd', 'x86-debian-9-bintar-initd', 'amd64-debian-9-bintar-systemd', 'amd64-debian-9-bintar-initd', 'aarch64-centos-7-bintar-systemd', 'aarch64-centos-7-bintar-initd', 'ppc64le-debian-9-bintar-systemd', 'ppc64le-debian-9-bintar-initd', 'aix', 's390x-ubuntu-2004']
supportedPlatforms["10.7"] = ['aarch64-centos-7', 'aarch64-centos-8', 'aarch64-debian-10', 'aarch64-debian-11', 'aarch64-debian-9', 'aarch64-debian-sid', 'aarch64-fedora-33', 'aarch64-fedora-34', 'aarch64-rhel-7', 'aarch64-rhel-8', 'aarch64-ubuntu-1804', 'aarch64-ubuntu-2004', 'aarch64-ubuntu-2010', 'aarch64-ubuntu-2104', 'amd64-centos-7', 'amd64-centos-8', 'amd64-debian-10', 'amd64-debian-11', 'amd64-debian-9', 'amd64-debian-sid', 'amd64-fedora-33', 'amd64-fedora-34', 'amd64-opensuse-15', 'amd64-opensuse-42', 'amd64-rhel-7', 'amd64-rhel-8', 'amd64-sles-12', 'amd64-sles-15', 'amd64-ubuntu-1804', 'amd64-ubuntu-1804-clang10', 'amd64-ubuntu-1804-clang10-asan', 'amd64-ubuntu-1804-clang6', 'amd64-ubuntu-1804-debug', 'amd64-ubuntu-1804-msan', 'amd64-ubuntu-1804-valgrind', 'amd64-ubuntu-2004', 'amd64-ubuntu-2004-clang11', 'amd64-ubuntu-2004-fulltest', 'amd64-ubuntu-2004-gcc10', 'amd64-ubuntu-2004-icc', 'amd64-ubuntu-2010', 'amd64-ubuntu-2104', 'amd64-windows', 'amd64-windows-compile-only', 'amd64-windows-packages', 'ppc64le-centos-7', 'ppc64le-debian-10', 'ppc64le-debian-11', 'ppc64le-debian-9', 'ppc64le-debian-sid', 'ppc64le-rhel-7', 'ppc64le-rhel-8', 'ppc64le-ubuntu-1804', 'ppc64le-ubuntu-1804-clang10', 'ppc64le-ubuntu-1804-clang6', 'ppc64le-ubuntu-1804-without-server', 'ppc64le-ubuntu-2004', 'ppc64le-ubuntu-2010', 'ppc64le-ubuntu-2104', 'x86-debian-9', 'x86-debian-sid', 'x86-ubuntu-1804', 'x86-windows', 'x86-windows-packages', 'x86-debian-9-bintar-systemd', 'x86-debian-9-bintar-initd', 'amd64-debian-9-bintar-systemd', 'amd64-debian-9-bintar-initd', 'aarch64-centos-7-bintar-systemd', 'aarch64-centos-7-bintar-initd', 'ppc64le-debian-9-bintar-systemd', 'ppc64le-debian-9-bintar-initd', 'aix', 's390x-ubuntu-2004']

# Hack to remove all github_status_builders since they are triggered separately
for k in supportedPlatforms:
    supportedPlatforms[k] = list(filter(lambda x: x not in github_status_builders, supportedPlatforms[k]))

@util.renderer
def getBranchBuilderNames(props):
    mBranch = props.getProperty("master_branch")

    return supportedPlatforms[mBranch]

@util.renderer
def getAutobakeBuilderNames(props):
    builderName = props.getProperty("parentbuildername")
    for b in builders_autobake:
        if builderName in b:
            return [b]
    return []

@util.renderer
def getBigtestBuilderNames(props):
    builderName = str(props.getProperty("parentbuildername"))

    for b in builders_big:
        if builderName in b:
            return [b]
    return []

@util.renderer
def getInstallBuilderNames(props):
    builderName = str(props.getProperty("parentbuildername"))

    for b in builders_install:
        if builderName in b:
            return [b]
    return []

@util.renderer
def getUpgradeBuilderNames(props):
    builderName = str(props.getProperty("parentbuildername"))

    builds = []
    for b in builders_upgrade:
        if builderName in b:
            builds.append(b)
    return builds

@util.renderer
def getEcoBuilderNames(props):
    builderName = str(props.getProperty("parentbuildername"))

    builds = []
    for b in builders_eco:
        if builderName in b:
            builds.append(b)
    return builds

@util.renderer
def getDockerLibraryNames(props):
    return builders_dockerlibrary[0]

def hasAutobake(props):
    builderName = props.getProperty("buildername")
    for b in builders_autobake:
        if builderName in b:
            return True
    return False

def hasBigtest(props):
    builderName = str(props.getProperty("buildername"))

    for b in builders_big:
        if builderName in b:
            return True
    return False

def hasInstall(props):
    builderName = str(props.getProperty("buildername"))

    for b in builders_install:
        if builderName in b:
            return True
    return False

def hasUpgrade(props):
    builderName = str(props.getProperty("buildername"))

    for b in builders_upgrade:
        if builderName in b:
            return True
    return False

def hasEco(props):
    builderName = str(props.getProperty("buildername"))

    for b in builders_eco:
        if builderName in b:
            return True
    return False

def hasDockerLibrary(props):
    branch = str(props.getProperty("master_branch"))
    builderName = str(props.getProperty("buildername"))

    # from https://github.com/MariaDB/mariadb-docker/blob/master/update.sh#L4-L7
    if branch == "10.2":
        dockerbase = "ubuntu-1804-deb-autobake"
    else:
        dockerbase = "ubuntu-2004-deb-autobake"

    # We only build on the above two autobakes for all architectures
    return builderName.endswith(dockerbase)

# git branch filter using fnmatch
import fnmatch
def staging_branch_fn(branch):
    return fnmatch.fnmatch(branch, 'prot-st-*')
def fnmatch_any(s, list_of_patterns):
    return any(fnmatch.fnmatch(s, p) for p in list_of_patterns)

c['schedulers'] = []

c['schedulers'].append(schedulers.Triggerable(name="s_upstream_all",
        builderNames=getBranchBuilderNames))

schedulerProtectedBranches = schedulers.Triggerable(name="s_protected_branches",
        builderNames=github_status_builders)
c['schedulers'].append(schedulerProtectedBranches)

schedulerPackages = schedulers.Triggerable(name="s_packages",
        builderNames=getAutobakeBuilderNames)
c['schedulers'].append(schedulerPackages)

schedulerBigtests = schedulers.Triggerable(name="s_bigtest",
        builderNames=getBigtestBuilderNames)
c['schedulers'].append(schedulerBigtests)

schedulerInstall = schedulers.Triggerable(name="s_install",
        builderNames=getInstallBuilderNames)
c['schedulers'].append(schedulerInstall)

schedulerUpgrade = schedulers.Triggerable(name="s_upgrade",
        builderNames=getUpgradeBuilderNames)
c['schedulers'].append(schedulerUpgrade)

schedulerEco = schedulers.Triggerable(name="s_eco",
        builderNames=getEcoBuilderNames)
c['schedulers'].append(schedulerEco)

schedulerDockerlibrary = schedulers.Triggerable(name="s_dockerlibrary",
        builderNames=getDockerLibraryNames)
c['schedulers'].append(schedulerDockerlibrary)

####### WORKERS

# The 'workers' list defines the set of recognized workers. Each element is
# a Worker object, specifying a unique worker name and password.  The same
# worker name and password must be configured on the worker.
c['workers'] = []

# Normal workers

def mkWorker(name, **kwargs):
    return worker.Worker(name, config["private"]["worker_pass"][name], **kwargs)

hz_bbw1_worker = mkWorker("hz-bbw1-ubuntu1804")
c['workers'].append(hz_bbw1_worker)

# AIX worker
aix_worker = mkWorker("aix-worker", properties={'jobs': 3})
c['workers'].append(aix_worker)

# Docker Library
dockerlibrary_worker = mkWorker("bb-rhel8-docker", properties={'jobs': 1})
c['workers'].append(dockerlibrary_worker)

# LibVirt workers
c['workers'].append(worker.LibVirtWorker('buildbot-debian10',
                    config["private"]["worker_pass"]["hz-bbw1-libvirt-debian-10"],
                    util.Connection('qemu+ssh://buildbot@95.216.39.88:65001/session?socket=/run/libvirt/libvirt-sock'),
                    '/var/lib/libvirt/images/buildbot-debian10', build_wait_timeout=0, max_builds=1))

c['workers'].append(worker.LibVirtWorker('buildbot-ubuntu1804',
                    config["private"]["worker_pass"]["hz-bbw1-libvirt-debian-10"],
                    util.Connection('qemu+ssh://buildbot@95.216.39.88:65001/session?socket=/run/libvirt/libvirt-sock'),
                    '/var/lib/libvirt/images/buildbot-ubuntu1804', build_wait_timeout=0, max_builds=1))

c['workers'].append(worker.LibVirtWorker('buildbot-centos7',
                    config["private"]["worker_pass"]["hz-bbw1-libvirt-debian-10"],
                    util.Connection('qemu+ssh://buildbot@95.216.39.88:65001/session?socket=/run/libvirt/libvirt-sock'),
                    '/var/lib/libvirt/images/buildbot-centos7', build_wait_timeout=0, max_builds=1))

# Docker workers

## hz-bbw1-docker
c['workers'].append(worker.DockerLatentWorker("hz-bbw1-docker-tarball-debian-10", None,
                    docker_host=config["private"]["docker_workers"]["hz-bbw1-docker"],
                    dockerfile=open("dockerfiles/debian-10.dockerfile").read(),
                    followStartupLogs=True,
                    masterFQDN='buildbot.mariadb.org',
                    hostconfig={ 'shm_size':'1G' },
                    volumes=['/mnt/autofs/master_packages/:/packages'],
                    max_builds=1,
                    build_wait_timeout=0,
                    properties={ 'jobs':4, 'save_packages':True }))

c['workers'].append(worker.DockerLatentWorker("intel-bbw1-docker-tarball-1-debian-10", None,
                    docker_host=config["private"]["docker_workers"]["intel-bbw1-docker"],
                    dockerfile=open("dockerfiles/debian-10.dockerfile").read(),
                    followStartupLogs=True,
                    masterFQDN='100.64.100.1',
                    hostconfig={ 'shm_size':'1G' },
                    volumes=['/mnt/autofs/master_packages/:/packages'],
                    max_builds=1,
                    build_wait_timeout=0,
                    properties={ 'jobs':4, 'save_packages':True }))

c['workers'].append(worker.DockerLatentWorker("intel-bbw1-docker-tarball-2-debian-10", None,
                    docker_host=config["private"]["docker_workers"]["intel-bbw1-docker"],
                    dockerfile=open("dockerfiles/debian-10.dockerfile").read(),
                    followStartupLogs=True,
                    masterFQDN='100.64.100.1',
                    hostconfig={ 'shm_size':'1G' },
                    volumes=['/mnt/autofs/master_packages/:/packages'],
                    max_builds=1,
                    build_wait_timeout=0,
                    properties={ 'jobs':4, 'save_packages':True }))

c['workers'].append(worker.DockerLatentWorker("intel-bbw1-docker-tarball-3-debian-10", None,
                    docker_host=config["private"]["docker_workers"]["intel-bbw1-docker"],
                    dockerfile=open("dockerfiles/debian-10.dockerfile").read(),
                    followStartupLogs=True,
                    masterFQDN='100.64.100.1',
                    hostconfig={ 'shm_size':'1G' },
                    volumes=['/mnt/autofs/master_packages/:/packages'],
                    max_builds=1,
                    build_wait_timeout=0,
                    properties={ 'jobs':4, 'save_packages':True }))

c['workers'].append(worker.DockerLatentWorker("intel-bbw1-docker-tarball-4-debian-10", None,
                    docker_host=config["private"]["docker_workers"]["intel-bbw1-docker"],
                    dockerfile=open("dockerfiles/debian-10.dockerfile").read(),
                    followStartupLogs=True,
                    masterFQDN='100.64.100.1',
                    hostconfig={ 'shm_size':'1G' },
                    volumes=['/mnt/autofs/master_packages/:/packages'],
                    max_builds=1,
                    build_wait_timeout=0,
                    properties={ 'jobs':4, 'save_packages':True }))

c['workers'].append(worker.DockerLatentWorker("intel-bbw1-docker-tarball-5-debian-10", None,
                    docker_host=config["private"]["docker_workers"]["intel-bbw1-docker"],
                    dockerfile=open("dockerfiles/debian-10.dockerfile").read(),
                    followStartupLogs=True,
                    masterFQDN='100.64.100.1',
                    hostconfig={ 'shm_size':'1G' },
                    volumes=['/mnt/autofs/master_packages/:/packages'],
                    max_builds=1,
                    build_wait_timeout=0,
                    properties={ 'jobs':4, 'save_packages':True }))

c['workers'].append(worker.DockerLatentWorker("hz-bbw1-docker-eco-php-ubuntu-2004", None,
                    docker_host=config["private"]["docker_workers"]["hz-bbw1-docker"],
                    dockerfile=open("dockerfiles/eco-php-ubuntu-2004.dockerfile").read(),
                    followStartupLogs=False,
                    masterFQDN='buildbot.mariadb.org',
                    hostconfig={ 'shm_size':'6G' },
                    build_wait_timeout=0,
                    max_builds=1,
                    volumes=['/srv/buildbot/eco/code:/code', '/srv/buildbot/eco/build:/build'],
                    properties={ 'jobs':7, 'save_packages':False }))

c['workers'].append(worker.DockerLatentWorker("hz-bbw1-docker-eco-dbdeployer-ubuntu-2004", None,
                    docker_host=config["private"]["docker_workers"]["hz-bbw1-docker"],
                    dockerfile=open("dockerfiles/eco-dbdeployer-ubuntu-2004.dockerfile").read(),
                    followStartupLogs=False,
                    masterFQDN='buildbot.mariadb.org',
                    hostconfig={ 'shm_size':'6G' },
                    build_wait_timeout=0,
                    max_builds=1,
                    volumes=['/srv/buildbot/eco/dbdeployer:/dbdeployer'],
                    properties={ 'jobs':7, 'save_packages':False }))

c['workers'].append(worker.DockerLatentWorker("hz-bbw1-docker-eco-pymysql-python-3-9-slim-buster", None,
                    docker_host=config["private"]["docker_workers"]["hz-bbw1-docker"],
                    dockerfile=open("dockerfiles/eco-pymysql-python-3-9-slim-buster.dockerfile").read(),
                    followStartupLogs=False,
                    masterFQDN='buildbot.mariadb.org',
                    hostconfig={ 'shm_size':'6G' },
                    build_wait_timeout=0,
                    max_builds=1,
                    volumes=['/srv/buildbot/eco/pymysqlcode:/code'],
                    properties={ 'jobs':7, 'save_packages':False }))

c['workers'].append(worker.DockerLatentWorker("hz-bbw1-docker-eco-mysqljs-nodejs15-buster", None,
                    docker_host=config["private"]["docker_workers"]["hz-bbw1-docker"],
                    dockerfile=open("dockerfiles/eco-mysqljs-nodejs15-buster.dockerfile").read(),
                    followStartupLogs=False,
                    masterFQDN='buildbot.mariadb.org',
                    hostconfig={ 'shm_size':'6G' },
                    build_wait_timeout=0,
                    max_builds=1,
                    volumes=['/srv/buildbot/eco/mysqljscode:/code'],
                    properties={ 'jobs':7, 'save_packages':False }))

workers={}
def addWorker(worker_name_prefix, worker_id, worker_type, dockerfile, jobs=5, save_packages=False, shm_size='15G'):
    worker_name = worker_name_prefix + str(worker_id) + '-docker'
    name = worker_name + worker_type

    i = worker_id
    tls = None
    #if worker_name_prefix.startswith('aarch64'):
    #    tls = docker.tls.TLSConfig(verify=True, ca_cert='/srv/buildbot/tlscerts/ca-arm-bbw' + str(i)+ '.pem', client_cert=('/srv/buildbot/tlscerts/cert-arm-bbw' + str(i) + '.pem', '/srv/buildbot/tlscerts/key-arm-bbw' + str(i) + '.pem'))
    #else:
    #    tls = None

    if worker_name_prefix.startswith('hz'):
        b_name = 'x64-bbw'
    elif worker_name_prefix.startswith('intel'):
        b_name = 'x64-bbw'
    elif worker_name_prefix.startswith('p9'):
        b_name = 'p9-bbw'
    else:
        b_name = worker_name_prefix
    base_name = b_name + '-docker' + worker_type

    if base_name not in workers:
        workers[base_name] = [name]
    else:
        workers[base_name].append(name)

    volumes=['/srv/buildbot/ccache:/mnt/ccache', '/srv/buildbot/packages:/mnt/packages', '/mnt/autofs/master_packages/:/packages']
    # Set master FQDN - for VPN machines it should be 100.64.100.1
    fqdn = 'buildbot.mariadb.org'
    if worker_name_prefix.startswith('intel') or worker_name_prefix.startswith('bg'):
        fqdn = '100.64.100.1'
    if worker_name_prefix.startswith('p9-rhel8'):
        fqdn = '10.103.203.14'
    dockerfile_str = open("dockerfiles/" + dockerfile).read()
    if 'rhel' in worker_type and not 'download' in dockerfile:
        dockerfile_str = dockerfile_str % (config["private"]["rhel_sub"]["user"], config["private"]["rhel_sub"]["password"])
    c['workers'].append(worker.DockerLatentWorker(name, None,
                        docker_host=config["private"]["docker_workers"][worker_name],
                        dockerfile=dockerfile_str,
                        tls=tls,
                        followStartupLogs=False,
                        masterFQDN=fqdn,
                        build_wait_timeout=0,
                        max_builds=1,
                        hostconfig={ 'shm_size':shm_size},
                        volumes=volumes,
                        properties={ 'jobs':jobs, 'save_packages':save_packages }))


for w_name in ['hz-bbw', 'intel-bbw']:
    if w_name.startswith('hz'):
        jobs = 7
    else:
        jobs = 15
    if w_name == 'hz-bbw':
        for i in [1, 2]:
            addWorker(w_name, i, '-debian-9', 'debian-9.dockerfile', jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-debian-9-i386', 'debian-9-i386.dockerfile', jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-debian-sid', 'debian-sid.dockerfile', jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-debian-sid-i386', 'debian-sid-i386.dockerfile', jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-ubuntu-1804', 'ubuntu-1804.dockerfile', jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-sles-12', 'sles-12-download.dockerfile', jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-sles-15', 'sles-15-download.dockerfile', jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-opensuse-42', 'opensuse-42.dockerfile', jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-valgrind-ubuntu-1804', "valgrind-ubuntu-1804.dockerfile", jobs=jobs, save_packages=False)
            addWorker(w_name, i, '-icc-ubuntu-2004', "icc-ubuntu-2004-download.dockerfile", jobs=jobs, save_packages=False)
            addWorker(w_name, i, '-rhel-7', "rhel-7-download.dockerfile", jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-ubuntu-2010', "ubuntu-2010.dockerfile", jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-ubuntu-2104', "ubuntu-2104.dockerfile", jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-opensuse-15', 'opensuse-15.dockerfile', jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-clang-ubuntu-1804', "clang-ubuntu-1804.dockerfile", jobs=jobs, save_packages=True)
            addWorker(w_name, i, '-fedora-34', 'fedora-34.dockerfile', jobs=jobs, save_packages=True)
    if w_name == 'intel-bbw':
        addWorker(w_name, 1, '-centos-7', 'centos-7.dockerfile', jobs=jobs, save_packages=True)
        addWorker(w_name, 1, '-debian-10', "debian-10.dockerfile", jobs=jobs, save_packages=True)
        addWorker(w_name, 1, '-debian-11', "debian-11.dockerfile", jobs=jobs, save_packages=True)
        addWorker(w_name, 1, '-fedora-33', 'fedora-33.dockerfile', jobs=jobs, save_packages=True)
        addWorker(w_name, 1, '-rhel-8', "rhel-8.dockerfile", jobs=jobs, save_packages=True)
        addWorker(w_name, 1, '-ubuntu-2004-clang', 'clang-ubuntu-2004.dockerfile', jobs=jobs, save_packages=True)
        addWorker(w_name, 1, '-ubuntu-2004', "ubuntu-2004.dockerfile", jobs=jobs, save_packages=True)

## apexis-bbw1-docker
c['workers'].append(worker.DockerLatentWorker("fjord1-docker-ubuntu-1804", None,
                    docker_host=config["private"]["docker_workers"]["apexis-bbw1-docker"],
                    tls=docker.tls.TLSConfig(verify=True, ca_cert='/srv/buildbot/tlscerts/ca-apexis1.pem', client_cert=('/srv/buildbot/tlscerts/cert-apexis1.pem', '/srv/buildbot/tlscerts/key-apexis1.pem')),
                    dockerfile=open("dockerfiles/clang-ubuntu-1804.dockerfile").read(),
                    followStartupLogs=False,
                    masterFQDN='buildbot.mariadb.org',
                    hostconfig={ 'shm_size':'6G' },
                    max_builds=1,
                    volumes=['/opt/mariadb-buildbot/ccache:/mnt/ccache', '/opt/mariadb-buildbot/packages:/mnt/packages'],
                    properties={ 'jobs':7, 'save_packages':False }))

c['workers'].append(worker.DockerLatentWorker("fjord2-docker-ubuntu-1804", None,
                    docker_host=config["private"]["docker_workers"]["apexis-bbw2-docker"],
                    tls=docker.tls.TLSConfig(verify=True, ca_cert='/srv/buildbot/tlscerts/ca-apexis2.pem', client_cert=('/srv/buildbot/tlscerts/cert-apexis2.pem', '/srv/buildbot/tlscerts/key-apexis2.pem')),
                    dockerfile=open("dockerfiles/clang-ubuntu-1804.dockerfile").read(),
                    followStartupLogs=False,
                    masterFQDN='buildbot.mariadb.org',
                    hostconfig={ 'shm_size':'6G' },
                    max_builds=1,
                    volumes=['/opt/mariadb-buildbot/ccache:/mnt/ccache', '/opt/mariadb-buildbot/packages:/mnt/packages'],
                    properties={ 'jobs':7, 'save_packages':False }))

## Add Power workers
for w_name in ['p9-rhel8-bbw', 'p9-rhel7-bbw', 'p9-db-bbw']:
    jobs = 12
    addWorker(w_name, 1, '-centos-7', 'ppc-centos-7-download.dockerfile', jobs=jobs, save_packages=True, shm_size='20G')
    addWorker(w_name, 1, '-ubuntu-1804', 'ppc-ubuntu-1804.dockerfile', jobs=jobs, save_packages=True, shm_size='20G')
    addWorker(w_name, 1, '-ubuntu-2004', 'ppc-ubuntu-2004.dockerfile', jobs=jobs, save_packages=True, shm_size='20G')
    addWorker(w_name, 1, '-ubuntu-2010', 'ppc-ubuntu-2010.dockerfile', jobs=jobs, save_packages=True, shm_size='20G')
    addWorker(w_name, 1, '-ubuntu-2104', 'ppc-ubuntu-2104.dockerfile', jobs=jobs, save_packages=True, shm_size='20G')
    addWorker(w_name, 1, '-debian-9', 'ppc-debian-9.dockerfile', jobs=jobs, save_packages=True, shm_size='20G')
    addWorker(w_name, 1, '-debian-10', 'ppc-debian-10.dockerfile', jobs=jobs, save_packages=True, shm_size='20G')
    addWorker(w_name, 1, '-debian-11', 'ppc-debian-11.dockerfile', jobs=jobs, save_packages=True, shm_size='20G')
    addWorker(w_name, 1, '-debian-sid', 'ppc-debian-sid.dockerfile', jobs=jobs, save_packages=True, shm_size='20G')
    addWorker(w_name, 1, '-clang-ubuntu-1804', 'ppc-clang-ubuntu-1804.dockerfile', jobs=jobs, save_packages=True, shm_size='20G')
    addWorker(w_name, 1, '-rhel-7', 'ppc-rhel-7-download.dockerfile', jobs=jobs, save_packages=True, shm_size='20G')
    addWorker(w_name, 1, '-rhel-8', 'ppc-rhel-8-download.dockerfile', jobs=jobs, save_packages=True, shm_size='20G')

## bg-bbw-docker
for i in range(1,6):
    if i == 1:
        jobs = 5
    else:
        jobs = 3

    addWorker('bg-bbw', i, '-clang-ubuntu-1804', "clang-ubuntu-1804.dockerfile", jobs=jobs, save_packages=True)
    addWorker('bg-bbw', i, '-msan-clang-ubuntu-1804', "msan-clang-ubuntu-1804.dockerfile", jobs=jobs, save_packages=False)
    addWorker('bg-bbw', i, '-valgrind-ubuntu-1804', "valgrind-ubuntu-1804.dockerfile", jobs=jobs, save_packages=False)
    addWorker('bg-bbw', i, '-fedora-33', "fedora-33.dockerfile", jobs=jobs, save_packages=True)
    addWorker('bg-bbw', i, '-fedora-34', "fedora-34.dockerfile", jobs=jobs, save_packages=True)
    addWorker('bg-bbw', i, '-opensuse-15', "opensuse-15.dockerfile", jobs=jobs, save_packages=True)
    addWorker('bg-bbw', i, '-centos-8', "centos-8.dockerfile", jobs=jobs, save_packages=True)
    addWorker('bg-bbw', i, '-x86-ubuntu-1804', "ubuntu-1804-i386.dockerfile", jobs=jobs, save_packages=False)
    addWorker('bg-bbw', i, '-ubuntu-2004', "ubuntu-2004.dockerfile", jobs=jobs, save_packages=True)
    addWorker('bg-bbw', i, '-debian-10', "debian-10.dockerfile", jobs=jobs, save_packages=True)
    addWorker('bg-bbw', i, '-rhel-8', "rhel-8.dockerfile", jobs=jobs, save_packages=True)
    addWorker('bg-bbw', i, '-centos-7', "centos-7.dockerfile", jobs=jobs, save_packages=True)
    addWorker('bg-bbw', i, '-sles-12', 'sles-12-download.dockerfile', jobs=jobs, save_packages=True)
    addWorker('bg-bbw', i, '-sles-15', 'sles-15-download.dockerfile', jobs=jobs, save_packages=True)
 
# aarch64-bbw-docker
for i in range(1, 5):
    jobs = 4
    if i == 4:
        addWorker('aarch64-bbw', i, '-debian-10', "aarch64-debian-10.dockerfile", jobs=8, save_packages=True)
        addWorker('aarch64-bbw', i, '-debian-11', "aarch64-debian-11.dockerfile", jobs=8, save_packages=True)
    else:
        addWorker('aarch64-bbw', i, '-debian-10', "aarch64-debian-10.dockerfile", jobs=jobs, save_packages=True)
        addWorker('aarch64-bbw', i, '-ubuntu-1804', "aarch64-ubuntu-1804.dockerfile", jobs=jobs, save_packages=True)
        addWorker('aarch64-bbw', i, '-ubuntu-2010', "aarch64-ubuntu-2010.dockerfile", jobs=jobs, save_packages=True)
        addWorker('aarch64-bbw', i, '-ubuntu-2104', "aarch64-ubuntu-2104.dockerfile", jobs=jobs, save_packages=True)
        addWorker('aarch64-bbw', i, '-fedora-33', "aarch64-fedora-33.dockerfile", jobs=jobs, save_packages=True)
        addWorker('aarch64-bbw', i, '-fedora-34', "aarch64-fedora-34.dockerfile", jobs=jobs, save_packages=True)
        addWorker('aarch64-bbw', i, '-debian-9', "aarch64-debian-9.dockerfile", jobs=jobs, save_packages=True)
        addWorker('aarch64-bbw', i, '-ubuntu-2004', "aarch64-ubuntu-2004.dockerfile", jobs=jobs, save_packages=True)
        addWorker('aarch64-bbw', i, '-debian-sid', "aarch64-debian-sid.dockerfile", jobs=jobs, save_packages=True)
        addWorker('aarch64-bbw', i, '-rhel-8', "rhel-8.dockerfile", jobs=jobs, save_packages=True)
    if i == 2:
        addWorker('aarch64-bbw', i, '-centos-7', "aarch64-centos-7.dockerfile", jobs=jobs, save_packages=True)
        addWorker('aarch64-bbw', i, '-rhel-7', "aarch64-rhel-7-download.dockerfile", jobs=jobs, save_packages=True)
        addWorker('aarch64-bbw', i, '-centos-8', "aarch64-centos-8.dockerfile", jobs=8, save_packages=True)

addWorker('s390x-bbw', 1, '-ubuntu-2004', "s390x-ubuntu-2004.dockerfile", jobs=8, save_packages=True)

# Small hack to only run protected branches on the dedicated worker
workers['aarch64-bbw-docker-debian-10'].remove('aarch64-bbw4-docker-debian-10')

## windows-bbw1-docker
windows_worker = mkWorker("bbw1-windows", max_builds=2, properties={'jobs': 64, 'save_packages': True})
c['workers'].append(windows_worker)
windows_worker = mkWorker("hz-bbw2-windows", max_builds=1, properties={'jobs': 12, 'save_packages': True})
c['workers'].append(windows_worker)
'''
c['workers'].append(worker.DockerLatentWorker("bbw1-docker-windows-1809", None,
                    docker_host=config["private"]["docker_workers"]["windows-bbw1-docker"],
                    dockerfile=open("dockerfiles/windows-download.dockerfile").read(),
                    tls=docker.tls.TLSConfig(verify=True, ca_cert='/srv/buildbot/tlscerts/ca-win.pem', client_cert=('/srv/buildbot/tlscerts/cert-win.pem', '/srv/buildbot/tlscerts/key-win.pem')),
                    followStartupLogs=True,
                    masterFQDN='100.64.100.1',
                    hostconfig={ 'shm_size':'6G' },
                    max_builds=1,
                    #volumes=['C:\packages:C:\packages'],
                    properties={ 'jobs':2, 'save_packages':True }))

c['workers'].append(worker.DockerLatentWorker("bbw2-docker-windows-1809", None,
                    docker_host=config["private"]["docker_workers"]["windows-bbw2-docker"],
                    dockerfile=open("dockerfiles/windows-download.dockerfile").read(),
                    followStartupLogs=True,
                    masterFQDN='100.64.100.1',
                    hostconfig={ 'shm_size':'6G' },
                    max_builds=1,
                    #volumes=['C:\packages:C:\packages'],
                    properties={ 'jobs':12, 'save_packages':True }))
'''

## bm-bbw1-docker
c['workers'].append(worker.DockerLatentWorker("bm-bbw1-docker-ubuntu-1804", None,
                    docker_host=config["private"]["docker_workers"]["bm-bbw1-docker"],
                    dockerfile=open("dockerfiles/ubuntu-1804.dockerfile").read(),
                    followStartupLogs=False,
                    masterFQDN='buildbot.mariadb.org',
                    hostconfig={ 'shm_size':'20G' },
                    max_builds=1,
                    volumes=['/srv/buildbot/ccache:/mnt/ccache', '/mnt/autofs/master_packages:/packages'],
                    properties={ 'jobs': 2, 'save_packages':False }))

####### BUILDERS

# The 'builders' list defines the Builders, which tell Buildbot how to perform a build:
# what steps, and which workers can execute them.  Note that any particular build will
# only take place on one worker.


# Priority filter based on saved package branches
def nextBuild(bldr, requests):
    for r in requests:
        if fnmatch_any(r.sources[""].branch, releaseBranches):
            return r
    for r in requests:
        if fnmatch_any(r.sources[""].branch, savedPackageBranches):
            return r
    return requests[0]

class FakeBuild(object):
    properties = Properties()

class FakeStep(object):
    build = FakeBuild()

@defer.inlineCallbacks
def shell(command, worker, builder):
    args = {
        'command': command,
        'logEnviron': False,
        'workdir': "/srv/buildbot/worker",
        'want_stdout': False,
        'want_stderr': False,
    }
    cmd = RemoteCommand('shell', args, stdioLogName=None)
    cmd.worker = worker
    yield cmd.run(FakeStep(), worker.conn, builder.name)
    return cmd.rc

@defer.inlineCallbacks
def canStartBuild(builder, wfb, request):
    worker=wfb.worker
    return True
    # check worker load over the last 5 minutes
    rc = yield shell(
        'test "$(cut -d" " -f2 /proc/loadavg | cut -d. -f1)" -le "$(( $(nproc) / 2 ))"',
        worker, builder)
    if rc != 0:
        log.msg('loadavg is too high to take new builds',
                system=repr(worker))
        worker.putInQuarantine()
        return False

    worker.quarantine_timeout = 180
    worker.putInQuarantine()
    worker.resetQuarantine()
    return True

# Save packages for current branch?
def savePackage(step):
    return step.getProperty("save_packages") and fnmatch_any(step.getProperty("branch"), savedPackageBranches)

# ls2list gets the output of ls and returns a list with the files and directories
def ls2list(rc, stdout, stderr):
    lsFilenames = []

    for l in stdout.strip().split('\n'):
        if l != "":
            lsFilenames.append(l.strip())

    return { 'packages' : lsFilenames }

# ls2string gets the output of ls and returns a space delimited string with the files and directories
def ls2string(rc, stdout, stderr):
    lsFilenames = []

    for l in stdout.strip().split('\n'):
        if l != "":
            lsFilenames.append(l.strip())

    return { 'packages' : " ".join(lsFilenames) }

# checks if the list of files is empty
def hasFiles(step):
  if len(step.getProperty("packages")) < 1:
    return False
  else:
    return True

def filterBranch(step):
  if '10.5' in step.getProperty("branch"):
        return False
  if '10.6' in step.getProperty("branch"):
        return False
  return True

# check if branch is a staging branch
def isStagingBranch(step):
  if staging_branch_fn(step.getProperty("branch")):
    return True
  else:
    return False

# returns true if build is succeeding
def ifStagingSucceeding(step):
  if isStagingBranch(step):
    step.setProperty("build_results", step.build.results)
    return step.build.results in ('SUCCESS', 'WARNINGS')
  else:
    return False

# set step's waitForFinish to True if staging branch
def waitIfStaging(step):
  if isStagingBranch(step):
    step.waitForFinish = True
  return True

def downloadSourceTarball():
    return ShellCommand(
             name="fetch_tarball",
             description="fetching source tarball",
             descriptionDone="fetching source tarball...done",
             haltOnFailure=True,
             command=["bash", "-xc", util.Interpolate("""
  d=/mnt/packages/
  f="%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz"
  find $d -type f -mtime +2 -delete -ls
  for i in `seq 1 10`;
  do
    if flock "$d$f" wget -cO "$d$f" "https://ci.mariadb.org/%(prop:tarbuildnum)s/%(prop:mariadb_version)s.tar.gz"; then
        break
    else
        sleep $i
    fi
  done
""")])

def downloadSourceTarballAIX():
    return ShellCommand(
             name="fetch_tarball",
             description="fetching source tarball",
             descriptionDone="fetching source tarball...done",
             haltOnFailure=True,
             command=["bash", "-xc", util.Interpolate("""
  d=/mnt/packages/
  f="%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz"
  find $d -type f -mtime +2 -delete -ls
  for i in `seq 1 10`;
  do
    if wget -cO "$d$f" "https://ci.mariadb.org/%(prop:tarbuildnum)s/%(prop:mariadb_version)s.tar.gz"; then
        break
    else
        sleep $i
    fi
  done
""")])


# curl fails range-bytes download miserably due to https://github.com/curl/curl/issues/1163
# what I tried:
# flock "$d$f" curl --fail -C - -o "$d$f" "https://ci.mariadb.org/%(prop:tarbuildnum)s/%(prop:mariadb_version)s.tar.gz"
# ret=$? ; test $ret -eq 22 || test $ret -eq 0

def moveMTRLogs():
    return """
parallel=$(expr %(kw:jobs)s \* 2)

mkdir -p /buildbot/logs
for ((mtr=0; mtr<=parallel; mtr++)); do
    for mysqld in {1..4}; do
        if [ $mtr = 0 ]; then
            logname="mysqld."$mysqld".err"
            filename="mysql-test/var/log/mysqld."$mysqld".err"
        else
            logname="mysqld."$mysqld".err."$mtr
            filename="mysql-test/var/"$mtr"/log/mysqld."$mysqld".err"
        fi
        if [ -e $filename ]; then
            cp $filename /buildbot/logs/$logname
        fi
    done
done
"""

def getHTMLLogString():
    return """
echo '<!DOCTYPE html>
<html>
<body>' >> /buildbot/mysql_logs.html

echo '<a href="https://ci.mariadb.org/%(prop:tarbuildnum)s/logs/%(prop:buildername)s/">mysqld* log dir</a><br>' >> /buildbot/mysql_logs.html

echo '</body>
</html>' >> /buildbot/mysql_logs.html"""

def downloadDebs():
    return ShellCommand(
              name="fetch_debs",
              description="fetching debs",
              descriptionDone="fetching debs...done",
              haltOnFailure=True,
              command=["sh", "-xc", util.Interpolate("""
  mkdir -p debs/binary debs/source
  wget -r -np -nH --cut-dirs=2 -A *.deb "https://ci.mariadb.org/%(prop:tarbuildnum)s/%(prop:parentbuildername)s/debs/binary/" -P .
""")])

def dpkgDeb():
    return ShellCommand(
            name="dpkg-scanpackages/sources",
            haltOnFailure=True,
            command=["sh", "-xc", util.Interpolate("""
    mkdir -p debs/binary debs/source
    cp `find .. -maxdepth 1 -type f` debs/binary/
    cd debs
    dpkg-scanpackages binary /dev/null | gzip -9c > Packages.gz
    dpkg-scansources source /dev/null | gzip -9c > Sources.gz
    cd ..
    find debs -type f -exec sha256sum {} \; | sort > sha256sums.txt
""")], doStepIf=lambda step: hasFiles(step) and savePackage(step))

def downloadRpms():
    return ShellCommand(
              name="fetch_rpms",
              description="fetching rpms",
              descriptionDone="fetching rpms...done",
              haltOnFailure=True,
              command=["sh", "-xc", util.Interpolate("""
  mkdir -p debs/binary debs/source
  wget -r -np -nH --cut-dirs=2 -A *.rpm "https://ci.mariadb.org/%(prop:tarbuildnum)s/%(prop:parentbuildername)s/rpms/" -P .
""")])


@util.renderer
def mtrJobsMultiplier(props):
    jobs = props.getProperty('jobs', default=20)
    return jobs * 2

@util.renderer
def dockerfile(props):
    worker = props.getProperty('workername')
    return "https://github.com/MariaDB/mariadb.org-tools/tree/master/buildbot.mariadb.org/dockerfiles/" + "-".join(worker.split('-')[-2:]) + '.dockerfile'

@util.renderer
def getArch(props):
    buildername = props.getProperty('buildername')
    return buildername.split('-')[0]

DEVELOPMENT_BRANCH="10.7"

def getRpmUpgradeStep():
     return Test(
        name="upgrade",
        haltOnFailure=True,
        description=["testing", "upgrade"],
        descriptionDone=["test", "upgrade"],
        command=["bash", "-xc", util.Interpolate("""
		set -xv
		test_mode=%(prop:test_mode)s
		test_type=%(prop:test_type)s
		case %(prop:branch)s in
		*galera*)
		  if [[ "$test_mode" == "all" ]] ; then
		    echo "Upgrade warning: the test in 'all' mode is not executed for galera branches"
		    exit
		  fi
		  ;;
		*%(kw:development_branch)s*)
		  if [[ "$test_mode" != "server" ]] ; then
		    echo "Upgrade warning: the test in 'all' or 'deps' mode is not executed for non-stable branches"
		    exit
		  fi
		  ;;
		esac
		package_version=`ls rpms/MariaDB-server-[0-9]* | head -n 1 | sed -e 's/.*MariaDB-server-\([0-9]*\.[0-9]*\.[0-9]*\).*/\\1/'`
		major_version=%(prop:major_version)s
		prev_major_version=$major_version
		# For now we rely on major_version being 10.1 or higher, can add a check later
		if [[ "$test_type" == "major" ]] ; then
		    minor_version_num=`echo $major_version | sed -e 's/10\.\([0-9]*\)/\\1/'`
		    ((prev_minor_version_num = minor_version_num - 1))
		    prev_major_version=10.$prev_minor_version_num
		fi
		arch=%(prop:arch)s
		distro=%(prop:version_name)s
		if [[ "$distro" == "sles123" ]] ; then
		    distro="sles12"
		fi
		repo_dist_arch=$distro-$arch
		echo "Architecture and distribution based on VM name: $repo_dist_arch"
		echo "Test properties"
		echo "  Systemd capability     %(prop:systemdCapability)s"
		echo "  Test type              $test_type"
		echo "  Test mode              $test_mode"
		echo "  Major version          $major_version"
		echo "  Previous major version $prev_major_version"
		#===============
		# This test can be performed in four modes:
		# - 'server' -- only mariadb-server is installed (with whatever dependencies it pulls) and upgraded.
		# - 'all'    -- all provided packages are installed and upgraded, except for Columnstore
		# - 'deps'   -- only a limited set of main packages is installed and upgraded,
		#               to make sure upgrade does not require new dependencies
		# - 'columnstore' -- mariadb-server and mariadb-plugin-columnstore are installed
		#===============
		echo "Current test mode: $test_mode"
		#============
		# Environment
		#============
		rpm -qa | grep -iE 'maria|mysql|galera'
		cat /etc/*release
		uname -a
		df -kT
		#========================================
		# Check whether a previous version exists
		#========================================
		if ! wget http://yum.mariadb.org/$prev_major_version/$repo_dist_arch/repodata -O repodata.list
		then
		  echo "Upgrade warning: could not find the 'repodata' folder for a previous version in MariaDB repo, skipping the test"
		  exit
		fi
		#===============================================
		# Define the list of packages to install/upgrade
		#===============================================
		case $test_mode in
		all|deps|columnstore)
		  primary_xml=`grep 'primary.xml.gz' repodata.list | sed -e 's/.*href="\(.*-primary.xml\)\.gz\".*/\\1/'`
		  wget http://yum.mariadb.org/$prev_major_version/$repo_dist_arch/repodata/$primary_xml.gz
		  if [[ $? != 0 ]] ; then
		    echo "ERROR: Couldn't download primary.xml.gz from the repository"
		    exit 1
		  fi
		  gunzip $primary_xml.gz
		  if [[ "$test_mode" == "all" ]] ; then
		    if grep -i columnstore $primary_xml > /dev/null ; then
		      echo "Upgrade warning: Due to MCOL-4120 and other issues, Columnstore upgrade will be tested separately"
		    fi
		    package_list=`grep -A 1 '<package type="rpm"' $primary_xml | grep MariaDB | grep -viE 'galera|columnstore' | sed -e 's/<name>//' | sed -e 's/<\/name>//' | sort | uniq | xargs`
		  elif [[ "$test_mode" == "deps" ]] ; then
		    package_list=`grep -A 1 '<package type="rpm"' $primary_xml | grep -iE 'MariaDB-server|MariaDB-test|MariaDB-client|MariaDB-common|MariaDB-compat' | sed -e 's/<name>//' | sed -e 's/<\/name>//' | sort | uniq | xargs`
		  elif [[ "$test_mode" == "columnstore" ]] ; then
		    if ! grep columnstore $primary_xml > /dev/null ; then
		      echo "Upgrade warning: Columnstore was not found in the released packages, the test will not be run"
		      exit
		    fi
		    package_list="MariaDB-server MariaDB-columnstore-engine"
		  fi
		  if [[ $arch == ppc* ]] ; then
		    package_list=`echo $package_list | xargs -n1 | sed -e 's/MariaDB-compat//gi' | xargs`
		  fi
		  ;;
		server)
		  package_list="MariaDB-server MariaDB-client"
		  ;;
		*)
		  echo "ERROR: unknown test mode: $test_mode"
		  exit 1
		esac
		echo "Package_list: $package_list"
		#======================================================================
		# Prepare yum/zypper configuration for installation of the last release
		#======================================================================
		if which zypper ; then
		  package_manager=zypper
		  repo_location=/etc/zypp/repos.d
		  install_command="zypper --no-gpg-checks install --from mariadb -y"
		  cleanup_command="zypper clean --all"
		  remove_command="zypper remove -y"
		  # Since there is no reasonable "upgrade" command in zypper which would
		  # pick up RPM files needed to upgrade existing packages, we have to use "install".
		  # However, if we run "install *.rpm", it will install all packages, regardless
		  # the test mode, and we will get a lot of differences in contents after upgrade
		  # (more plugins, etc.). So, instead for each package that we are going to install,
		  # we'll also find an RPM file which provides it, and will use its name in
		  # in the "upgrade" (second install) command
		  if [[ "$test_mode" == "all" ]] ; then
		    rm -f rpms/*columnstore*.rpm
		    rpms_for_upgrade="rpms/*.rpm"
		    case "%(prop:branch)s" in
		    *10.[2-9]*)
		      ;;
		    *)
		      echo "Upgrade warning: Due to MDEV-14560 (only fixed in 10.2+) an extra service restart will be performed after upgrade"
		      extra_restart_after_upgrade="yes"
		      ;;
		    esac
		  else
		    rpms_for_upgrade=""
		    extra_restart_after_upgrade="yes"
		    for p in $package_list ; do
		      for f in rpms/*.rpm ; do
			if rpm -qp $f --provides | grep -i "^$p =" ; then
			  rpms_for_upgrade="$rpms_for_upgrade $f"
			  break
			fi
		      done
		    done
		  fi
		  upgrade_command="zypper --no-gpg-checks install -y $rpms_for_upgrade"
		# As of now (February 2018), RPM packages do not support major upgrade.
		# To imitate it, we will remove previous packages and install new ones.
		elif which yum ; then
		  package_manager=yum
		  repo_location=/etc/yum.repos.d
		  install_command="yum -y --nogpgcheck install"
		  cleanup_command="yum clean all"
		  upgrade_command="yum -y --nogpgcheck upgrade rpms/*.rpm"
		  if [[ "$test_type" == "major" ]] ; then
		    upgrade_command="yum -y --nogpgcheck install rpms/*.rpm"
		  fi
		  if yum autoremove 2>&1 |grep -q 'need to be root'; then
		    remove_command="yum -y autoremove"
		  else
		    remove_command="yum -y remove"
		  fi
		else
		  echo "ERROR: could not find package manager"
		  exit 1
		fi
		if [[ "$test_mode" == "columnstore" ]] ; then
		  echo "Upgrade warning: Due to MCOL-4120 an extra service restart will be performed after upgrade"
		  extra_restart_after_upgrade="yes"
		fi
		extra_restart_after_upgrade="yes"
		ls $repo_location/* | grep -iE '(maria|galera)' | xargs -r sudo rm -f
		sudo sh -c "echo '[mariadb]
name=MariaDB
baseurl=http://yum.mariadb.org/$prev_major_version/$repo_dist_arch
gpgkey=https://yum.mariadb.org/RPM-GPG-KEY-MariaDB
gpgcheck=1' > $repo_location/MariaDB.repo"
		# Add fix for MDEV-20673 to rhel8/centos8 repo
		case $HOSTNAME in
		  rhel8*|centos8*) sudo sh -c "echo 'module_hotfixes = 1' >> $repo_location/MariaDB.repo";;
		esac
		# Workaround for TODO-1479 (errors upon reading from SUSE repos)
		#sudo rm -rf /etc/zypp/repos.d/SUSE_Linux_Enterprise_Server_12_SP3_x86_64:SLES12-SP3-Updates.repo /etc/zypp/repos.d/SUSE_Linux_Enterprise_Server_12_SP3_x86_64:SLES12-SP3-Pool.repo
		sudo sh -c "$cleanup_command"
		#=========================
		# Install previous release
		#=========================
		sudo sh -c "$install_command $package_list"
		if [[ $? -ne 0 ]] ; then
		  echo "ERROR: Installation of a previous release failed, see the output above"
		  exit 1
		fi
		#==========================================================================
		# Start the server, check that it is functioning and create some structures
		#==========================================================================
		case `expr "$prev_major_version" '<' "10.1"`"%(prop:systemdCapability)s" in
		0yes)
		  sudo systemctl start mariadb
		  if [[ "$distro" != *"sles"* ]] && [[ "$distro" != *"suse"* ]] ; then
		    sudo systemctl enable mariadb
		  else
		    echo "Upgrade warning: due to MDEV-23044 mariadb service won't be enabled in the test"
		  fi
		  sudo systemctl status mariadb --no-pager
		  ;;
		*)
		  sudo /etc/init.d/mysql start
		  ;;
		esac
		if [[ $? -ne 0 ]] ; then
		  echo "ERROR: Server startup failed"
		  sudo cat /var/log/messages | grep -iE 'mysqld|mariadb'
		  sudo cat /var/lib/mysql/*.err
		  exit 1
		fi
		if [[ "$prev_major_version" > "10.3" ]] ; then
		# 10.4+ uses unix_socket by default, hence sudo,
		# and also might have simple_password_check plugin, hence non-default password
		  sudo mysql -e "set password= PASSWORD('S1mpl-pw')"
		  password_option="-pS1mpl-pw"
		fi
		# All the commands below should succeed
		set -e
		mysql -uroot $password_option -e "CREATE DATABASE db"
		mysql -uroot $password_option -e "CREATE TABLE db.t_innodb(a1 SERIAL, c1 CHAR(8)) ENGINE=InnoDB; INSERT INTO db.t_innodb VALUES (1,'foo'),(2,'bar')"
		mysql -uroot $password_option -e "CREATE TABLE db.t_myisam(a2 SERIAL, c2 CHAR(8)) ENGINE=MyISAM; INSERT INTO db.t_myisam VALUES (1,'foo'),(2,'bar')"
		mysql -uroot $password_option -e "CREATE TABLE db.t_aria(a3 SERIAL, c3 CHAR(8)) ENGINE=Aria; INSERT INTO db.t_aria VALUES (1,'foo'),(2,'bar')"
		mysql -uroot $password_option -e "CREATE TABLE db.t_memory(a4 SERIAL, c4 CHAR(8)) ENGINE=MEMORY; INSERT INTO db.t_memory VALUES (1,'foo'),(2,'bar')"
		mysql -uroot $password_option -e "CREATE ALGORITHM=MERGE VIEW db.v_merge AS SELECT * FROM db.t_innodb, db.t_myisam, db.t_aria"
		mysql -uroot $password_option -e "CREATE ALGORITHM=TEMPTABLE VIEW db.v_temptable AS SELECT * FROM db.t_innodb, db.t_myisam, db.t_aria"
		mysql -uroot $password_option -e "CREATE PROCEDURE db.p() SELECT * FROM db.v_merge"
		mysql -uroot $password_option -e "CREATE FUNCTION db.f() RETURNS INT DETERMINISTIC RETURN 1"
		if [[ "$test_mode" == "columnstore" ]] ; then
		  mysql -uroot $password_option -e "CREATE TABLE db.t_columnstore(a INT, c VARCHAR(8)) ENGINE=ColumnStore; SHOW CREATE TABLE db.t_columnstore; INSERT INTO db.t_columnstore VALUES (1,'foo'),(2,'bar')"
		fi
		set +e
		#====================================================================================
		# Store information about server version and available plugins/engines before upgrade
		#====================================================================================
		mysql -uroot $password_option --skip-column-names -e "select @@version" | awk -F'-' '{ print $1 }' > /tmp/version.old
		old_version=`cat /tmp/version.old`
		# If the tested branch has the same version as the public repository,
		# upgrade won't work properly. For releasable branches, we will return an error
		# urging to bump the version number. For other branches, we will abort the test
		# with a warning (which nobody will read). This is done upon request from
		# development, as temporary branches might not be rebased in a timely manner
		if [ "$package_version" == "$old_version" ] ; then
		    echo "ERROR: Server version $package_version has already been released. Bump the version number!"
		    for b in %(kw:releasable_branches)s ; do
			if [ "$b" == "%(prop:branch)s" ] ; then
			    exit 1
			fi
		    done
		    echo "Upgrade warning: The test will be skipped, as upgrade will not work properly"
		    exit
		fi
		mysql -uroot $password_option --skip-column-names -e "select engine, support, transactions, savepoints from information_schema.engines" | sort > /tmp/engines.old
		case "$prev_major_version" in
		5.5)
		  mysql -uroot $password_option --skip-column-names -e "show plugins" | sort > /tmp/plugins.old
		  ;;
		10.[0-9])
		  mysql -uroot $password_option --skip-column-names -e "select plugin_name, plugin_status, plugin_type, plugin_library, plugin_license from information_schema.all_plugins" | sort > /tmp/plugins.old
		  ;;
		*)
		  echo "ERROR: unknown major version: $prev_major_version"
		  exit 1
		  ;;
		esac
		# Store dependency information for old binaries/libraries:
		# - names starting with "mysql*" in the directory where mysqld is located;
		# - names starting with "mysql*" in the directory where mysql is located;
		# - everything in the plugin directories installed by any MariaDB packages
		set +x
		for i in `sudo which mysqld | sed -e 's/mysqld$/mysql\*/'` `which mysql | sed -e 's/mysql$/mysql\*/'` `rpm -ql \`rpm -qa | grep MariaDB | xargs\` | grep -v 'mysql-test' | grep -v '/debug/' | grep '/plugin/' | sed -e 's/[^\/]*$/\*/' | sort | uniq | xargs`; do echo "=== $i" ; ldd $i | sort | sed 's/(.*)//' ; done > /home/buildbot/ldd.old
		set -x
		#======================================================================
		# Prepare yum/zypper configuration for installation of the new packages
		#======================================================================
		set -e
		if [[ "$test_type" == "major" ]] ; then
		  echo
		  echo "Remove old packages for major upgrade"
		  echo
		  packages_to_remove=`rpm -qa | grep 'MariaDB-' | awk -F'-' '{print $1"-"$2}' | xargs`
		  sudo sh -c "$remove_command $packages_to_remove"
		  rpm -qa | grep -iE 'maria|mysql' || true
		fi
		if [[ "$test_mode" == "deps" ]] ; then
		  sudo mv $repo_location/MariaDB.repo /tmp
		  sudo rm -rf $repo_location/*
		  sudo mv /tmp/MariaDB.repo $repo_location/
		  sudo sh -c "$cleanup_command"
		fi
		#=========================
		# Install the new packages
		#=========================
		# Between 10.3 and 10.4(.2), required galera version changed from galera(-3) to galera-4.
		# It means that there will be no galera-4 in the "old" repo, and it's not among the local RPMs.
		# So, we need to add a repo for it
		if [[ "$test_type" == "major" ]] && [[ "$major_version" > "10.3" ]] && [[ "$prev_major_version" < "10.4" ]] ; then
		  sudo sh -c "echo '[galera]
name=Galera
baseurl=http://yum.mariadb.org/galera/repo4/rpm/$repo_dist_arch
gpgkey=https://yum.mariadb.org/RPM-GPG-KEY-MariaDB
gpgcheck=1' > $repo_location/galera.repo"
		fi
		sudo sh -c "$upgrade_command"
		set +e
		#===================================================
		# Check that no old packages have left after upgrade
		#===================================================
		# The check is only performed for all-package-upgrade, because
		# for selective ones some implicitly installed packages might not be upgraded
		if [[ "$test_mode" == "all" ]] ; then
		  if [ "%(prop:is_main_tree)s" == "yes" ] ; then
		    rpm -qa | grep -iE 'mysql|maria' | grep `cat /tmp/version.old`
		  else
		    rpm -qa | grep -iE 'mysql|maria' | grep `cat /tmp/version.old` | grep -v debuginfo
		  fi
		  if [[ $? -eq 0 ]] ; then
		    echo "ERROR: Old packages have been found after upgrade"
		    exit 1
		  fi
		fi
		#================================
		# Optionally (re)start the server
		#================================
		set -e
		if [ "$test_type" == "major" ] ; then
		  case "%(prop:systemdCapability)s" in
		  yes)
		    sudo systemctl start mariadb
		    ;;
		  no)
		    sudo /etc/init.d/mysql start
		    ;;
		  esac
		elif [ -n "$extra_restart_after_upgrade" ] ; then
		  case "%(prop:systemdCapability)s" in
		  yes)
		    sudo systemctl restart mariadb
		    ;;
		  no)
		    sudo /etc/init.d/mysql restart
		    ;;
		  esac
		fi
		#================================
		# Make sure that the new server is running
		#================================
		if mysql -uroot $password_option -e "select @@version" | grep "$old_version" ; then
		  echo "ERROR: The server was not upgraded or was not restarted after upgrade"
		  exit 1
		fi
		#=====================================================================================
		# Run mysql_upgrade for non-GA branches (minor upgrades in GA branches shouldn't need it)
		#=====================================================================================
		if [[ "$major_version" == %(kw:development_branch)s ]] || [[ "$test_type" == "major" ]] ; then
		  mysql_upgrade -uroot $password_option
		fi
		set +e
		#=====================================================================================
		# Check that the server is functioning and previously created structures are available
		#=====================================================================================
		# All the commands below should succeed
		set -e
		mysql -uroot $password_option -e "select @@version, @@version_comment"
		mysql -uroot $password_option -e "SHOW TABLES IN db"
		mysql -uroot $password_option -e "SELECT * FROM db.t_innodb; INSERT INTO db.t_innodb VALUES (3,'foo'),(4,'bar')"
		mysql -uroot $password_option -e "SELECT * FROM db.t_myisam; INSERT INTO db.t_myisam VALUES (3,'foo'),(4,'bar')"
		mysql -uroot $password_option -e "SELECT * FROM db.t_aria; INSERT INTO db.t_aria VALUES (3,'foo'),(4,'bar')"
		echo "If the next INSERT fails with a duplicate key error,"
		echo "it is likely because the server was not upgraded or restarted after upgrade"
		mysql -uroot $password_option -e "SELECT * FROM db.t_memory; INSERT INTO db.t_memory VALUES (1,'foo'),(2,'bar')"
		mysql -uroot $password_option -e "SELECT COUNT(*) FROM db.v_merge"
		mysql -uroot $password_option -e "SELECT COUNT(*) FROM db.v_temptable"
		mysql -uroot $password_option -e "CALL db.p()"
		mysql -uroot $password_option -e "SELECT db.f()"
		if [[ "$test_mode" == "columnstore" ]] ; then
		  mysql -uroot $password_option -e "SELECT * FROM db.t_columnstore; INSERT INTO db.t_columnstore VALUES (3,'foo'),(4,'bar')"
		fi
		set +e
		#===================================================================================
		# Store information about server version and available plugins/engines after upgrade
		#===================================================================================
		set -e
		mysql -uroot $password_option --skip-column-names -e "select @@version" | awk -F'-' '{ print $1 }' > /tmp/version.new
		mysql -uroot $password_option --skip-column-names -e "select engine, support, transactions, savepoints from information_schema.engines" | sort > /tmp/engines.new
		cat /tmp/engines.new
		case "$major_version" in
		5.5)
		  mysql -uroot $password_option --skip-column-names -e "show plugins" | sort > /tmp/plugins.new
		  ;;
		10.[0-9])
		  mysql -uroot $password_option --skip-column-names -e "select plugin_name, plugin_status, plugin_type, plugin_library, plugin_license from information_schema.all_plugins" | sort > /tmp/plugins.new
		  ;;
		esac
		# Dependency information for new binaries/libraries
		set +x
		for i in `sudo which mysqld | sed -e 's/mysqld$/mysql\*/'` `which mysql | sed -e 's/mysql$/mysql\*/'` `rpm -ql \`rpm -qa | grep MariaDB | xargs\` | grep -v 'mysql-test' | grep -v '/debug/' | grep '/plugin/' | sed -e 's/[^\/]*$/\*/' | sort | uniq | xargs`; do echo "=== $i" ; ldd $i | sort | sed 's/(.*)//' ; done > /home/buildbot/ldd.new
		set -x
		case "%(prop:systemdCapability)s" in
		yes)
		  ls -l /usr/lib/systemd/system/mariadb.service
		  ls -l /etc/systemd/system/mariadb.service.d/migrated-from-my.cnf-settings.conf
		  ls -l /etc/init.d/mysql || true
		  systemctl status mariadb.service --no-pager
		  systemctl status mariadb --no-pager
		  # Not done for SUSE due to MDEV-23044
		  if [[ "$distro" != *"sles"* ]] && [[ "$distro" != *"suse"* ]] ; then
		    # Major upgrade for RPMs is remove / install, so previous configuration
		    # could well be lost
		    if [[ "$test_type" == "major" ]] ; then
		      sudo systemctl enable mariadb
		    fi
		    systemctl is-enabled mariadb
		    systemctl status mysql --no-pager
		    systemctl status mysqld --no-pager
		  fi
		  ;;
		no)
		  echo "Steps related to systemd will be skipped"
		  ;;
		*)
		  echo "ERROR: It should never happen, check your configuration (systemdCapability property is not set or is set to a wrong value)"
		  exit 1
		  ;;
		esac
		set +e
		# Until %(kw:development_branch)s is GA, the list of plugins/engines might be unstable, skipping the check
		# For major upgrade, no point to do the check at all
		if [[ "$major_version" != %(kw:development_branch)s ]] && [[ "$test_type" != "major" ]] ; then
		  # This output is for informational purposes
		  diff -u /tmp/engines.old /tmp/engines.new
		  diff -u /tmp/plugins.old /tmp/plugins.new
		  # Only fail if there are any disappeared/changed engines or plugins
		  disappeared_or_changed=`comm -23 /tmp/engines.old /tmp/engines.new | wc -l`
		  if [[ $disappeared_or_changed -ne 0 ]] ; then
		    echo "ERROR: the lists of engines in the old and new installations differ"
		    exit 1
		  fi
		  disappeared_or_changed=`comm -23 /tmp/plugins.old /tmp/plugins.new | wc -l`
		  if [[ $disappeared_or_changed -ne 0 ]] ; then
		    echo "ERROR: the lists of available plugins in the old and new installations differ"
		    exit 1
		  fi
		  if [ "$test_mode" == "all" ] ; then
		    set -o pipefail
		    if wget --timeout=20 --no-check-certificate https://raw.githubusercontent.com/MariaDB/mariadb.org-tools/master/buildbot/baselines/ldd.${major_version}.${distro}.${arch} -O /tmp/ldd.baseline > /dev/null ; then
		      ldd_baseline=/tmp/ldd.baseline
		    else
		      ldd_baseline=/home/buildbot/ldd.old
		    fi
		    diff -U1000 $ldd_baseline /home/buildbot/ldd.new | ( grep -E '^[-+]|^ =' || true )
		    if [[ $? -ne 0 ]] ; then
		      echo "ERROR: something has changed in the dependencies of binaries or libraries. See the diff above"
		      exit 1
		    fi
		  fi
		  set +o pipefail
		fi
		diff -u /tmp/version.old /tmp/version.new
		if [[ $? -eq 0 ]] ; then
		  echo "ERROR: server version has not changed after upgrade"
		  echo "It can be a false positive if we forgot to bump version after release,"
		  echo "or if it is a development tree is based on an old version"
		  exit 1
		fi
		echo "Done"
""", development_branch=DEVELOPMENT_BRANCH, releasable_branches=RELEASABLE_BRANCHES)])

	
def getRpmInstallStep():
     return Test(
        name="install",
        haltOnFailure=True,
        description=["testing", "install"],
        descriptionDone=["test", "install"],
        command=["bash", "-xc", util.Interpolate("""
		set -ex
		df -kT
		case "%(prop:branch)s" in
		*mdev10416*)
		  sudo cat /etc/sysconfig/selinux | grep SELINUX || true
		  sudo sh -c \"PATH=$PATH:/usr/sbin getenforce || true\"
		  sudo sh -c \"PATH=$PATH:/usr/sbin setenforce Enforcing || true\"
		  sudo sh -c \"PATH=$PATH:/usr/sbin getenforce || true\"
		  ;;
		esac
		rpm -qa | { grep -iE 'maria|mysql|galera' || true; }
		# Try several times, to avoid sporadic "The requested URL returned error: 404"
		made_cache=0
		for i in 1 2 3 4 5 ; do
		  sudo rm -rf /var/cache/yum/*
		  sudo yum clean all
		  case $HOSTNAME in
		    rhel8*) sudo subscription-manager refresh ;;
		  esac
		  if sudo yum makecache ; then
		    made_cache=1
		    break
		  else
		    sleep 5
		  fi
		done
		if [ "$made_cache" != "1" ] ; then
		  echo "Failed to make cache"
		  exit 1
		fi
		sudo yum search mysql | { grep "^mysql" || true; }
		sudo yum search maria | { grep "^maria" || true; }
		sudo yum search percona | { grep percona || true; }
		case "%(prop:branch)s" in
		# 10.1+ branches; 3.x is for MDEV-17688, 10.2 with 3.x connector
		*10.[1-9]*|*3.[0-9]*)
		  sudo sh -c "echo '[galera]
name=galera
baseurl=http://yum.mariadb.org/galera/repo/rpm/%(prop:arch)s
gpgkey=https://yum.mariadb.org/RPM-GPG-KEY-MariaDB
gpgcheck=1' > /etc/yum.repos.d/galera.repo"
		  # Update galera.repo to point at either the galera-3 or galera-4 test repo
		  case "%(prop:branch)s" in
		  *10.[1-3]*)
		    sudo sed -i 's/repo/repo3/' /etc/yum.repos.d/galera.repo
		    ;;
		  *10.[4-9]*)
		    sudo sed -i 's/repo/repo4/' /etc/yum.repos.d/galera.repo
		    ;;
		  esac
		  sudo cat /etc/yum.repos.d/galera.repo
		  sudo yum -y --nogpgcheck install rpms/*.rpm
		  sudo sh -c 'g=/usr/lib*/galera*/libgalera_smm.so; echo -e "[galera]\nwsrep_provider=$g"' > /etc/my.cnf.d/galera.cnf
		  case "%(prop:systemdCapability)s" in
		  yes)
		    if ! sudo systemctl start mariadb ; then
		      sudo journalctl -lxn 500 --no-pager -u mariadb.service
		      sudo systemctl -l status mariadb.service --no-pager
		      exit 1
		    fi
		    ;;
		  no)
		    sudo /etc/init.d/mysql restart
		    ;;
		  *)
		    echo "It should never happen, check your configuration (systemdCapability property is not set or is set to a wrong value)"
		    ;;
		  esac
		  if [[ "%(prop:branch)s" == *"10."[4-9]* ]] ; then
		    echo "Uninstallation of Cracklib plugin may fail if it wasn't installed, it's quite all right"
		    if sudo mysql -e "uninstall soname 'cracklib_password_check.so'" ; then
		      reinstall_cracklib_plugin="YES"
		    fi
		    sudo mysql -e "set password=''"
		  fi
		  mysql -uroot -e 'drop database if exists test; create database test; use test; create table t(a int primary key) engine=innodb; insert into t values (1); select * from t; drop table t;'
		  if ls rpms/*.rpm | grep -i columnstore > /dev/null 2>&1 ; then
		    mysql --verbose -uroot -e "create database cs; use cs; create table cs.t_columnstore (a int, b char(8)); insert into cs.t_columnstore select seq, concat('val',seq) from seq_1_to_10; select * from cs.t_columnstore"
		    sudo systemctl restart mariadb
		    mysql --verbose -uroot -e "select * from cs.t_columnstore; update cs.t_columnstore set b = 'updated'"
		    sudo systemctl restart mariadb-columnstore
		    mysql --verbose -uroot -e "update cs.t_columnstore set a = a + 10; select * from cs.t_columnstore"
		  fi
		  mysql -uroot -e 'show global status like "wsrep%%"'
		  ;;
		# 5.5/10.0 non-Galera branches
		*)
		  sudo yum -y --nogpgcheck install rpms/*.rpm
		  sudo /etc/init.d/mysql restart
		  mysql -uroot -e "use test; create table t(a int primary key) engine=innodb; insert into t values (1); select * from t; drop table t"
		  ;;
		esac
		echo "Test for MDEV-18563, MDEV-18526"
		set +e
		case "%(prop:systemdCapability)s" in
		yes)
		  sudo systemctl stop mariadb
		  ;;
		no)
		  sudo /etc/init.d/mysql stop
		  ;;
		esac
		sleep 1
		sudo pkill -9 mysqld
		for p in /bin /sbin /usr/bin /usr/sbin /usr/local/bin /usr/local/sbin ; do
		  if test -x $p/mysql_install_db ; then
		    sudo $p/mysql_install_db --no-defaults --user=mysql --plugin-maturity=unknown
		  else
		    echo "$p/mysql_install_db does not exist"
		  fi
		done
		sudo mysql_install_db --no-defaults --user=mysql --plugin-maturity=unknown
		set +e
		echo "All done"
""")])

def getDebGaleraStep(port):

    def if_run_galera_test(step):
        if step.getProperty("sst_mode") == "off":
            return False
        return True
        if not branch_is_10_1_or_later(step):
            return False
        if step.getProperty("branch") == 'bb-10.2-compatibility':
            return False
        if sst_mode == 'xtrabackup-v2':
            if branch_is_10_3_or_later(step):
                return False # because of "The redo log was created with MariaDB 10.3.6"
            if branch_is_10_2_or_later(step):
                return False # because of MDEV-12289, this might be fixable
            if arch not in ['x86', 'i386', 'amd64', 'x86_64']:
                return False # no xtrabackup for other architectures
            if arch in ['x86', 'i386'] and version_name in ['artful','stretch']:
                return False # no 32-bit debs for ubuntu stable and debian 9
        return True

    return Test(
        name="galera",
        warningPattern="Test warning:.*",
        description=["testing", "galera", "SST"],
        descriptionDone=["galera", "SST"],
        timeout=300,
        logfiles={"daemon": "/var/log/daemon.log", "syslog": "/var/log/syslog", "node1": "/var/lib/node1/node1.err", "node2": "/var/lib/node2/node2.err", "node3": "/var/lib/node3/node3.err", "mysqld.1.err": "/home/buildbot/var/log/mysqld.1.err", "mysqld.2.err": "/home/buildbot/var/log/mysqld.2.err", "mysqld.3.err": "/home/buildbot/var/log/mysqld.3.err", "node1.mariabackup.prepare": "/home/buildbot/mariabackup_logs/node1.mariabackup.prepare.log", "node2.mariabackup.prepare": "/home/buildbot/mariabackup_logs/node2.mariabackup.prepare.log", "node3.mariabackup.prepare": "/home/buildbot/mariabackup_logs/node3.mariabackup.prepare.log", "node1.mariabackup.move": "/home/buildbot/mariabackup_logs/node1.mariabackup.move.log", "node2.mariabackup.move": "/home/buildbot/mariabackup_logs/node2.mariabackup.move.log", "node3.mariabackup.move": "/home/buildbot/mariabackup_logs/node3.mariabackup.move.log", "node1.mariabackup.backup": "/home/buildbot/mariabackup_logs/node1.mariabackup.backup.log", "node2.mariabackup.backup": "/home/buildbot/mariabackup_logs/node2.mariabackup.backup.log", "node4.mariabackup.backup": "/home/buildbot/mariabackup_logs/node4.mariabackup.backup.log"},
        doStepIf=if_run_galera_test,
        command=["bash","-xc", util.Interpolate("""
set -xv
sst_mode=%(prop:sst_mode)s
version_name=%(prop:version_name)s
arch=%(prop:arch)s
# Limitations coming from Percona
if [ "$sst_mode" == "xtrabackup-v2" ] ; then
  case $version_name in
    "bionic"|"focal")
      xtrabackup_version="0.1-5"
      ;;
    *)
      xtrabackup_version="0.1-4"
      ;;
  esac
fi
sudo killall mysqld
for i in 1 2 3 4 5 6 7 8 9 10 ; do
  if sudo ps -ef | grep -iE 'mysqld|mariadb' | grep -v grep ; then
    sleep 3
  else
    break
  fi
done
# We don't want crash recovery, but if mysqld hasn't stopped, we'll have to deal with it
sudo killall -s 9 mysqld
if [ "$sst_mode" == "mariabackup" ] ; then
# Starting from 10.3.6, MariaBackup packages have a generic name mariadb-backup.
# Before 10.3, MariaBackup packages have a version number in them, e.g. mariadb-backup-10.2 etc.
# First, try to find the generic package, if can't, then the name with the number
  mbackup=`ls debs/binary/ | grep -v ddeb | grep mariadb-backup_ | sed -e 's/^\(mariadb-backup\).*/\\1/' | uniq`
  if [ -z "$mbackup" ] ; then
    mbackup=`ls debs/binary/ | grep -v ddeb | grep mariadb-backup- | sed -e 's/^\(mariadb-backup-10\.[1-9]\).*/\\1/' | uniq`
    if [ -z "$mbackup" ] ; then
      echo "Test warning: mariabackup is not available for installing?"
      exit 1
    fi
  fi
  echo "Installing $mbackup"
  if ! sudo sh -c "DEBIAN_FRONTEND=noninteractive MYSQLD_STARTUP_TIMEOUT=180 apt-get install --allow-unauthenticated -y $mbackup socat" ; then
    echo "Test warning: failed to install MariaBackup"
    exit 1
  fi
elif [ "$sst_mode" == "xtrabackup-v2" ] ; then
  sudo wget https://repo.percona.com/apt/percona-release_${xtrabackup_version}.${version_name}_all.deb
  sudo dpkg -i percona-release_${xtrabackup_version}.${version_name}_all.deb
  sudo apt-get update
  if ! sudo sh -c "DEBIAN_FRONTEND=noninteractive MYSQLD_STARTUP_TIMEOUT=180 apt-get install --allow-unauthenticated -y percona-xtrabackup-24 socat" ; then
    echo "Test warning: could not install XtraBackup, check if it's available for this version/architecture"
    exit 1
  fi
fi
echo "Run MTR tests for the corresponding SST method ($sst_mode)"
sudo sh -c "DEBIAN_FRONTEND=noninteractive MYSQLD_STARTUP_TIMEOUT=180 apt-get install --allow-unauthenticated $allow_downgrades -y mariadb-test"
cd /usr/share/mysql/mysql-test
perl mysql-test-run.pl --vardir="$(readlink -f /dev/shm/var)" --force --max-save-core=0 --max-save-datadir=0 --big-test --suite=galera --do-test=galera_sst_${sst_mode}*
res=$?
rm -rf /home/buildbot/var
cp -r /dev/shm/var /home/buildbot
if [ $res -ne 0 ] ; then
    echo "ERROR: MTR tests failed"
    exit $res
fi
sudo cp -r /var/lib/mysql /var/lib/node1
sudo cp -r /var/lib/mysql /var/lib/node2
sudo cp -r /var/lib/mysql /var/lib/node3
sudo chown -R mysql:mysql /var/lib/node1 /var/lib/node2 /var/lib/node3
# To make sure that xtrabackup / mariabackup works with the right datadir
sudo mv /var/lib/mysql /var/lib/mysql.save
sudo sh -c "echo '
[galera]
wsrep-on
binlog-format=ROW
wsrep_sst_method=$sst_mode
wsrep_provider=libgalera_smm.so
' > /etc/mysql/conf.d/galera.cnf"
if [ "$sst_mode" == "mysqldump" ] ; then
  sudo sh -c "echo 'bind-address=0.0.0.0' >> /etc/mysql/conf.d/galera.cnf"
fi
if [ "$sst_mode" != "rsync" ] ; then
  sudo sh -c "echo 'wsrep_sst_auth=galera:gal3ra123' >> /etc/mysql/conf.d/galera.cnf"
fi
echo '
[mysqld]
port=8301
socket=/tmp/node1.sock
pid-file=/tmp/node1.pid
datadir=/var/lib/node1
server-id=1
log-error=node1.err
wsrep_cluster_address=gcomm://127.0.0.1:4566,127.0.0.1:4567?gmcast.listen_addr=tcp://127.0.0.1:4565
wsrep_node_address=127.0.0.1:4565
[mysqld_safe]
socket=/tmp/node1.sock
pid-file=/tmp/node1.pid
log-error=/var/lib/node1/node1.err
skip-syslog
' > /home/buildbot/node1.cnf
echo '
[mysqld]
port=8302
socket=/tmp/node2.sock
pid-file=/tmp/node2.pid
datadir=/var/lib/node2
server-id=2
log-error=node2.err
wsrep_cluster_address=gcomm://127.0.0.1:4565?gmcast.listen_addr=tcp://127.0.0.1:4566
wsrep_node_address=127.0.0.1:4566
[mysqld_safe]
socket=/tmp/node2.sock
pid-file=/tmp/node2.pid
log-error=/var/lib/node2/node2.err
skip-syslog
' > /home/buildbot/node2.cnf
echo '
[mysqld]
port=8303
socket=/tmp/node3.sock
pid-file=/tmp/node3.pid
datadir=/var/lib/node3
server-id=3
log-error=node3.err
wsrep_cluster_address=gcomm://127.0.0.1:4565?gmcast.listen_addr=tcp://127.0.0.1:4567
wsrep_node_address=127.0.0.1:4567
[mysqld_safe]
socket=/tmp/node3.sock
pid-file=/tmp/node3.pid
log-error=/var/lib/node3/node3.err
skip-syslog
' > /home/buildbot/node3.cnf
chmod uga+r /home/buildbot/node*.cnf
sudo mysqld_safe --defaults-extra-file=/home/buildbot/node1.cnf --user=mysql --wsrep-new-cluster &
mysql -uroot -prootpass --port=8301 --protocol=tcp -e "DROP database mgc IF EXISTS"
for i in 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ; do
  sleep 2
  if mysql -uroot -prootpass --port=8301 --protocol=tcp -e "create database mgc; create table mgc.t1 (i int); insert into mgc.t1 values (1); select * from mgc.t1" ; then
    break
  fi
done
# We can't start both nodes at once, because it causes rsync port conflict
# (and maybe some other SST methods will have problems too)
for node in 2 3 ; do
  if [ "$sst_mode" == "rsync" ] ; then
    sudo killall rsync
  fi
  sudo mysqld_safe --defaults-extra-file=/home/buildbot/node$node.cnf --user=mysql &
  for i in 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ; do
    if ! mysql -uroot -prootpass --port=830$node --protocol=tcp -e "select * from mgc.t1" ; then
      sleep 3
    else
      break
    fi
  done
done
mysql -uroot -prootpass --port=8301 --protocol=tcp -e "show status like 'wsrep_cluster_size'"
sudo chmod uga+r /var/lib/node*/node*.err
if [ "$sst_mode" == "mariabackup" ] ; then
  mkdir /home/buildbot/mariabackup_logs
  for node in 1 2 3 ; do
    for log in prepare move backup ; do
      sudo cp /var/lib/node${node}/mariabackup.${log}.log /home/buildbot/mariabackup_logs/node${node}.mariabackup.${log}.log
    done
  done
  sudo chown -R buildbot:buildbot /home/buildbot/mariabackup_logs
fi
set -e
mysql -uroot -prootpass --port=8301 --protocol=tcp -e "show status like 'wsrep_cluster_size'" | grep 3
mysql -uroot -prootpass --port=8302 --protocol=tcp -e "select * from mgc.t1"
mysql -uroot -prootpass --port=8303 --protocol=tcp -e "select * from mgc.t1"
mysql -uroot -prootpass --port=8303 --protocol=tcp -e "drop table mgc.t1"
! mysql -uroot -prootpass --port=8302 --protocol=tcp -e "set wsrep_sync_wait=15; select * from mgc.t1"
! mysql -uroot -prootpass --port=8301 --protocol=tcp -e "set wsrep_sync_wait=15; select * from mgc.t1"

sudo pkill --signal 9 mysqld 2> /dev/null || true
sudo pkill --signal 9 mariadb 2> /dev/null || true
sudo pkill --signal 9 mysqld_safe 2> /dev/null || true
""")])


def getDebMinorUpgradeStep():
     return Test(
        name="upgrade",
        haltOnFailure=True,
        description=["testing", "upgrade"],
        descriptionDone=["test", "upgrade"],
        command=["bash", "-xc", util.Interpolate("""
		set -x
		test_mode=%(prop:test_mode)s
		test_type=%(prop:test_type)s

		case "%(prop:branch)s" in
		*galera*)
		  if [[ "$test_mode" == "all" ]] ; then
		    echo "Upgrade warning: the test in 'all' mode is not executed for galera branches"
		    exit
		  fi
		  ;;
		*%(kw:development_branch)s*)
		  if [[ "$test_mode" != "server" ]] ; then
		    echo "Upgrade warning: For non-stable branches the test is only run in 'test' mode"
		    exit
		  fi
		  ;;
		esac
		arch=%(prop:arch)s
		if [[ "$arch" == "ppc64le" ]] ; then
		  arch=ppc64el
		elif [[ "$arch" == "x86" ]] ; then
		  arch=i386
		fi
		dist_name=%(prop:dist_name)s
		version_name=%(prop:version_name)s
		major_version=%(prop:major_version)s

		prev_major_version=$major_version
		# For now we rely on major_version being 10.1 or higher, can add a check later
		if [[ "$test_type" == "major" ]] ; then
		    minor_version_num=`echo $major_version | sed -e 's/10\.\([0-9]*\)/\\1/'`
		    ((prev_minor_version_num = minor_version_num - 1))
		    prev_major_version=10.$prev_minor_version_num
		fi


		echo "Architecture, distribution and version based on VM name: $arch $dist_name $version_name"
		echo "Test properties"
		echo "  Systemd capability %(prop:systemdCapability)s"
		echo "  Major version %(prop:major_version)s"
		echo "  Previous major version $prev_major_version"
		#===============
		# This test can be performed in four modes:
		# - 'server' -- only mariadb-server is installed (with whatever dependencies it pulls) and upgraded.
		# - 'all'    -- all provided packages are installed and upgraded, except for Columnstore
		# - 'deps'   -- only a limited set of main packages is installed and upgraded,
		#               to make sure upgrade does not require new dependencies
		# - 'columnstore' -- mariadb-server and mariadb-plugin-columnstore are installed
		#===============
		echo "Current test mode: $test_mode"
		#============
		# Environment
		#============
		dpkg -l | grep -iE 'maria|mysql|galera'
		lsb_release -a
		uname -a
		df -kT
		#========================================
		# Check whether a previous version exists
		#========================================
		if ! wget http://mirror.netinch.com/pub/mariadb/repo/$prev_major_version/$dist_name/dists/$version_name/main/binary-$arch/Packages
		then
		  echo "Upgrade warning: could not find the 'Packages' file for a previous version in MariaDB repo, skipping the test"
		  exit
		fi
		#===============================================
		# Define the list of packages to install/upgrade
		#===============================================
		case $test_mode in
		all)
		  if grep -i columnstore Packages > /dev/null ; then
		    echo "Upgrade warning: Due to MCOL-4120 (Columnstore leaves the server shut down) and other bugs Columnstore upgrade is tested separately"
		  fi
		  package_list=`grep -B 1 'Source: mariadb-' Packages | grep 'Package:' | grep -vE 'galera|spider|columnstore' | awk '{print $2}' | sort | uniq | xargs`
		  if grep -i spider Packages > /dev/null ; then
		    echo "Upgrade warning: Due to MDEV-14622 Spider will be installed separately after the server"
		    spider_package_list=`grep -B 1 'Source: mariadb-' Packages | grep 'Package:' | grep 'spider' | awk '{print $2}' | sort | uniq | xargs`
		  fi
		  if grep -i tokudb Packages > /dev/null ; then
		    # For the sake of installing TokuDB, disable hugepages
		    sudo sh -c "echo never > /sys/kernel/mm/transparent_hugepage/enabled" || true
		  fi
		  ;;
		deps)
		  package_list="mariadb-server mariadb-client mariadb-common mariadb-test mysql-common libmysqlclient18"
		  ;;
		server)
		  package_list=mariadb-server
		  ;;
		columnstore)
		  if ! grep columnstore Packages > /dev/null ; then
		    echo "Upgrade warning: Columnstore was not found in packages, the test will not be run"
		    exit
		  fi
		  package_list="mariadb-server "`grep -B 1 'Source: mariadb-' Packages | grep 'Package:' | grep 'columnstore' | awk '{print $2}' | sort | uniq | xargs`
		  ;;
		*)
		  echo "ERROR: unknown test mode: $test_mode"
		  exit 1
		esac
		echo "Package_list: $package_list"
		#======================================================================
		# Prepare apt source configuration for installation of the last release
		#======================================================================
		sudo sh -c "echo 'deb [trusted=yes] http://mirror.netinch.com/pub/mariadb/repo/$prev_major_version/$dist_name $version_name main' > /etc/apt/sources.list.d/mariadb_upgrade.list"
		# We need to pin directory to ensure that installation happens from MariaDB repo
		# rather than from the default distro repo
		sudo sh -c "echo 'Package: *' > /etc/apt/preferences.d/release"
		sudo sh -c "echo 'Pin: origin mirror.netinch.com' >> /etc/apt/preferences.d/release"
		sudo sh -c "echo 'Pin-Priority: 1000' >> /etc/apt/preferences.d/release"
		sudo cp /etc/apt/sources.list /etc/apt/sources.list.backup
		sudo sh -c 'grep -v "^deb .*file" /etc/apt/sources.list.backup | grep -v "^deb-src .*file" > /etc/apt/sources.list'
		# Sometimes apt-get update fails because the repo is being updated.
		res=1
		for i in 1 2 3 4 5 6 7 8 9 10 ; do
		  if sudo apt-get update ; then
		    res=0
		    break
		  fi
		  echo "Upgrade warning: apt-get update failed, retrying ($i)"
		  sleep 10
		done
		if [[ $res -ne 0 ]] ; then
		  echo "ERROR: apt-get update failed"
		  exit $res
		fi
		function get_columnstore_logs () {
		  if [[ "$test_mode" == "columnstore" ]] ; then
		    echo "Storing Columnstore logs in columnstore_logs"
		    set +ex
		    # It is done in such a weird way, because Columnstore currently makes its logs hard to read
		    for f in `sudo ls /var/log/mariadb/columnstore | xargs` ; do
		      f=/var/log/mariadb/columnstore/$f
		      echo "----------- $f -----------" >> /home/buildbot/columnstore_logs
		      sudo cat $f 1>> /home/buildbot/columnstore_logs 2>&1
		    done
		    for f in /tmp/columnstore_tmp_files/* ; do
		      echo "----------- $f -----------" >> /home/buildbot/columnstore_logs
		      sudo cat $f >> /home/buildbot/columnstore_logs 2>&1
		    done
		  fi
		}
		#=========================
		# Install previous release
		#=========================
		# Debian installation/upgrade/startup always attempts to execute mysql_upgrade, and
		# also run mysqlcheck and such. Due to MDEV-14622, they are subject to race condition,
		# and can be executed later or even omitted.
		# We will wait till they finish, to avoid any clashes with SQL we are going to execute
		function wait_for_mysql_upgrade () {
		  set +x
		  res=1
		  for i in 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ; do
		    if ps -ef | grep -iE 'mysql_upgrade|mysqlcheck|mysqlrepair|mysqlanalyze|mysqloptimize|mariadb-upgrade|mariadb-check' | grep -v grep ; then
		      sleep 2
		    else
		      res=0
		      break
		    fi
		  done
		  set -x
		  if [[ $res -ne 0 ]] ; then
		    echo "ERROR: mysql_upgrade or alike have not finished in reasonable time"
		  fi
		}
		sudo sh -c "DEBIAN_FRONTEND=noninteractive MYSQLD_STARTUP_TIMEOUT=180 apt-get -o Dpkg::Options::=--force-confnew install --allow-unauthenticated -y $package_list"
		if [[ $? -ne 0 ]] ; then
		  echo "ERROR: Installation of a previous release failed, see the output above"
		  exit 1
		fi
		wait_for_mysql_upgrade
		if [ -n "$spider_package_list" ] ; then
		  sudo sh -c "DEBIAN_FRONTEND=noninteractive MYSQLD_STARTUP_TIMEOUT=180 apt-get -o Dpkg::Options::=--force-confnew install --allow-unauthenticated -y $spider_package_list"
		  if [[ $? -ne 0 ]] ; then
		    echo "ERROR: Installation of Spider from the previous release failed, see the output above"
		    exit 1
		  fi
		  wait_for_mysql_upgrade
		fi
		# To avoid confusing errors in further logic, do an explicit check
		# whether the service is up and running
		if [[ "%(prop:systemdCapability)s" == "yes" ]] ; then
		  if ! sudo systemctl status mariadb --no-pager ; then
		    sudo journalctl -xe --no-pager
		    get_columnstore_logs
		    echo "ERROR: mariadb service didn't start properly after installation"
		    exit 1
		  fi
		fi
		if [[ "$test_mode" == "all" ]] && [[ "%(prop:branch)s" == *"10."[5-9]* ]] ; then
		  echo "Upgrade warning: Due to MDEV-23061, an extra server restart is needed"
		  sudo systemctl restart mariadb
		fi
		#================================================================
		# Check that the server is functioning and create some structures
		#================================================================
		if [[ "%(prop:branch)s" == *"10."[4-9]* ]] ; then
		# 10.4+ uses unix_socket by default
		  sudo mysql -e "set password=password('rootpass')"
		else
		# Even without unix_socket, on some of VMs the password might be not pre-created as expected. This command should normally fail.
		  mysql -uroot -e "set password = password('rootpass')" >> /dev/null 2>&1
		fi
		# All the commands below should succeed
		set -e
		mysql -uroot -prootpass -e "CREATE DATABASE db"
		mysql -uroot -prootpass -e "CREATE TABLE db.t_innodb(a1 SERIAL, c1 CHAR(8)) ENGINE=InnoDB; INSERT INTO db.t_innodb VALUES (1,'foo'),(2,'bar')"
		mysql -uroot -prootpass -e "CREATE TABLE db.t_myisam(a2 SERIAL, c2 CHAR(8)) ENGINE=MyISAM; INSERT INTO db.t_myisam VALUES (1,'foo'),(2,'bar')"
		mysql -uroot -prootpass -e "CREATE TABLE db.t_aria(a3 SERIAL, c3 CHAR(8)) ENGINE=Aria; INSERT INTO db.t_aria VALUES (1,'foo'),(2,'bar')"
		mysql -uroot -prootpass -e "CREATE TABLE db.t_memory(a4 SERIAL, c4 CHAR(8)) ENGINE=MEMORY; INSERT INTO db.t_memory VALUES (1,'foo'),(2,'bar')"
		mysql -uroot -prootpass -e "CREATE ALGORITHM=MERGE VIEW db.v_merge AS SELECT * FROM db.t_innodb, db.t_myisam, db.t_aria"
		mysql -uroot -prootpass -e "CREATE ALGORITHM=TEMPTABLE VIEW db.v_temptable AS SELECT * FROM db.t_innodb, db.t_myisam, db.t_aria"
		mysql -uroot -prootpass -e "CREATE PROCEDURE db.p() SELECT * FROM db.v_merge"
		mysql -uroot -prootpass -e "CREATE FUNCTION db.f() RETURNS INT DETERMINISTIC RETURN 1"
		if [[ "$test_mode" == "columnstore" ]] ; then
		  if ! mysql -uroot -prootpass -e "CREATE TABLE db.t_columnstore(a INT, c VARCHAR(8)) ENGINE=ColumnStore; SHOW CREATE TABLE db.t_columnstore; INSERT INTO db.t_columnstore VALUES (1,'foo'),(2,'bar')" ; then
		    get_columnstore_logs
		    exit 1
		  fi
		fi
		set +e
		#====================================================================================
		# Store information about server version and available plugins/engines before upgrade
		#====================================================================================
		if [[ "$test_mode" == "all" ]] ; then
		  # Due to MDEV-14560, we have to restart the server to get the full list of engines
		  # MDEV-14560 is fixed in 10.2
		  if [[ "$prev_major_version" != *"10."[2-9]* ]] ; then
		    case "%(prop:systemdCapability)s" in
		    yes)
		      sudo systemctl restart mariadb
		      ;;
		    no)
		      sudo /etc/init.d/mysql restart
		      ;;
		    esac
		  fi
		fi
		mysql -uroot -prootpass --skip-column-names -e "select @@version" | awk -F'-' '{ print $1 }' > /tmp/version.old
		mysql -uroot -prootpass --skip-column-names -e "select engine, support, transactions, savepoints from information_schema.engines" | sort > /tmp/engines.old
		case "$prev_major_version" in
		5.5)
		  mysql -uroot -prootpass --skip-column-names -e "show plugins" | sort > /tmp/plugins.old
		  ;;
		10.[0-9])
		  mysql -uroot -prootpass --skip-column-names -e "select plugin_name, plugin_status, plugin_type, plugin_library, plugin_license from information_schema.all_plugins" | sort > /tmp/plugins.old
		  ;;
		*)
		  echo "ERROR: unknown major version: $prev_major_version"
		  exit 1
		  ;;
		esac
		# Store dependency information for old binaries/libraries:
		# - names starting with "mysql*" in the directory where mysqld is located;
		# - names starting with "mysql*" in the directory where mysql is located;
		# - everything in the plugin directories installed by any MariaDB packages
		set +x
		for i in `sudo which mysqld | sed -e 's/mysqld$/mysql\*/'` `which mysql | sed -e 's/mysql$/mysql\*/'` `dpkg-query -L \`dpkg -l | grep mariadb | awk '{print $2}' | xargs\` | grep -v 'mysql-test' | grep -v '/debug/' | grep '/plugin/' | sed -e 's/[^\/]*$/\*/' | sort | uniq | xargs` ; do echo "=== $i"; ldd $i | sort | sed 's/(.*)//' ; done > /buildbot/ldd.old
		set -x
		#=========================================
		# Restore apt configuration for local repo
		#=========================================
		cd debs
		dpkg-scanpackages binary /dev/null | gzip -9c > binary/Packages.gz
		dpkg-scansources source /dev/null | gzip -9c > source/Sources.gz
		cd ..

		chmod -cR go+r debs

		if [ -e debs/binary/Packages.gz ] ; then
		    gunzip debs/binary/Packages.gz
		fi

		if [ "%(prop:needsGalera)s" == "yes" ]
		then
		  if ! wget http://yum.mariadb.org/galera/repo/deb/dists/$version_name
		  # Override the location of the library for versions which don't have their own
		  then
		    if [ "$dist_name" == "debian" ] ; then
		      sudo sh -c "echo 'deb [trusted=yes] http://yum.mariadb.org/galera/repo/deb stretch main' > /etc/apt/sources.list.d/galera-test-repo.list"
		    else
		      sudo sh -c "echo 'deb [trusted=yes] http://yum.mariadb.org/galera/repo/deb xenial main' > /etc/apt/sources.list.d/galera-test-repo.list"
		    fi
		  else
		    sudo sh -c "echo 'deb [trusted=yes] http://yum.mariadb.org/galera/repo/deb $version_name main' > /etc/apt/sources.list.d/galera-test-repo.list"
		  fi
		  # Update galera-test-repo.list to point at either the galera-3 or galera-4 test repo
		  case "%(prop:branch)s" in
		  *10.[1-3]*)
		    sudo sed -i 's/repo/repo3/' /etc/apt/sources.list.d/galera-test-repo.list
		    ;;
		  *10.[4-9]*)
		    sudo sed -i 's/repo/repo4/' /etc/apt/sources.list.d/galera-test-repo.list
		    ;;
		  esac
		fi

		if [[ "$test_mode" == "deps" ]] ; then
		  # For the dependency check, only keep the local repo
		  sudo sh -c "grep -iE 'deb .*file|deb-src .*file' /etc/apt/sources.list.backup > /etc/apt/sources.list"
		  sudo rm -rf /etc/apt/sources.list.d/*
		else
		  sudo cp /etc/apt/sources.list.backup /etc/apt/sources.list
		  sudo rm /etc/apt/sources.list.d/mariadb_upgrade.list
		fi
		sudo rm /etc/apt/preferences.d/release
		sudo sh -c "echo 'deb [trusted=yes] file:$(pwd)/debs binary/' >> /etc/apt/sources.list"
		# Sometimes apt-get update fails because the repo is being updated.
		res=1
		for i in 1 2 3 4 5 6 7 8 9 10 ; do
		  if sudo apt-get update ; then
		    res=0
		    break
		  fi
		  echo "Upgrade warning: apt-get update failed, retrying ($i)"
		  sleep 10
		done
		if [[ $res -ne 0 ]] ; then
		  echo "ERROR: apt-get update failed"
		  exit $res
		fi
		#=========================
		# Install the new packages
		#=========================
		sudo sh -c "DEBIAN_FRONTEND=noninteractive MYSQLD_STARTUP_TIMEOUT=180 apt-get -o Dpkg::Options::=--force-confnew install --allow-unauthenticated -y $package_list"
		if [[ $? -ne 0 ]] ; then
		  echo "ERROR: Installation of the new packages failed, see the output above"
		  exit 1
		fi
		wait_for_mysql_upgrade
		if [ -n "$spider_package_list" ] ; then
		  sudo sh -c "DEBIAN_FRONTEND=noninteractive MYSQLD_STARTUP_TIMEOUT=180 apt-get -o Dpkg::Options::=--force-confnew install --allow-unauthenticated -y $spider_package_list"
		  if [[ $? -ne 0 ]] ; then
		    echo "ERROR: Installation of the new Spider packages failed, see the output above"
		    exit 1
		  fi
		  wait_for_mysql_upgrade
		fi
		if [[ "$test_mode" == "columnstore" ]] ; then
		  echo "Upgrade warning: Due to MCOL-4120 an extra server restart is needed"
		  sudo systemctl restart mariadb
		fi
		#==========================================================
		# Wait till mysql_upgrade, mysqlcheck and such are finished
		#==========================================================
		# Again, wait till mysql_upgrade is finished, to avoid clashes;
		# and for non-stable versions, it might be necessary, so run it again
		# just in case it was omitted
		wait_for_mysql_upgrade
		# run mysql_upgrade for non GA branches
		if [[ "%(prop:major_version)s" == %(kw:development_branch)s ]] ; then
		  mysql_upgrade -uroot -prootpass
		fi
		#================================
		# Make sure that the new server is running
		#================================
		if mysql -uroot -prootpass -e "select @@version" | grep `cat /tmp/version.old` ; then
		  echo "ERROR: The server was not upgraded or was not restarted after upgrade"
		  exit 1
		fi
		#===================================================
		# Check that no old packages have left after upgrade
		#===================================================
		# The check is only performed for all-package-upgrade, because
		# for selective ones some implicitly installed packages might not be upgraded
		if [[ "$test_mode" == "all" ]] ; then
		  if dpkg -l | grep -iE 'mysql|maria' | grep `cat /tmp/version.old` ; then
		    echo "ERROR: Old packages have been found after upgrade"
		    exit 1
		  fi
		fi
		#=====================================================================================
		# Check that the server is functioning and previously created structures are available
		#=====================================================================================
		# All the commands below should succeed
		set -e
		mysql -uroot -prootpass -e "select @@version, @@version_comment"
		mysql -uroot -prootpass -e "SHOW TABLES IN db"
		mysql -uroot -prootpass -e "SELECT * FROM db.t_innodb; INSERT INTO db.t_innodb VALUES (3,'foo'),(4,'bar')"
		mysql -uroot -prootpass -e "SELECT * FROM db.t_myisam; INSERT INTO db.t_myisam VALUES (3,'foo'),(4,'bar')"
		mysql -uroot -prootpass -e "SELECT * FROM db.t_aria; INSERT INTO db.t_aria VALUES (3,'foo'),(4,'bar')"
		echo "If the next INSERT fails with a duplicate key error,"
		echo "it is likely because the server was not upgraded or restarted after upgrade"
		mysql -uroot -prootpass -e "SELECT * FROM db.t_memory; INSERT INTO db.t_memory VALUES (1,'foo'),(2,'bar')"
		mysql -uroot -prootpass -e "SELECT COUNT(*) FROM db.v_merge"
		mysql -uroot -prootpass -e "SELECT COUNT(*) FROM db.v_temptable"
		mysql -uroot -prootpass -e "CALL db.p()"
		mysql -uroot -prootpass -e "SELECT db.f()"
		if [[ "$test_mode" == "columnstore" ]] ; then
		  if ! mysql -uroot -prootpass -e "SELECT * FROM db.t_columnstore; INSERT INTO db.t_columnstore VALUES (3,'foo'),(4,'bar')" ; then
		    get_columnstore_logs
		    exit 1
		  fi
		fi
		set +e
		#===================================================================================
		# Store information about server version and available plugins/engines after upgrade
		#===================================================================================
		set -e
		mysql -uroot -prootpass --skip-column-names -e "select @@version" | awk -F'-' '{ print $1 }' > /tmp/version.new
		mysql -uroot -prootpass --skip-column-names -e "select engine, support, transactions, savepoints from information_schema.engines" | sort > /tmp/engines.new
		case "%(prop:major_version)s" in
		5.5)
		  mysql -uroot -prootpass --skip-column-names -e "show plugins" | sort > /tmp/plugins.new
		  ;;
		10.[0-9])
		  mysql -uroot -prootpass --skip-column-names -e "select plugin_name, plugin_status, plugin_type, plugin_library, plugin_license from information_schema.all_plugins" | sort > /tmp/plugins.new
		  ;;
		esac
		# Dependency information for new binaries/libraries
		set +x
		for i in `sudo which mysqld | sed -e 's/mysqld$/mysql\*/'` `which mysql | sed -e 's/mysql$/mysql\*/'` `dpkg-query -L \`dpkg -l | grep mariadb | awk '{print $2}' | xargs\` | grep -v 'mysql-test' | grep -v '/debug/' | grep '/plugin/' | sed -e 's/[^\/]*$/\*/' | sort | uniq | xargs` ; do echo "=== $i"; ldd $i | sort | sed 's/(.*)//' ; done > /home/buildbot/ldd.new
		set -x
		case "%(prop:systemdCapability)s" in
		yes)
		  ls -l /lib/systemd/system/mariadb.service
		  ls -l /etc/systemd/system/mariadb.service.d/migrated-from-my.cnf-settings.conf
		  ls -l /etc/init.d/mysql || true
		  systemctl --no-pager status mariadb.service
		  systemctl --no-pager status mariadb
		  systemctl --no-pager status mysql
		  systemctl --no-pager status mysqld
		  systemctl --no-pager is-enabled mariadb
		  ;;
		no)
		  echo "Steps related to systemd will be skipped"
		  ;;
		*)
		  echo "ERROR: It should never happen, check your configuration (systemdCapability property is not set or is set to a wrong value)"
		  exit 1
		  ;;
		esac
		set +e
		# This output is for informational purposes
		diff -u /tmp/engines.old /tmp/engines.new
		diff -u /tmp/plugins.old /tmp/plugins.new
		case "%(prop:branch)s" in
		*%(kw:development_branch)s*)
		  echo "Until %(kw:development_branch)s is GA, the list of plugins/engines might be unstable, skipping the check"
		  ;;
		*)
		  # Only fail if there are any disappeared/changed engines or plugins
		  disappeared_or_changed=`comm -23 /tmp/engines.old /tmp/engines.new | wc -l`
		  if [[ $disappeared_or_changed -ne 0 ]] ; then
		    echo "ERROR: the lists of engines in the old and new installations differ"
		    exit 1
		  fi
                  if [[ "$test_type" == "minor" ]] ; then
		  	disappeared_or_changed=`comm -23 /tmp/plugins.old /tmp/plugins.new | wc -l`
		  	if [[ $disappeared_or_changed -ne 0 ]] ; then
		    		echo "ERROR: the lists of plugins in the old and new installations differ"
		    		exit 1
		  	fi
		  fi
		  set -o pipefail
		  if [ "$test_mode" == "all" ] ; then
		    set -o pipefail
		    if wget --timeout=20 --no-check-certificate https://raw.githubusercontent.com/MariaDB/mariadb.org-tools/master/buildbot/baselines/ldd.%(prop:major_version)s.${version_name}.${arch} -O /tmp/ldd.baseline > /dev/null ; then
		      ldd_baseline=/tmp/ldd.baseline
		    else
		      ldd_baseline=/buildbot/ldd.old
		    fi
		    diff -U1000 $ldd_baseline /home/buildbot/ldd.new | ( grep -E '^[-+]|^ =' || true )
		    if [[ $? -ne 0 ]] ; then
		      echo "ERROR: something has changed in the dependencies of binaries or libraries. See the diff above"
		      exit 1
		    fi
		  fi
		  set +o pipefail
		  ;;
		esac
		diff -u /tmp/version.old /tmp/version.new
		if [[ $? -eq 0 ]] ; then
		  echo "ERROR: server version has not changed after upgrade"
		  echo "It can be a false positive if we forgot to bump version after release,"
		  echo "or if it is a development tree is based on an old version"
		  exit 1
		fi
""", development_branch=DEVELOPMENT_BRANCH)])	

def getDebUpgradeStep():
     return Test(
        name="upgrade",
        haltOnFailure=True,
        description=["testing", "upgrade"],
        descriptionDone=["test", "upgrade"],
        command=["bash", "-xc", util.Interpolate("""
		set -ex

		dpkg -l | grep -iE 'maria|mysql|galera' || true
		old_ver=`dpkg -l | grep -iE 'mysql-server-|mariadb-server-' | head -1 | awk '{print $2}' | sed -e "s/.*\(mysql\|mariadb\)-server-\(5\.[567]\|10\.[0-9]\).*/\\1-\\2/"`

		# version_arch is "trusty-ppc64le" etc.
		version_arch='%(prop:version_name)s'
		dist_name='%(prop:dist_name)s'
		version_name='%(prop:version_name)s'

		sudo sh -c "echo 'deb [trusted=yes] file:$(pwd)/debs binary/' >> /etc/apt/sources.list"

		cd debs
		dpkg-scanpackages binary /dev/null | gzip -9c > binary/Packages.gz
		dpkg-scansources source /dev/null | gzip -9c > source/Sources.gz
		cd ..

		chmod -cR go+r debs

		if [ -e debs/binary/Packages.gz ] ; then
		    gunzip debs/binary/Packages.gz
		fi

		package_version=`ls debs/binary/mariadb-server_* | head -n 1 | sed -e 's/.*mariadb-server_\([0-9]*\.[0-9]*\.[0-9]*\).*/\\1/'`
		packages_to_install="mariadb-server mariadb-client libmariadbclient18"

		case "$old_ver-%(prop:mariadb_version)s" in
		mysql-5.7-10.[0-1])
		  echo "Upgrade warning: cannot downgrade from InnoDB 5.7 to 5.6"
		  exit
		  ;;
		mysql-5.[67]-5.5)
		  echo "Upgrade warning: cannot downgrade from InnoDB $old_ver to 5.5"
		  exit
		  ;;
		mariadb-10.[0-9]-5.5)
		  echo "Upgrade warning: Downgrade from $old_ver to 5.5 is not expected to work"
		  exit
		  ;;
		mariadb-10.[0-9]-10.[0-9])
		  if [[ "$old_ver" > "mariadb-%(prop:mariadb_version)s" ]] ; then
		    echo "Upgrade warning: Downgrade from $old_ver to %(prop:major_version)s is not expected to work"
		    exit
		  fi
		  if [[ "$old_ver" == "mariadb-%(prop:mariadb_version)s" ]]
		  then
		    # 3rd column is the package version, e.g. 10.1.23-9+deb9u1 vs 10.1.23+maria-1~stretch
		    if ! dpkg -l | grep -i mariadb-server- | head -1 | awk '{print $3}' | grep maria
		    then
		      echo "Upgrade warning: MDEV-11979 - cannot upgrade from Debian packages to MariaDB packages of the same major version"
		      exit
		    fi
		  fi
		  ;;
		mysql*-8.0-*)
		  echo "Upgrade warning: live upgrade from MySQL 8.0 is not supported, re-installation with dump/restore will be performed instead"
		  replace_incompatible_version=8.0
		  ;;
		*)
		  echo "Upgrade from MySQL $old_ver to MariaDB %(prop:mariadb_version)s will be attempted"
		  ;;
		esac
		if [ "%(prop:needsGalera)s" == "yes" ]
		then
		  if ! wget http://yum.mariadb.org/galera/repo/deb/dists/$version_name
		  # Override the location of the library for versions which don't have their own
		  then
		    if [ "$dist_name" == "debian" ] ; then
		      sudo sh -c "echo 'deb [trusted=yes] http://yum.mariadb.org/galera/repo/deb stretch main' > /etc/apt/sources.list.d/galera-test-repo.list"
		    else
		      sudo sh -c "echo 'deb [trusted=yes] http://yum.mariadb.org/galera/repo/deb xenial main' > /etc/apt/sources.list.d/galera-test-repo.list"
		    fi
		  else
		    sudo sh -c "echo 'deb [trusted=yes] http://yum.mariadb.org/galera/repo/deb $version_name main' > /etc/apt/sources.list.d/galera-test-repo.list"
		  fi
		  # Update galera-test-repo.list to point at either the galera-3 or galera-4 test repo
		  case "%(prop:branch)s" in
		  *10.[1-3]*)
		    sudo sed -i 's/repo/repo3/' /etc/apt/sources.list.d/galera-test-repo.list
		    ;;
		  *10.[4-9]*)
		    sudo sed -i 's/repo/repo4/' /etc/apt/sources.list.d/galera-test-repo.list
		    ;;
		  esac
		fi
		chmod -cR go+r debs
		# Sometimes apt-get update fails because the repo is being updated.
		for i in 1 2 3 4 5 6 7 8 9 10 ; do
		  if sudo apt-get update ; then
		    break
		  fi
		  echo "Upgrade warning: apt-get update failed, retrying ($i)"
		  sleep 10
		done
		# On some of VMs the password might be not pre-created as expected
		if mysql -uroot -e "set password = password('rootpass')" ; then
		  echo "The password has now been set"
		# Or, Debian packages local root might be using unix_socket plugin even with older versions.
		# Change it to the normal password authentication
		elif sudo mysql -uroot -e "update mysql.user set plugin = 'mysql_native_password'; flush privileges; set password = password('rootpass')" ; then
		  echo "The error above does not mean a test failure, it's one of expected outcomes"
		  echo "Unix socket authentication has been unset"
		else
		  echo "Errors above do not mean a test failure, it's one of expected outcomes"
		fi
		mysql -uroot -prootpass -e "CREATE DATABASE if not exists mytest"
		mysql -uroot -prootpass -e "use mytest; drop table if exists upgrade_test; create table upgrade_test (pk int primary key auto_increment, c char(64), v varchar(2048), d date, t time, dt datetime, ts timestamp) engine=InnoDB; begin; insert into upgrade_test values (null, 'test', 'test', date(now()), time(now()), now(), now());  insert into upgrade_test select null, 'test', 'test', date(now()), time(now()), now(), now() from upgrade_test; insert into upgrade_test select null, 'test', 'test', date(now()), time(now()), now(), now() from upgrade_test; insert into upgrade_test select null, 'test', 'test', date(now()), time(now()), now(), now() from upgrade_test; insert into upgrade_test select null, 'test', 'test', date(now()), time(now()), now(), now() from upgrade_test; insert into upgrade_test select null, 'test', 'test', date(now()), time(now()), now(), now() from upgrade_test; insert into upgrade_test select null, 'test', 'test', date(now()), time(now()), now(), now() from upgrade_test; insert into upgrade_test select null, 'test', 'test', date(now()), time(now()), now(), now() from upgrade_test; insert into upgrade_test select null, 'test', 'test', date(now()), time(now()), now(), now() from upgrade_test; insert into upgrade_test select null, 'test', 'test', date(now()), time(now()), now(), now() from upgrade_test; insert into upgrade_test select null, 'test', 'test', date(now()), time(now()), now(), now() from upgrade_test; insert into upgrade_test select null, 'test', 'test', date(now()), time(now()), now(), now() from upgrade_test; insert into upgrade_test select null, 'test', 'test', date(now()), time(now()), now(), now() from upgrade_test; commit" --force
		mysql -uroot -prootpass --skip-column-names -e "select @@version" | awk -F'-' '{ print $1 }' > /tmp/version.old
		old_version=`cat /tmp/version.old`
		# If the tested branch has the same version as the public repository,
		# upgrade won't work properly. For releasable branches, we will return an error
		# urging to bump the version number. For other branches, we will abort the test
		# with a warning (which nobody will read). This is done upon request from
		# development, as temporary branches might not be rebased in a timely manner
		if [ "$package_version" == "$old_version" ] ; then
		    echo "ERROR: Server version $package_version has already been released. Bump the version number!"
		    for b in %(kw:releasable_branches)s ; do
			if [ "$b" == "%(prop:branch)s" ] ; then
			    exit 1
			fi
		    done
		    echo "The test will be skipped, as upgrade will not work properly"
		    exit 0
		fi
		mysql -uroot -prootpass -e "CREATE DATABASE autoinc; CREATE TABLE autoinc.t_autoinc(a SERIAL) ENGINE=InnoDB SELECT 42 a"
		mysql -uroot -prootpass -e "CREATE TABLE autoinc.t_autoinc2(a SERIAL) ENGINE=InnoDB; BEGIN; INSERT INTO autoinc.t_autoinc2 VALUES (NULL),(NULL); ROLLBACK; SHOW CREATE TABLE autoinc.t_autoinc2 \G"
		if [ -n "$replace_incompatible_version" ] ; then
		  mysqldump -uroot -prootpass -E --triggers --routines --databases mytest autoinc > ~/mysql.dump
		# See notes in MDEV-21179, possibly more adjustments will have to be added here with time
		  sed -i 's/utf8mb4_0900_ai_ci/utf8mb4_general_ci/g' ~/mysql.dump
		  sudo apt-get purge -y `dpkg -l | grep mysql | grep "$replace_incompatible_version" | grep -E '^ii' | awk '{ print $2 }' | xargs`
		# On some reason apt-get purge for 8.0.18 doesn't remove /var/lib/mysql, maybe because mysql-common-5.8 remains
		  sudo mv /var/lib/mysql /var/lib/mysql.backup.$replace_incompatible_version || true
		fi
		sudo sh -c "DEBIAN_FRONTEND=noninteractive MYSQLD_STARTUP_TIMEOUT=180 apt-get install --allow-unauthenticated -y $packages_to_install"
		if [ -n "$replace_incompatible_version" ] ; then
		# Since we re-installed system tables, we need to adjust the password again
		  if sudo mysql -uroot -e "set password = password('rootpass')" ; then
		    echo "The password has now been set"
		  elif sudo mysql -uroot -e "update mysql.user set plugin = 'mysql_native_password'; flush privileges; set password = password('rootpass')" ; then
		    echo "The error above does not mean a test failure, it's one of expected outcomes"
		    echo "Unix socket authentication has been unset"
		  else
		    echo "Errors above do not mean a test failure, it's one of expected outcomes"
		  fi
		  mysql -uroot -prootpass < ~/mysql.dump
		fi
		mysql -uroot -prootpass --skip-column-names -e "INSERT INTO autoinc.t_autoinc SET a=NULL;  SELECT COUNT(*) Expect_2 FROM autoinc.t_autoinc WHERE a>=42"
		echo "Prior to MDEV-6076, the next SELECT would return 1. After MDEV-6076, it should be 3"
		mysql -uroot -prootpass --skip-column-names -e "INSERT INTO autoinc.t_autoinc2 VALUES (NULL); SELECT * FROM autoinc.t_autoinc2"
		mysql -uroot -prootpass -e "select @@version, @@version_comment"
		mysql -uroot -prootpass --skip-column-names -e "select @@version" | awk -F'-' '{ print $1 }' > /tmp/version.new
		echo "The next line must show a difference between versions, otherwise it's a failure"
		echo "It can be a false positive if we forgot to bump version after release,"
		echo "or if the tree is based on an old version"
		! diff -u  /tmp/version.old  /tmp/version.new
		sudo cat /var/lib/mysql/mysql_upgrade_info | awk -F'-' '{ print $1 }' > /tmp/version.upgrade
		# mysql_upgrade is run automatically in deb packages
		# TODO: something weird goes on with mysql_upgrade, to be checked later
		#diff -u /tmp/version.new /tmp/version.upgrade
		cat /tmp/version.new
		cat /tmp/version.upgrade
		case "%(prop:systemdCapability)s" in
		yes)
		  ls -l /lib/systemd/system/mariadb.service
		  ls -l /etc/systemd/system/mariadb.service.d/migrated-from-my.cnf-settings.conf
		  ls -l /etc/init.d/mysql || true
		  systemctl --no-pager status mariadb.service
		  systemctl --no-pager status mariadb
		  systemctl --no-pager status mysql
		  systemctl --no-pager status mysqld
		  systemctl --no-pager is-enabled mariadb
		  sudo systemctl --no-pager restart mariadb
		  systemctl --no-pager status mariadb
		  sudo journalctl -lxn 500 --no-pager | grep -iE 'mysqld|mariadb'
		  # It does not do the same as systemctl now
		  # /etc/init.d/mysql status
		  ;;
		no)
		  echo "Steps related to systemd will be skipped"
		  ;;
		*)
		  echo "It should never happen, check your configuration (systemdCapability property is not set or is set to a wrong value)"
		  ;;
		esac
		mysql -uroot -prootpass -e "use mytest; select count(*) from upgrade_test"
		# Workaround for MDEV-20298
		# and for libdbd-mariadb-perl not "pretending" to be DBD:mysql
		#if ! dpkg -l | grep -E 'libdbd-mysql-perl|libdbd-mariadb-perl' ; then
		if ! dpkg -l | grep libdbd-mysql-perl ; then
		  sudo apt-get install -y libdbd-mysql-perl
		fi
		perl -MDBD::mysql -e print
""", releasable_branches=RELEASABLE_BRANCHES)])

def getDebInstallStep():
     return Test(
        name="install",
        haltOnFailure=True,
        description=["testing", "install"],
        descriptionDone=["test", "install"],
        command=["bash", "-xc", util.Interpolate("""
		set -ex
		df -kT
		arch="amd64"
		dpkg -l | grep -iE 'maria|mysql|galera' || true
		# We want a clean installation here
		dpkg -l | grep -iE 'maria|mysql|galera' | awk '{print $2}' | xargs sudo apt-get remove -y
		dpkg -l | grep -iE 'maria|mysql|galera' | awk '{print $2}' | xargs sudo apt-get purge -y
		dist_name=%(prop:dist_name)s
		arch=%(prop:arch)s
		version_name=%(prop:version_name)s

		if [ "%(prop:needsGalera)s" == "yes" ]
		then
		  if ! wget http://yum.mariadb.org/galera/repo/deb/dists/$version_name
		  # Override the location of the library for versions which don't have their own
		  then
		    if [ "$dist_name" == "debian" ] ; then
		      sudo sh -c "echo 'deb [trusted=yes] http://yum.mariadb.org/galera/repo/deb stretch main' > /etc/apt/sources.list.d/galera-test-repo.list"
		    else
		      sudo sh -c "echo 'deb [trusted=yes] http://yum.mariadb.org/galera/repo/deb xenial main' > /etc/apt/sources.list.d/galera-test-repo.list"
		    fi
		  else
		    sudo sh -c "echo 'deb [trusted=yes] http://yum.mariadb.org/galera/repo/deb $version_name main' > /etc/apt/sources.list.d/galera-test-repo.list"
		  fi
		  # Update galera-test-repo.list to point at either the galera-3 or galera-4 test repo
		  case "%(prop:branch)s" in
		  *10.[1-3]*)
		    sudo sed -i 's/repo/repo3/' /etc/apt/sources.list.d/galera-test-repo.list
		    ;;
		  *10.[4-9]*)
		    sudo sed -i 's/repo/repo4/' /etc/apt/sources.list.d/galera-test-repo.list
		    ;;
		  esac
		fi

		sudo sh -c "echo 'deb [trusted=yes] file:$(pwd)/debs binary/' >> /etc/apt/sources.list"

		cd debs
		dpkg-scanpackages binary /dev/null | gzip -9c > binary/Packages.gz
		dpkg-scansources source /dev/null | gzip -9c > source/Sources.gz
		cd ..

		chmod -cR go+r debs

		if [ -e debs/binary/Packages.gz ] ; then
		    gunzip debs/binary/Packages.gz
		fi
		# Due to MDEV-14622 and its effect on Spider installation,
		# Spider has to be installed separately after the server
		package_list=`grep -B 1 'Source: mariadb-' debs/binary/Packages | grep 'Package:' | grep -vE 'galera|spider|columnstore' | awk '{print $2}' | xargs`
		if grep -i spider debs/binary/Packages > /dev/null ; then
		  spider_package_list=`grep -B 1 'Source: mariadb-' debs/binary/Packages | grep 'Package:' | grep 'spider' | awk '{print $2}' | xargs`
		fi
		if grep -i columnstore debs/binary/Packages > /dev/null ; then
		  if [[ "$arch" == "x86" ]] ; then
		    echo "Upgrade warning: Due to MCOL-4123, Columnstore won't be installed on x86"
		  else
		    columnstore_package_list=`grep -B 1 'Source: mariadb-' debs/binary/Packages | grep 'Package:' | grep 'columnstore' | awk '{print $2}' | xargs`
		  fi
		fi
		# Sometimes apt-get update fails because the repo is being updated.
		for i in 1 2 3 4 5 6 7 8 9 10 ; do
		  if sudo apt-get update ; then
		    break
		  fi
		  echo "Upgrade warning: apt-get update failed, retrying ($i)"
		  sleep 10
		done
		sudo sh -c "DEBIAN_FRONTEND=noninteractive MYSQLD_STARTUP_TIMEOUT=180 apt-get install --allow-unauthenticated -y $package_list $columnstore_package_list"
		# MDEV-14622: Wait for mysql_upgrade running in the background to finish
		res=1
		for i in 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ; do
		if ps -ef | grep -iE 'mysql_upgrade|mysqlcheck|mysqlrepair|mysqlanalyze|mysqloptimize|mariadb-upgrade|mariadb-check' | grep -v grep ; then
		  sleep 2
		else
		  res=0
		  break
		fi
		done
		if [[ $res -ne 0 ]] ; then
		  echo "Upgrade warning: mysql_upgrade or alike have not finished in reasonable time, different problems may occur"
		fi
		# To avoid confusing errors in further logic, do an explicit check
		# whether the service is up and running
		if [[ "%(prop:systemdCapability)s" == "yes" ]] ; then
		  if ! sudo systemctl status mariadb --no-pager ; then
		    sudo journalctl -xe --no-pager
		    echo "Upgrade warning: mariadb service isn't running properly after installation"
		    if echo $package_list | grep columnstore ; then
		      echo "It is likely to be caused by ColumnStore problems upon installation, getting the logs"
		      set +e
		      # It is done in such a weird way, because Columnstore currently makes its logs hard to read
		      for f in `sudo ls /var/log/mariadb/columnstore | xargs` ; do
			f=/var/log/mariadb/columnstore/$f
			echo "----------- $f -----------"
			sudo cat $f
		      done
		      for f in /tmp/columnstore_tmp_files/* ; do
			echo "----------- $f -----------"
			sudo cat $f
		      done
		    fi
		    echo "ERROR: mariadb service didn't start properly after installation"
		    exit 1
		  fi
		fi
		# Due to MDEV-14622 and its effect on Spider installation,
		# Spider has to be installed separately after the server
		if [ -n "$spider_package_list" ] ; then
		  sudo sh -c "DEBIAN_FRONTEND=noninteractive MYSQLD_STARTUP_TIMEOUT=180 apt-get install --allow-unauthenticated -y $spider_package_list"
		fi

		# Unix socket
		if [[ "%(prop:branch)s" == *"10."[4-9]* ]] ; then
  	          sudo mysql -e "set password=password('rootpass')"
	        else
		  # Even without unix_socket, on some of VMs the password might be not pre-created as expected. This command should normally fail.
		  mysql -uroot -e "set password = password('rootpass')" >> /dev/null 2>&1
		fi
		
		mysql --verbose -uroot -prootpass -e "create database test; use test; create table t(a int primary key) engine=innodb; insert into t values (1); select * from t; drop table t; drop database test; create user galera identified by 'gal3ra123'; grant all on *.* to galera;"
		mysql -uroot -prootpass -e "select @@version"
		echo "Test for MDEV-18563, MDEV-18526"
		set +e
		case "%(prop:systemdCapability)s" in
		yes)
		  sudo systemctl stop mariadb
		  ;;
		no)
		  sudo /etc/init.d/mysql stop
		  ;;
		esac
		sleep 1
		sudo pkill -9 mysqld
		for p in /bin /sbin /usr/bin /usr/sbin /usr/local/bin /usr/local/sbin ; do
		  if test -x $p/mysql_install_db ; then
		    sudo $p/mysql_install_db --no-defaults --user=mysql --plugin-maturity=unknown
		  else
		    echo "$p/mysql_install_db does not exist"
		  fi
		done
		sudo mysql_install_db --no-defaults --user=mysql --plugin-maturity=unknown
		set +e
		## Install mariadb-test for further use
		#sudo sh -c "DEBIAN_FRONTEND=noninteractive MYSQLD_STARTUP_TIMEOUT=180 apt-get install --allow-unauthenticated -y mariadb-test"
		if dpkg -l | grep -i spider > /dev/null ; then
		  echo "Upgrade warning: Workaround for MDEV-22979, otherwise server hangs further in SST steps"
		  sudo sh -c "DEBIAN_FRONTEND=noninteractive MYSQLD_STARTUP_TIMEOUT=180 apt-get remove --allow-unauthenticated -y mariadb-plugin-spider" || true
		  sudo sh -c "DEBIAN_FRONTEND=noninteractive MYSQLD_STARTUP_TIMEOUT=180 apt-get purge --allow-unauthenticated -y mariadb-plugin-spider" || true
		fi
		if dpkg -l | grep -i columnstore > /dev/null ; then
		  echo "Upgrade warning: Workaround for a bunch of Columnstore bugs, otherwise mysqldump in SST steps fails when Columnstore returns errors"
		  sudo sh -c "DEBIAN_FRONTEND=noninteractive MYSQLD_STARTUP_TIMEOUT=180 apt-get remove --allow-unauthenticated -y mariadb-plugin-columnstore" || true
		  sudo sh -c "DEBIAN_FRONTEND=noninteractive MYSQLD_STARTUP_TIMEOUT=180 apt-get purge --allow-unauthenticated -y mariadb-plugin-columnstore" || true
		fi
""")])

####### FACTORY CODE

## f_tarball - create source tarball
f_tarball = util.BuildFactory()
f_tarball.addStep(steps.SetProperty(property="dockerfile", value=util.Interpolate("%(kw:url)s", url=dockerfile), description="dockerfile"))
f_tarball.addStep(steps.ShellCommand(command=["echo", " revision: ", util.Property('revision')]))
f_tarball.addStep(steps.GitHub(
  repourl=util.Property('repository'),
  mode='full',
  method='clobber',
  workdir='build/server',
  shallow=True,
  submodules=True
))
f_tarball.addStep(steps.Compile(command=["cmake","../server"], workdir='build/mkdist', description="cmake"))
f_tarball.addStep(steps.Compile(command=["make", "dist"], workdir='build/mkdist', description="make dist"))
f_tarball.addStep(steps.SetPropertyFromCommand(property="mariadb_version", command="basename mariadb-*.tar.gz .tar.gz", workdir="build/mkdist"))
f_tarball.addStep(steps.SetPropertyFromCommand(property="master_branch", command=util.Interpolate("echo " + "%(prop:mariadb_version)s" + " | cut -d'-' -f 2 | cut -d'.' -f 1,2")))
f_tarball.addStep(steps.ShellCommand(command=util.Interpolate("mkdir -p %(prop:buildnumber)s/logs"), workdir="build/mkdist"))
f_tarball.addStep(steps.ShellCommand(command=util.Interpolate("sha256sum %(prop:mariadb_version)s" + ".tar.gz >> " + " %(prop:buildnumber)s" + "/sha256sums.txt" + " && mv %(prop:mariadb_version)s" +".tar.gz" + " %(prop:buildnumber)s"), workdir="build/mkdist"))
f_tarball.addStep(steps.SetPropertyFromCommand(command="ls -1 *.tar.gz", extract_fn=ls2list, workdir=util.Interpolate("build/mkdist/" + "%(prop:buildnumber)s")))
#f_tarball.addStep(steps.DirectoryUpload(workersrc=util.Interpolate('%(prop:builddir)s' + '/build/mkdist/' + '%(prop:buildnumber)s'),
#    masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:buildnumber)s'), url=util.Interpolate('https://ci.mariadb.org/' + "%(prop:buildnumber)s"), urlText="Download", doStepIf=hasFiles))
f_tarball.addStep(steps.ShellCommand(name='save_packages', haltOnFailure=True, command=util.Interpolate('cp -r ' + '%(prop:builddir)s' + '/build/mkdist/' + '%(prop:buildnumber)s' + ' /packages && sync /packages/' + '%(prop:buildnumber)s')))
f_tarball.addStep(steps.Trigger(schedulerNames=['s_protected_branches'], waitForFinish=False, updateSourceStamp=False, doStepIf=waitIfStaging,
    set_properties={"tarbuildnum" : Property("buildnumber"), "mariadb_version" : Property("mariadb_version"), "master_branch" : Property("master_branch")}))
f_tarball.addStep(steps.Trigger(schedulerNames=['s_upstream_all'], waitForFinish=False, updateSourceStamp=False,
    set_properties={"tarbuildnum" : Property("buildnumber"), "mariadb_version" : Property("mariadb_version"), "master_branch" : Property("master_branch")}))
f_tarball.addStep(steps.SetPropertyFromCommand(command=util.Interpolate("echo " + "prot-" + "%(prop:master_branch)s"), property="master_staging_branch"))
f_tarball.addStep(steps.ShellSequence( commands=[
    util.ShellArg(command="git config --global user.email '" + config["private"]["gh_mdbci"]["email"] + "'"),
    util.ShellArg(command="git config --global user.name '" + config["private"]["gh_mdbci"]["name"] + "'"),
    util.ShellArg(command="git remote set-url origin https://" + config["private"]["gh_mdbci"]["push_access_token"] + ":x-oauth-basic@github.com/cvicentiu/server"),
    util.ShellArg(command=util.Interpolate("git fetch origin %(prop:master_staging_branch)s && git branch %(prop:master_staging_branch)s FETCH_HEAD && git checkout %(prop:master_staging_branch)s && git checkout %(prop:branch)s && git pull --unshallow"), logfile="rebase"),
    util.ShellArg(command=["bash", "-xc", util.Interpolate("if git checkout %(prop:master_staging_branch)s && git merge --ff-only %(prop:branch)s; then git push --set-upstream origin %(prop:master_staging_branch)s; else  if git checkout %(prop:branch)s && [[ $(git --no-pager log --merges %(prop:master_staging_branch)s..%(prop:branch)s | wc -l) -ne 0 ]]; then exit 1; else git rebase %(prop:master_staging_branch)s && git push --force; fi fi")], logfile="rebase")],
    workdir="build/server", haltOnFailure="true", doStepIf=lambda step: isStagingBranch(step)))
#f_tarball.addStep(steps.ShellSequence( commands=[
#    util.ShellArg(command=util.Interpolate("git checkout " + "%(prop:staging_branch)s"), logfile="rebase"),
#    util.ShellArg(command=util.Interpolate("git merge %(prop:branch)s"), logfile="rebase")], workdir="build/server", haltOnFailure="true", doStepIf=ifStagingSucceeding))
f_tarball.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_quick_build
f_quick_build = util.BuildFactory()
f_quick_build.addStep(steps.SetProperty(property="dockerfile", value=util.Interpolate("%(kw:url)s", url=dockerfile), description="dockerfile"))
f_quick_build.addStep(downloadSourceTarball())
f_quick_build.addStep(steps.ShellCommand(command=util.Interpolate("tar -xvzf /mnt/packages/%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz --strip-components=1")))
f_quick_build.addStep(steps.ShellCommand(name="create html log file", command=['bash', '-c', util.Interpolate(getHTMLLogString(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
# build steps
f_quick_build.addStep(steps.Compile(command=
    ["sh", "-c", util.Interpolate("export PATH=/usr/lib/ccache:/usr/lib64/ccache:$PATH && cmake . -DCMAKE_BUILD_TYPE=%(kw:build_type)s -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_C_COMPILER=%(kw:c_compiler)s -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER=%(kw:cxx_compiler)s -DPLUGIN_TOKUDB=NO -DPLUGIN_MROONGA=NO -DPLUGIN_SPIDER=NO -DPLUGIN_OQGRAPH=NO -DPLUGIN_PERFSCHEMA=%(kw:perf_schema)s -DPLUGIN_SPHINX=NO %(kw:additional_args)s && make -j%(kw:jobs)s package", perf_schema=util.Property('perf_schema', default='YES'), build_type=util.Property('build_type', default='RelWithDebInfo'), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'), c_compiler=util.Property('c_compiler', default='gcc'), cxx_compiler=util.Property('cxx_compiler', default='g++'), additional_args=util.Property('additional_args', default='') )], env={'CCACHE_DIR':'/mnt/ccache'}, haltOnFailure="true"))

f_quick_build.addStep(steps.MTR(logfiles={"mysqld*": "/buildbot/mysql_logs.html"}, command=
    ["sh", "-c", util.Interpolate("cd mysql-test && exec perl mysql-test-run.pl --verbose-restart --force --retry=3 --max-save-core=1 --max-save-datadir=1 --max-test-fail=20 --mem --parallel=$(expr %(kw:jobs)s \* 2) %(kw:mtr_additional_args)s", mtr_additional_args=util.Property('mtr_additional_args', default=''), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=7200, haltOnFailure="true", parallel=mtrJobsMultiplier, dbpool=mtrDbPool, autoCreateTables=True))
f_quick_build.addStep(steps.ShellCommand(name="move mysqld log files", alwaysRun=True, command=['bash', '-c', util.Interpolate(moveMTRLogs(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
f_quick_build.addStep(steps.DirectoryUpload(name="save mysqld log files", compress="bz2", alwaysRun=True,  workersrc='/buildbot/logs/', masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + '/logs/' + '%(prop:buildername)s' )))
## trigger packages
f_quick_build.addStep(steps.Trigger(schedulerNames=['s_packages'], waitForFinish=False, updateSourceStamp=False, alwaysRun=True,
    set_properties={"parentbuildername": Property('buildername'), "tarbuildnum" : Property("tarbuildnum"), "mariadb_version" : Property("mariadb_version"), "master_branch" : Property("master_branch")}, doStepIf=hasAutobake))
## trigger bigtest
f_quick_build.addStep(steps.Trigger(schedulerNames=['s_bigtest'], waitForFinish=False, updateSourceStamp=False,
    set_properties={"parentbuildername": Property('buildername'), "tarbuildnum" : Property("tarbuildnum"), "mariadb_version" : Property("mariadb_version"), "master_branch" : Property("master_branch")}, doStepIf=hasBigtest))
# create package and upload to master
f_quick_build.addStep(steps.SetPropertyFromCommand(command="basename mariadb-*-linux-*.tar.gz", property="mariadb_binary", doStepIf=savePackage))
f_quick_build.addStep(steps.ShellCommand(name='save_packages', timeout=7200, haltOnFailure=True, command=util.Interpolate('mkdir -p ' + '/packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s'+ ' && sha256sum %(prop:mariadb_binary)s >> sha256sums.txt  && cp ' + '%(prop:mariadb_binary)s sha256sums.txt' + ' /packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s' + '/' +  ' && sync /packages/' + '%(prop:tarbuildnum)s'), doStepIf=savePackage))
f_quick_build.addStep(steps.Trigger(name='eco', schedulerNames=['s_eco'], waitForFinish=False, updateSourceStamp=False, set_properties={"parentbuildername": Property("buildername"), "tarbuildnum" : Property("tarbuildnum"), "mariadb_binary": Property("mariadb_binary"), "mariadb_version" : Property("mariadb_version"), "master_branch" : Property("master_branch"), "parentbuildername": Property("buildername")}, doStepIf=lambda step: savePackage(step) and hasEco(step)))
f_quick_build.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_32b_quick_build
f_32b_quick_build = util.BuildFactory()
f_32b_quick_build.addStep(steps.SetProperty(property="dockerfile", value=util.Interpolate("%(kw:url)s", url=dockerfile), description="dockerfile"))
f_32b_quick_build.addStep(downloadSourceTarball())
f_32b_quick_build.addStep(steps.ShellCommand(command=util.Interpolate("tar -xvzf /mnt/packages/%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz --strip-components=1")))
f_32b_quick_build.addStep(steps.ShellCommand(name="create html log file", command=['bash', '-c', util.Interpolate(getHTMLLogString(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
# build steps
f_32b_quick_build.addStep(steps.Compile(command=
    ["sh", "-c", util.Interpolate("export PATH=/usr/lib/ccache:/usr/lib64/ccache:$PATH && cmake . -DCMAKE_SYSTEM_LIBRARY_PATH=/usr/lib/i386-linux-gnu/ -DCMAKE_LIBRARY_PATH=/usr/lib/i386-linux-gnu/ -DCMAKE_FIND_ROOT_PATH=/usr/lib/i386-linux-gnu -DCMAKE_LIBRARY_ARCHITECTURE=i386 -DCMAKE_BUILD_TYPE=RelWithDebInfo -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_C_COMPILER=gcc -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER=g++ -DWITH_EMBEDDED_SERVER=OFF -DWITH_SAFEMALLOC=OFF -DWITH_WSREP=OFF -DPLUGIN_ARCHIVE=NO -DPLUGIN_TOKUDB=NO -DPLUGIN_MROONGA=NO -DPLUGIN_SPIDER=NO -DPLUGIN_OQGRAPH=NO -DPLUGIN_CONNECT=NO -DPLUGIN_SPHINX=NO -DWITH_SSL=bundled -DWITH_ZLIB=system -DCMAKE_C_FLAGS=-m32 -DCMAKE_CXX_FLAGS=-m32 && make -j%(kw:jobs)s package", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)') )], env={'CCACHE_DIR':'/mnt/ccache'}, haltOnFailure="true"))

f_32b_quick_build.addStep(steps.MTR(logfiles={"mysqld*": "/buildbot/mysql_logs.html"}, command=
    ["sh", "-c", util.Interpolate("cd mysql-test && exec perl mysql-test-run.pl --verbose-restart --force --retry=3 --max-save-core=1 --max-save-datadir=1 --max-test-fail=20 --mem --parallel=$(expr %(kw:jobs)s \* 2)", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=7200, haltOnFailure="true", parallel=mtrJobsMultiplier, dbpool=mtrDbPool, autoCreateTables=True))
f_32b_quick_build.addStep(steps.ShellCommand(name="move mysqld log files", alwaysRun=True, command=['bash', '-c', util.Interpolate(moveMTRLogs(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
f_32b_quick_build.addStep(steps.DirectoryUpload(name="save mysqld log files", compress="bz2", alwaysRun=True,  workersrc='/buildbot/logs/', masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + '/logs/' + '%(prop:buildername)s' )))
# create package and upload to master
f_32b_quick_build.addStep(steps.SetPropertyFromCommand(command="basename mariadb-*-linux-*.tar.gz", property="mariadb_binary"))
#f_32b_quick_build.addStep(steps.ShellCommand(name='save_packages', timeout=7200, haltOnFailure=True, command=util.Interpolate('mkdir -p ' + '/packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s'+ ' && sha256sum %(prop:mariadb_binary)s >> sha256sums.txt  && cp ' + '%(prop:mariadb_binary)s sha256sums.txt' + ' /packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s' + '/' +  ' && sync /packages/' + '%(prop:tarbuildnum)s'), doStepIf=savePackage))
f_32b_quick_build.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_asan_build
f_asan_build = util.BuildFactory()
f_asan_build.addStep(steps.SetProperty(property="dockerfile", value=util.Interpolate("%(kw:url)s", url=dockerfile), description="dockerfile"))
f_asan_build.addStep(downloadSourceTarball())
f_asan_build.addStep(steps.ShellCommand(command=util.Interpolate("tar -xvzf /mnt/packages/%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz --strip-components=1")))
f_asan_build.addStep(steps.ShellCommand(name="create html log file", command=['bash', '-c', util.Interpolate(getHTMLLogString(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
# build steps
f_asan_build.addStep(steps.ShellCommand(command='echo "leak:libtasn1\nleak:libgnutls\nleak:libgmp" > mysql-test/lsan.supp', doStepIf=filterBranch))
f_asan_build.addStep(steps.ShellCommand(command='cat mysql-test/lsan.supp', doStepIf=filterBranch))
f_asan_build.addStep(steps.Compile(command=
    ["sh", "-c", util.Interpolate('cmake . -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DCMAKE_C_COMPILER=clang-10 -DCMAKE_CXX_COMPILER=clang++ -DCMAKE_C_FLAGS="-O2 -msse4.2 -Wno-unused-command-line-argument -fdebug-macro -Wno-inconsistent-missing-override" -DCMAKE_CXX_FLAGS="-O2 -msse4.2 -Wno-unused-command-line-argument -fdebug-macro -Wno-inconsistent-missing-override" -DCMAKE_EXPORT_COMPILE_COMMANDS=ON -DCMAKE_BUILD_TYPE=Debug -DWITH_ASAN=YES -DPLUGIN_TOKUDB=NO -DPLUGIN_MROONGA=NO -DPLUGIN_OQGRAPH=NO -DPLUGIN_ROCKSDB=NO -DPLUGIN_CONNECT=NO -DWITH_SAFEMALLOC=OFF -DWITH_ZLIB=bundled -DWITH_SSL=bundled -DWITH_PCRE=system && make -j%(kw:jobs)s package', jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], haltOnFailure="true"))
f_asan_build.addStep(steps.MTR(logfiles={"mysqld*": "/buildbot/mysql_logs.html"}, command=
    ["sh", "-c", util.Interpolate('cd mysql-test && MTR_FEEDBACK_PLUGIN=1 ASAN_OPTIONS="abort_on_error=1" LSAN_OPTIONS="print_suppressions=0,suppressions=`pwd`/lsan.supp" perl mysql-test-run.pl --verbose-restart --force --retry=3 --max-save-core=1 --max-save-datadir=1 --max-test-fail=20 --mem --parallel=$(expr %(kw:jobs)s \* 2)', jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=7200, haltOnFailure="true", parallel=mtrJobsMultiplier, dbpool=mtrDbPool, autoCreateTables=True))
f_asan_build.addStep(steps.ShellCommand(name="move mysqld log files", alwaysRun=True, command=['bash', '-c', util.Interpolate(moveMTRLogs(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
f_asan_build.addStep(steps.DirectoryUpload(name="save mysqld log files", compress="bz2", alwaysRun=True,  workersrc='/buildbot/logs/', masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + '/logs/' + '%(prop:buildername)s' )))
f_asan_build.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_msan_build
f_msan_build = util.BuildFactory()
f_msan_build.addStep(steps.SetProperty(property="dockerfile", value=util.Interpolate("%(kw:url)s", url=dockerfile), description="dockerfile"))
f_msan_build.addStep(steps.ShellCommand(name="create html log file", command=['bash', '-c', util.Interpolate(getHTMLLogString(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
f_msan_build.addStep(downloadSourceTarball())
f_msan_build.addStep(steps.ShellCommand(command=util.Interpolate("tar -xvzf /mnt/packages/%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz --strip-components=1")))
# build steps
f_msan_build.addStep(steps.ShellCommand(command='ls /mariadb/llvm-toolchain-10-10.0.1/libc++msan/lib'))
f_msan_build.addStep(steps.Compile(command=
    ["bash", "-xc", util.Interpolate('cmake -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DCMAKE_C_COMPILER=clang-10 -DCMAKE_CXX_COMPILER=clang++-10 -DCMAKE_C_FLAGS="-O3 -march=native -mtune=native -Wno-unused-command-line-argument -fdebug-macro" -DCMAKE_CXX_FLAGS="-stdlib=libc++ -O3 -march=native -mtune=native -Wno-unused-command-line-argument -fdebug-macro" -DWITH_EMBEDDED_SERVER=OFF -DWITH_UNIT_TESTS=OFF -DCMAKE_BUILD_TYPE=Debug -DHAVE_LIBAIO_H=0 -DCMAKE_DISABLE_FIND_PACKAGE_{URING,LIBAIO}=1 -DWITH_INNODB_BZIP2=OFF -DWITH_INNODB_LZ4=OFF -DWITH_INNODB_LZMA=OFF -DWITH_INNODB_LZO=OFF -DWITH_INNODB_SNAPPY=OFF -DPLUGIN_ARCHIVE=NO -DPLUGIN_TOKUDB=NO -DPLUGIN_MROONGA=NO -DPLUGIN_OQGRAPH=NO -DPLUGIN_ROCKSDB=NO -DPLUGIN_CONNECT=NO -DPLUGIN_SPIDER=NO -DWITH_SAFEMALLOC=OFF -DWITH_ZLIB=bundled -DWITH_SSL=bundled -DWITH_PCRE=bundled -DWITH_MSAN=ON -DWITH_DBUG_TRACE=OFF && make -j%(kw:jobs)s package', jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], haltOnFailure="true"))
f_msan_build.addStep(steps.MTR(logfiles={"mysqld*": "/buildbot/mysql_logs.html"}, command=
    ["bash", "-xc", util.Interpolate('cd mysql-test && LD_LIBRARY_PATH=/mariadb/llvm-toolchain-10-10.0.1/libc++msan/lib MSAN_OPTIONS=abort_on_error=1 ./mtr --big-test --force --retry=0 --max-test-fail=40 --parallel=$(expr %(kw:jobs)s \* 2)', jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=7200, haltOnFailure="true", parallel=mtrJobsMultiplier, dbpool=mtrDbPool, autoCreateTables=True))
f_msan_build.addStep(steps.ShellCommand(name="move mysqld log files", alwaysRun=True, command=['bash', '-c', util.Interpolate(moveMTRLogs(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
f_msan_build.addStep(steps.DirectoryUpload(name="save mysqld log files", compress="bz2", alwaysRun=True,  workersrc='/buildbot/logs/', masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + '/logs/' + '%(prop:buildername)s' )))
f_msan_build.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_valgrind_build
f_valgrind_build = util.BuildFactory()
f_valgrind_build.addStep(steps.SetProperty(property="dockerfile", value=util.Interpolate("%(kw:url)s", url=dockerfile), description="dockerfile"))
f_valgrind_build.addStep(steps.ShellCommand(name="create html log file", command=['bash', '-c', util.Interpolate(getHTMLLogString(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
f_valgrind_build.addStep(downloadSourceTarball())
f_valgrind_build.addStep(steps.ShellCommand(command=util.Interpolate("tar -xvzf /mnt/packages/%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz --strip-components=1")))
# build steps
f_valgrind_build.addStep(steps.Compile(command=
    ["sh", "-c", util.Interpolate('cmake . -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DENABLE_ASSEMBLER=1 -DWITH_EXTRA_CHARSETS=complex -DENABLE_THREAD_SAFE_CLIENT=1 -DWITH_BIG_TABLES=1 -DWITH_PLUGIN_ARIA=1 -DWITH_ARIA_TMP_TABLES=1 -DWITH_JEMALLOC=NO=1 -DCMAKE_BUILD_TYPE=Debug -DSECURITY_HARDENED=OFF -DWITH_VALGRIND=1 -DWITH_SSL=bundled -DWITH_MAX=AUTO -DWITH_EMBEDDED_SERVER=1 -DWITH_LIBEVENT=bundled -DPLUGIN_PLUGIN_FILE_KEY_MANAGEMENT=NO -DPLUGIN_ROCKSDB=DYNAMIC -DPLUGIN_TEST_SQL_DISCOVERY=DYNAMIC -DPLUGIN_TOKUDB=NO -DPLUGIN_ROCKSDB=NO -DENABLE_LOCAL_INFILE=1 && make -j%(kw:jobs)s package', jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], haltOnFailure="true"))
f_valgrind_build.addStep(steps.MTR(logfiles={"mysqld*": "/buildbot/mysql_logs.html"}, command=
    ["sh", "-c", util.Interpolate('cd mysql-test && perl mysql-test-run.pl --valgrind="--leak-check=summary --gen-suppressions=yes --num-callers=10" --skip-test=encryption*  --force --retry=0 --max-save-core=1 --max-save-datadir=1 --max-test-fail=20 --parallel=$(expr %(kw:jobs)s \* 2)', jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=7200, haltOnFailure="true", parallel=mtrJobsMultiplier, dbpool=mtrDbPool, autoCreateTables=True))
f_valgrind_build.addStep(steps.ShellCommand(name="move mysqld log files", alwaysRun=True, command=['bash', '-c', util.Interpolate(moveMTRLogs(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
f_valgrind_build.addStep(steps.DirectoryUpload(name="save mysqld log files", compress="bz2", alwaysRun=True,  workersrc='/buildbot/logs/', masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + '/logs/' + '%(prop:buildername)s' )))
f_valgrind_build.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_big_test
f_big_test = util.BuildFactory()
f_big_test.addStep(steps.SetProperty(property="dockerfile", value=util.Interpolate("%(kw:url)s", url=dockerfile), description="dockerfile"))
f_big_test.addStep(steps.ShellCommand(name="create html log file", command=['bash', '-c', util.Interpolate(getHTMLLogString(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
# get the source tarball and extract it
f_big_test.addStep(steps.FileDownload(mastersrc=util.Interpolate("/srv/buildbot/packages/" + "%(prop:tarbuildnum)s" + "/" + "%(prop:mariadb_version)s" + ".tar.gz"),
    workerdest=util.Interpolate("%(prop:mariadb_version)s" + ".tar.gz")))
f_big_test.addStep(steps.ShellCommand(command=util.Interpolate("tar -xvzf " + "%(prop:mariadb_version)s" + ".tar.gz --strip-components=1")))
# build steps
f_big_test.addStep(steps.Compile(command=
    ["sh", "-c", util.Interpolate("export PATH=/usr/lib/ccache:/usr/lib64/ccache:$PATH && cmake . -DCMAKE_BUILD_TYPE=RelWithDebInfo  -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DPLUGIN_ROCKSDB=NO -DPLUGIN_TOKUDB=NO -DPLUGIN_MROONGA=NO -DPLUGIN_SPIDER=NO -DPLUGIN_OQGRAPH=NO -DPLUGIN_SPHINX=NO && make -j%(kw:jobs)s VERBOSE=1 package", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], env={'CCACHE_DIR':'/mnt/ccache'}))
f_big_test.addStep(steps.MTR(logfiles={"mysqld*": "/buildbot/mysql_logs.html"}, command=
    ["sh", "-c", util.Interpolate("cd mysql-test && exec perl mysql-test-run.pl --verbose-restart --force --retry=3 --max-save-core=1 --max-save-datadir=1 --max-test-fail=20 --big --big --mem --parallel=$(expr %(kw:jobs)s \* 2) --skip-test=archive.archive-big", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=10800, dbpool=mtrDbPool, parallel=mtrJobsMultiplier))
f_big_test.addStep(steps.ShellCommand(name="move mysqld log files", alwaysRun=True, command=['bash', '-c', util.Interpolate(moveMTRLogs(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
f_big_test.addStep(steps.DirectoryUpload(name="save mysqld log files", compress="bz2", alwaysRun=True,  workersrc='/buildbot/logs/', masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + '/logs/' + '%(prop:buildername)s' )))
# create package and upload to master
f_big_test.addStep(steps.SetPropertyFromCommand(command="basename mariadb-*-linux-*.tar.gz", property="mariadb_binary"))
#f_big_test.addStep(steps.ShellCommand(name='save_packages', timeout=7200, haltOnFailure=True, command=util.Interpolate('mkdir -p ' + '/packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s'+ ' && sha256sum %(prop:mariadb_binary)s >> sha256sums.txt  && cp ' + '%(prop:mariadb_binary)s sha256sums.txt' + ' /packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s' + '/' +  ' && sync /packages/' + '%(prop:tarbuildnum)s'), doStepIf=savePackage))
f_big_test.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_full_test
f_full_test = util.BuildFactory()
f_full_test.addStep(steps.SetProperty(property="dockerfile", value=util.Interpolate("%(kw:url)s", url=dockerfile), description="dockerfile"))
# get the source tarball and extract it
f_full_test.addStep(steps.FileDownload(mastersrc=util.Interpolate("/srv/buildbot/packages/" + "%(prop:tarbuildnum)s" + "/" + "%(prop:mariadb_version)s" + ".tar.gz"),
    workerdest=util.Interpolate("%(prop:mariadb_version)s" + ".tar.gz")))
f_full_test.addStep(steps.ShellCommand(command=util.Interpolate("tar -xvzf " + "%(prop:mariadb_version)s" + ".tar.gz --strip-components=1")))
# build steps
f_full_test.addStep(steps.Compile(command=
    ["sh", "-c", util.Interpolate("export PATH=/usr/lib/ccache:/usr/lib64/ccache:$PATH && cmake . -DBUILD_CONFIG=mysql_release -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DWITH_SSL=system -DWITH_JEMALLOC=auto -DWITH_EMBEDDED_SERVER=1 -DHAVE_EMBEDDED_PRIVILEGE_CONTROL=1 -DWITH_LIBARCHIVE=ON -Wno-dev && make -j%(kw:jobs)s VERBOSE=1 package", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], env={'CCACHE_DIR':'/mnt/ccache'}))
f_full_test.addStep(steps.MTR(addLogs=True, name="test emb", command=
    ["sh", "-c", util.Interpolate("cd mysql-test && MTR_FEEDBACK_PLUGIN=1 perl mysql-test-run.pl  --verbose-restart --force --retry=3 --max-save-core=0 --max-save-datadir=1 --mem --embedded-server --parallel=$(expr %(kw:jobs)s \* 2)", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=10800, dbpool=mtrDbPool, parallel=mtrJobsMultiplier))
f_full_test.addStep(steps.MTR(addLogs=True, name="test n", command=
    ["sh", "-c", util.Interpolate("cd mysql-test && MTR_FEEDBACK_PLUGIN=1 perl mysql-test-run.pl  --verbose-restart --force --retry=3 --max-save-core=0 --max-save-datadir=1 --mem --parallel=$(expr %(kw:jobs)s \* 2)", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=10800, dbpool=mtrDbPool, parallel=mtrJobsMultiplier))
f_full_test.addStep(steps.MTR(addLogs=True, name="test p", command=
    ["sh", "-c", util.Interpolate("cd mysql-test && MTR_FEEDBACK_PLUGIN=1 perl mysql-test-run.pl  --verbose-restart --force --retry=3 --max-save-core=0 --max-save-datadir=1 --mem --ps-protocol --parallel=$(expr %(kw:jobs)s \* 2)", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=10800, dbpool=mtrDbPool, parallel=mtrJobsMultiplier))
f_full_test.addStep(steps.MTR(addLogs=True, name="test ps-embedded", command=
    ["sh", "-c", util.Interpolate("cd mysql-test && MTR_FEEDBACK_PLUGIN=1 perl mysql-test-run.pl  --verbose-restart --force --retry=3 --max-save-core=0 --max-save-datadir=1 --ps --embedded --mem --parallel=$(expr %(kw:jobs)s \* 2)", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=10800, dbpool=mtrDbPool, parallel=mtrJobsMultiplier))
f_full_test.addStep(steps.MTR(addLogs=True, name="test xtra", command=
    ["sh", "-c", util.Interpolate("cd mysql-test && MTR_FEEDBACK_PLUGIN=1 perl mysql-test-run.pl  --verbose-restart --force --retry=3 --max-save-core=0 --max-save-datadir=1 --mem --suite=funcs_1,funcs_2,stress,jp --big --testcase-timeout=120 --mysqld=--open-files-limit=0 --mysqld=--log-warnings=1 --parallel=$(expr %(kw:jobs)s \* 2)", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=10800, dbpool=mtrDbPool, parallel=mtrJobsMultiplier))
f_full_test.addStep(steps.MTR(addLogs=True, name="test engines", command=
    ["sh", "-c", util.Interpolate("cd mysql-test && MTR_FEEDBACK_PLUGIN=1 perl mysql-test-run.pl  --verbose-restart --force --retry=3 --max-save-core=0 --max-save-datadir=1 --mem --suite=spider,spider/bg,engines/funcs,engines/iuds --big --testcase-timeout=120 --mysqld=--open-files-limit=0 --mysqld=--log-warnings=1 --parallel=$(expr %(kw:jobs)s \* 2)", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=10800, dbpool=mtrDbPool, parallel=mtrJobsMultiplier))
f_full_test.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_deb_autobake
f_deb_autobake = util.BuildFactory()
f_deb_autobake.addStep(steps.SetProperty(property="dockerfile", value=util.Interpolate("%(kw:url)s", url=dockerfile), description="dockerfile"))
f_deb_autobake.addStep(downloadSourceTarball())
f_deb_autobake.addStep(steps.ShellCommand(command=util.Interpolate("tar -xvzf /mnt/packages/%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz --strip-components=1")))
# build steps
f_deb_autobake.addStep(steps.Compile(logfiles={'CMakeCache.txt': './builddir/CMakeCache.txt'}, command=["debian/autobake-deb.sh"],
    env={'CCACHE_DIR':'/mnt/ccache', 'DEB_BUILD_OPTIONS':util.Interpolate('parallel=%(kw:jobs)s', jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))}, description="autobake-deb.sh"))
# upload binaries
f_deb_autobake.addStep(steps.SetPropertyFromCommand(command="find .. -maxdepth 1 -type f", extract_fn=ls2string))
#f_deb_autobake.addStep(steps.MultipleFileUpload(workersrcs=util.Property('packages'),
#    masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s'), mode=0o755, url=util.Interpolate('https://ci.mariadb.org/' + "%(prop:tarbuildnum)s" + "/" + '%(prop:buildername)s' + "/"), doStepIf=lambda step: hasFiles(step) and savePackage(step)))
#f_deb_autobake.addStep(steps.ShellCommand(name='save_packages', haltOnFailure=True, command=util.Interpolate('mkdir -p ' + '/packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s'+ ' && cp ' + '%(prop:packages)s' + ' /packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s' + '/' +  ' && sync /packages/' + '%(prop:tarbuildnum)s'), doStepIf=lambda step: hasFiles(step) and savePackage(step)))
f_deb_autobake.addStep(dpkgDeb())
#f_deb_autobake.addStep(steps.MultipleFileUpload(workersrcs=['debs/Packages.gz', 'debs/Sources.gz'],
#    masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s'), mode=0o755, url=util.Interpolate('https://ci.mariadb.org/' + "%(prop:tarbuildnum)s" + "/" + '%(prop:buildername)s' + "/"), doStepIf=lambda step: hasFiles(step) and savePackage(step)))
f_deb_autobake.addStep(steps.ShellCommand(name='save_packages', timeout=7200, haltOnFailure=True, command=util.Interpolate('mkdir -p ' + '/packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s'+ ' && cp -r debs/ sha256sums.txt /packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s' + '/' +  ' && sync /packages/' + '%(prop:tarbuildnum)s'), doStepIf=lambda step: hasFiles(step) and savePackage(step)))
f_deb_autobake.addStep(steps.Trigger(name='install', schedulerNames=['s_install'], waitForFinish=True, updateSourceStamp=False,
    set_properties={"tarbuildnum" : Property("tarbuildnum"), "mariadb_version" : Property("mariadb_version"), "master_branch" : Property("master_branch"), "parentbuildername": Property("buildername"), "sst_mode": "off"}, doStepIf=lambda step: hasInstall(step) and savePackage(step) and hasFiles(step)))
f_deb_autobake.addStep(steps.Trigger(name='galera-sst-mariabackup', schedulerNames=['s_install'], waitForFinish=True, updateSourceStamp=False,
    set_properties={"tarbuildnum" : Property("tarbuildnum"), "mariadb_version" : Property("mariadb_version"), "master_branch" : Property("master_branch"), "parentbuildername": Property("buildername"), "sst_mode": "mariabackup"}, doStepIf=lambda step: hasInstall(step) and savePackage(step) and hasFiles(step)))
f_deb_autobake.addStep(steps.Trigger(name='galera-sst-mysqldump', schedulerNames=['s_install'], waitForFinish=True, updateSourceStamp=False,
    set_properties={"tarbuildnum" : Property("tarbuildnum"), "mariadb_version" : Property("mariadb_version"), "master_branch" : Property("master_branch"), "parentbuildername": Property("buildername"), "sst_mode": "mysqldump"}, doStepIf=lambda step: hasInstall(step) and savePackage(step) and hasFiles(step)))
f_deb_autobake.addStep(steps.Trigger(name='galera-sst-rsync', schedulerNames=['s_install'], waitForFinish=True, updateSourceStamp=False,
    set_properties={"tarbuildnum" : Property("tarbuildnum"), "mariadb_version" : Property("mariadb_version"), "master_branch" : Property("master_branch"), "parentbuildername": Property("buildername"), "sst_mode": "rsync"}, doStepIf=lambda step: hasInstall(step) and savePackage(step) and hasFiles(step)))
f_deb_autobake.addStep(steps.Trigger(name='major-minor-upgrade', schedulerNames=['s_upgrade'], waitForFinish=True, updateSourceStamp=False,
    set_properties={"tarbuildnum" : Property("tarbuildnum"), "mariadb_version" : Property("mariadb_version"), "master_branch" : Property("master_branch"), "parentbuildername": Property("buildername")}, doStepIf=lambda step: hasUpgrade(step) and savePackage(step) and hasFiles(step)))
f_deb_autobake.addStep(steps.Trigger(name='dockerlibrary', schedulerNames=['s_dockerlibrary'], waitForFinish=False, updateSourceStamp=False,
    set_properties={"tarbuildnum" : Property("tarbuildnum"), "mariadb_version" : Property("mariadb_version"), "master_branch" : Property("master_branch"), "parentbuildername": Property("buildername")}, doStepIf=lambda step: savePackage(step) and hasDockerLibrary(step)))
f_deb_autobake.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_deb_install
f_deb_install = util.BuildFactory()
f_deb_install.addStep(downloadDebs())
f_deb_install.addStep(getDebInstallStep())
f_deb_install.addStep(getDebGaleraStep("2223"))
f_deb_install.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_deb_upgrade
f_deb_upgrade = util.BuildFactory()
f_deb_upgrade.addStep(downloadDebs())
f_deb_upgrade.addStep(steps.SetPropertyFromCommand(name="major_version", property="major_version", command=util.Interpolate("sh -c \"echo '%(prop:branch)s' | sed -e \\\"s/.*\\\\(5\\\\.5\\\\|10\\\\.[0-9]\\\\).*/\\\\1/\\\"\"")))
f_deb_upgrade.addStep(getDebMinorUpgradeStep())
f_deb_upgrade.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_rpm_autobake
f_rpm_autobake= util.BuildFactory()
f_rpm_autobake.addStep(steps.SetProperty(property="dockerfile", value=util.Interpolate("%(kw:url)s", url=dockerfile), description="dockerfile"))
f_rpm_autobake.workdir=f_rpm_autobake.workdir + "/padding_for_CPACK_RPM_BUILD_SOURCE_DIRS_PREFIX/"
f_rpm_autobake.addStep(steps.ShellCommand(name='fetch packages for MariaDB-compat', command=["sh", "-c", util.Interpolate('wget -cO ../MariaDB-shared-5.3.%(kw:arch)s.rpm "https://ci.mariadb.org/helper_files/mariadb-shared-5.3-%(kw:arch)s.rpm" && wget -cO ../MariaDB-shared-10.1.%(kw:arch)s.rpm "https://ci.mariadb.org/helper_files/mariadb-shared-10.1-kvm-rpm-%(kw:rpm_type)s-%(kw:arch)s.rpm"', arch=getArch, rpm_type=util.Property('rpm_type'))]))
f_rpm_autobake.addStep(downloadSourceTarball())
f_rpm_autobake.addStep(steps.ShellCommand(command=util.Interpolate("tar -xvzf /mnt/packages/%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz --strip-components=1")))
f_rpm_autobake.addStep(steps.ShellCommand(command="ls .."))
# build steps
f_rpm_autobake.addStep(steps.ShellCommand(logfiles={'CMakeCache.txt': 'CMakeCache.txt'}, name="cmake", command=
    ["sh", "-c", util.Interpolate("export PATH=/usr/lib/ccache:/usr/lib64/ccache:$PATH && cmake . -DBUILD_CONFIG=mysql_release -DRPM=%(kw:rpm_type)s -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER_LAUNCHER=ccache  %(kw:mtr_additional_args)s", mtr_additional_args=util.Property('mtr_additional_args', default=''), rpm_type=util.Property('rpm_type'))], env={'CCACHE_DIR':'/mnt/ccache'}, description="cmake"))
f_rpm_autobake.addStep(steps.Compile(command=
    ["sh", "-xc", util.Interpolate("""
        mkdir -p rpms srpms
        if grep -qw CPACK_RPM_SOURCE_PKG_BUILD_PARAMS CPackSourceConfig.cmake; then
            make package_source
            mv *.src.rpm srpms/
        fi
        export PATH=/usr/lib/ccache:/usr/lib64/ccache:$PATH && make -j %(kw:jobs)s package
    """, jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], env={'CCACHE_DIR':'/mnt/ccache'}, description="make package"))
# list rpm contents
f_rpm_autobake.addStep(steps.ShellCommand(command=
    ['sh', '-c', 'for rpm in *.rpm; do echo $rpm ; rpm -q --qf "[%{FILEMODES:perms} %{FILEUSERNAME} %{FILEGROUPNAME} .%-36{FILENAMES}\n]" $rpm; echo "------------------------------------------------"; done'], description="list rpm contents"))
# upload binaries
f_rpm_autobake.addStep(steps.SetPropertyFromCommand(command="ls -1 *.rpm", extract_fn=ls2string))
f_rpm_autobake.addStep(steps.ShellCommand(command=
    ["bash", "-xc", util.Interpolate("""
        if [ -e MariaDB-shared-10.1.*.rpm ]; then
           rm MariaDB-shared-10.1.*.rpm
        fi
        cp `ls -1 *.rpm` rpms/
        find srpms -type f -exec sha256sum {} \; | sort > sha256sums.txt
        find rpms -type f -exec sha256sum {} \; | sort >> sha256sums.txt
    """)]))
#f_rpm_autobake.addStep(steps.MultipleFileUpload(workersrcs=util.Property('packages'),
#    masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s'), mode=0o755, url=util.Interpolate('https://ci.mariadb.org/' + "%(prop:tarbuildnum)s" + "/" + '%(prop:buildername)s' + "/"), doStepIf=lambda step: hasFiles(step) and savePackage(step)))
f_rpm_autobake.addStep(steps.ShellCommand(name='save_packages', timeout=7200, haltOnFailure=True, command=util.Interpolate('mkdir -p ' + '/packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s'+ ' && cp -r rpms srpms sha256sums.txt' + ' /packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s' + '/' +  ' && sync /packages/' + '%(prop:tarbuildnum)s'), doStepIf=lambda step: hasFiles(step) and savePackage(step)))
f_rpm_autobake.addStep(steps.Trigger(name='install', schedulerNames=['s_install'], waitForFinish=True, updateSourceStamp=False,
    set_properties={"tarbuildnum" : Property("tarbuildnum"), "mariadb_version" : Property("mariadb_version"), "master_branch" : Property("master_branch"), "parentbuildername": Property("buildername")}, doStepIf=lambda step: hasInstall(step) and savePackage(step) and hasFiles(step)))
f_rpm_autobake.addStep(steps.Trigger(name='major-minor-upgrade', schedulerNames=['s_upgrade'], waitForFinish=True, updateSourceStamp=False,
    set_properties={"tarbuildnum" : Property("tarbuildnum"), "mariadb_version" : Property("mariadb_version"), "master_branch" : Property("master_branch"), "parentbuildername": Property("buildername")}, doStepIf=lambda step: hasUpgrade(step) and savePackage(step) and hasFiles(step)))
f_rpm_autobake.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_rpm_install
f_rpm_install = util.BuildFactory()
f_rpm_install.addStep(downloadRpms())
f_rpm_install.addStep(getRpmInstallStep())
f_rpm_install.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_rpm_upgrade
f_rpm_upgrade = util.BuildFactory()
f_rpm_upgrade.addStep(steps.SetPropertyFromCommand(name="major_version", property="major_version", command=util.Interpolate("sh -c \"echo '%(prop:branch)s' | sed -e \\\"s/.*\\\\(5\\\\.5\\\\|10\\\\.[0-9]\\\\).*/\\\\1/\\\"\"")))
f_rpm_upgrade.addStep(downloadRpms())
f_rpm_upgrade.addStep(getRpmUpgradeStep())
f_rpm_upgrade.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_quick_build
f_bintar = util.BuildFactory()
f_bintar.addStep(downloadSourceTarball())
f_bintar.addStep(steps.ShellCommand(command=util.Interpolate("tar -xvzf /mnt/packages/%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz --strip-components=1")))
f_bintar.addStep(steps.ShellCommand(name="create html log file", command=['bash', '-c', util.Interpolate(getHTMLLogString(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
# build steps
f_bintar.addStep(steps.Compile(command=
    ["sh", "-c", util.Interpolate("export PATH=/usr/lib/ccache:/usr/lib64/ccache:$PATH && cmake . -DBUILD_CONFIG=mysql_release -DWITH_READLINE=1 -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER_LAUNCHER=ccache %(kw:additional_args)s  && make -j%(kw:jobs)s package", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'), additional_args=util.Property('additional_args', default=''))], env={'CCACHE_DIR':'/mnt/ccache'}, haltOnFailure="true"))

#f_bintar.addStep(steps.MTR(logfiles={"mysqld*": "/buildbot/mysql_logs.html"}, command=
#    ["sh", "-c", util.Interpolate("cd mysql-test && exec perl mysql-test-run.pl --verbose-restart --force --retry=3 --max-save-core=1 --max-save-datadir=1 --max-test-fail=20 --mem --parallel=$(expr %(kw:jobs)s \* 2)", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))], timeout=7200, haltOnFailure="true", parallel=mtrJobsMultiplier, dbpool=mtrDbPool, autoCreateTables=True))
#f_bintar.addStep(steps.ShellCommand(name="move mysqld log files", alwaysRun=True, command=['bash', '-c', util.Interpolate(moveMTRLogs(), jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'))]))
#f_bintar.addStep(steps.DirectoryUpload(name="save mysqld log files", compress="bz2", alwaysRun=True,  workersrc='/buildbot/logs/', masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + '/logs/' + '%(prop:buildername)s' )))
# create package and upload to master
f_bintar.addStep(steps.SetPropertyFromCommand(command="basename mariadb-*-linux-*.tar.gz", property="mariadb_binary", doStepIf=savePackage))
f_bintar.addStep(steps.ShellCommand(name='save_packages', timeout=7200, haltOnFailure=True, command=util.Interpolate('mkdir -p ' + '/packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s'+ ' && sha256sum %(prop:mariadb_binary)s >> sha256sums.txt  && cp ' + '%(prop:mariadb_binary)s sha256sums.txt' + ' /packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s' + '/' +  ' && sync /packages/' + '%(prop:tarbuildnum)s'), doStepIf=savePackage))
f_bintar.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_without_server
f_without_server = util.BuildFactory()
f_without_server.addStep(steps.SetProperty(property="dockerfile", value=util.Interpolate("%(kw:url)s", url=dockerfile), description="dockerfile"))
f_without_server.addStep(steps.ShellCommand(command="ls -la"))
f_without_server.addStep(downloadSourceTarball())
f_without_server.addStep(steps.ShellCommand(command="ls -la"))
f_without_server.addStep(steps.ShellCommand(command=util.Interpolate("tar -xvzf /mnt/packages/%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz --strip-components=1")))
f_without_server.addStep(steps.ShellCommand(command="ls -la"))
# build steps
f_without_server.addStep(steps.Compile(command=
    ["sh", "-c", util.Interpolate("export PATH=/usr/lib/ccache:/usr/lib64/ccache:$PATH && cmake . -DCMAKE_BUILD_TYPE=RelWithDebInfo -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_C_COMPILER=%(kw:c_compiler)s -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER=%(kw:cxx_compiler)s -DWITHOUT_SERVER=1 && make -j%(kw:jobs)s package", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'), c_compiler=util.Property('c_compiler', default='gcc'), cxx_compiler=util.Property('cxx_compiler', default='g++'))], env={'CCACHE_DIR':'/mnt/ccache'}, haltOnFailure="true"))
#    ["sh", "-c", util.Interpolate("export PATH=/usr/lib/ccache:/usr/lib64/ccache:$PATH && mkdir -p ../builddir && cd ../builddir && cmake ${OLDPWD} -DCMAKE_BUILD_TYPE=RelWithDebInfo -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_C_COMPILER=%(kw:c_compiler)s -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER=%(kw:cxx_compiler)s -DWITHOUT_SERVER=ON && cmake --build . --parallel %(kw:jobs)s --target package", jobs=util.Property('jobs', default='$(getconf _NPROCESSORS_ONLN)'), c_compiler=util.Property('c_compiler', default='gcc'), cxx_compiler=util.Property('cxx_compiler', default='g++'))], env={'CCACHE_DIR':'/mnt/ccache'}, haltOnFailure="true"))
# create package and upload to master
f_without_server.addStep(steps.SetPropertyFromCommand(command="basename mariadb-*-linux-*.tar.gz", property="mariadb_binary"))
#f_without_server.addStep(steps.FileUpload(workersrc=util.Interpolate("%(prop:mariadb_binary)s"), masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + "/" + '%(prop:buildername)s' + "/" + "%(prop:mariadb_binary)s"), mode=0o755, url=util.Interpolate('https://ci.mariadb.org/' + "%(prop:tarbuildnum)s" + "/" + '%(prop:buildername)s' + "/"), urlText="Download", doStepIf=savePackage))
f_without_server.addStep(steps.ShellCommand(name='save_packages', timeout=7200, haltOnFailure=True, command=util.Interpolate('mkdir -p ' + '/packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s'+ ' && sha256sum %(prop:mariadb_binary)s >> sha256sums.txt  && cp ' + '%(prop:mariadb_binary)s sha256sums.txt' + ' /packages/' + '%(prop:tarbuildnum)s' + '/' + '%(prop:buildername)s' + '/' +  ' && sync /packages/' + '%(prop:tarbuildnum)s'), doStepIf=savePackage))
f_without_server.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* 2> /dev/null || true", alwaysRun=True))

## f_macos_10_13
'''
f_macos_10_13 = util.BuildFactory()
f_macos_10_13.addStep(steps.Git(repourl=util.Property('repository'), mode='incremental'))
f_macos_10_13.addStep(steps.Compile(command=
    ["sh", "-c", "cmake . -DCMAKE_BUILD_TYPE=RelWithDebInfo -DWITH_ASAN=ON -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DOPENSSL_ROOT_DIR=/usr/local/opt/openssl/ -DOPENSSL_LIBRARIES=/usr/local/opt/openssl/lib -DPLUGIN_TOKUDB=NO -DPLUGIN_MROONGA=NO -DPLUGIN_SPIDER=NO -DPLUGIN_OQGRAPH=NO -DPLUGIN_PERFSCHEMA=NO -DPLUGIN_SPHINX=NO && make -j$(getconf _NPROCESSORS_ONLN) VERBOSE=1"]))
f_macos_10_13.addStep(steps.MTR(command=
    ["sh", "-c", "cd mysql-test && exec perl mysql-test-run.pl  --verbose-restart --force --retry=3  --max-save-core=1 --max-save-datadir=1 --parallel=$(getconf _NPROCESSORS_ONLN)"], timeout=7200))
'''

## f_windows
f_windows = util.BuildFactory()
f_windows.addStep(steps.ShellCommand(name="unlock_file_handles", command=["dojob", "unlock_handles.bat"], alwaysRun=True))
f_windows.addStep(steps.ShellCommand(name="removedirs", command=["dojob", '"', "powershell", "-command", "Remove-Item", '"$pwd\*"', "-Recurse", "-Force", '"'], alwaysRun=True))
f_windows.addStep(steps.ShellCommand(
             name="fetch_tarball",
             description="fetching source tarball",
             descriptionDone="fetching source tarball...done",
             haltOnFailure=True,
             command=["dojob", '"', "powershell", "-command", "Start-BitsTransfer", "-Source", util.Interpolate("https://ci.mariadb.org/%(prop:tarbuildnum)s/%(prop:mariadb_version)s.tar.gz"), "-Destination", util.Interpolate("%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz"), '"']))
f_windows.addStep(steps.ShellCommand(name="unpack tarball", command=["dojob", '"', util.Interpolate("tar -xvzf %(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz --strip-components=1"), '"']))
f_windows.addStep(steps.Compile(name="cmake", command=["dojob", '"', util.Interpolate("C:\VCTools\Common7\Tools\VsDevCmd.bat -arch=%(kw:arch)s && cmake . -A %(kw:arch_cmake)s -DPLUGIN_ROCKSDB=NO -DMYSQL_MAINTAINER_MODE=ERR -Wno-dev", arch=util.Property('arch', default='x64'), arch_cmake=util.Property('arch_cmake', default='x64')), '"']))
f_windows.addStep(steps.Compile(name="compile", command=["dojob", '"', util.Interpolate("C:\VCTools\Common7\Tools\VsDevCmd.bat -arch=%(kw:arch)s && cmake --build . --verbose --config Debug -- -m", arch=util.Property('arch', default='x64')), '"'], timeout=7200))
f_windows.addStep(steps.MTR(addLogs=True, name="test nm", command=["dojob", '"', util.Interpolate("C:\VCTools\Common7\Tools\VsDevCmd.bat -arch=%(kw:arch)s && cd mysql-test && perl mysql-test-run.pl --verbose-restart --force --suite-timeout=120 --max-test-fail=10 --retry=3 --suite=vcol,gcol,perfschema,main,innodb,versioning,plugins,mariabackup,roles,auth_gssapi,rocksdb --parallel=%(kw:jobs)s %(kw:mtr_additional_args)s && cd ..", mtr_additional_args=util.Property('mtr_additional_args', default=''), jobs=util.Property('jobs', default=4), arch=util.Property('arch', default='x64')), '"'], timeout=7200, haltOnFailure="true", parallel=mtrJobsMultiplier, dbpool=mtrDbPool, autoCreateTables=True))
f_windows.addStep(steps.MTR(addLogs=True, name="extra", command=["dojob", '"', util.Interpolate("C:\VCTools\Common7\Tools\VsDevCmd.bat -arch=%(kw:arch)s && cd mysql-test && perl mysql-test-run.pl  --verbose-restart --force  --testcase-timeout=45 --suite-timeout=600  --retry=3 --suites=connect --parallel=%(kw:jobs)s %(kw:mtr_additional_args)s", mtr_additional_args=util.Property('mtr_additional_args', default=''), jobs=util.Property('jobs', default=4), arch=util.Property('arch', default='x64')), '"'], timeout=7200, haltOnFailure="true", parallel=mtrJobsMultiplier, dbpool=mtrDbPool, autoCreateTables=True))
f_windows.addStep(steps.ShellCommand(name="cleanup", command=["dojob", '"', "powershell", "-command", "Remove-Item", '"$pwd\*"', "-Recurse", "-Force", '"'], alwaysRun=True))

## f_windows_compile
f_windows_compile = util.BuildFactory()
f_windows_compile.addStep(steps.SetProperty(property="dockerfile", value=util.Interpolate("%(kw:url)s", url=dockerfile), description="dockerfile"))
f_windows_compile.addStep(steps.ShellCommand(
             name="fetch_tarball",
             description="fetching source tarball",
             descriptionDone="fetching source tarball...done",
             haltOnFailure=True,
             command=["powershell", "-command", "Start-BitsTransfer", "-Source", util.Interpolate("https://ci.mariadb.org/%(prop:tarbuildnum)s/%(prop:mariadb_version)s.tar.gz"), "-Destination", util.Interpolate("%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz")]))
f_windows_compile.addStep(steps.ShellCommand(name="unpack tarball", command=util.Interpolate("tar -xvzf %(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz --strip-components=1")))
f_windows_compile.addStep(steps.Compile(name="cmake", command=util.Interpolate("C:\VCTools\Common7\Tools\VsDevCmd.bat -arch=%(kw:arch)s && cmake . -A %(kw:arch_cmake)s -DPLUGIN_ROCKSDB=NO -DMYSQL_MAINTAINER_MODE=ERR -Wno-dev", arch=util.Property('arch', default='x64'), arch_cmake=util.Property('arch_cmake', default='x64')))) 
f_windows_compile.addStep(steps.Compile(name="compile", command=util.Interpolate("C:\VCTools\Common7\Tools\VsDevCmd.bat -arch=%(kw:arch)s && cmake --build . --config Debug", arch=util.Property('arch', default='x64')), timeout=7200))
f_windows_compile.addStep(steps.ShellCommand(name="cleanup", command=["powershell", "-command", "Remove-Item", '"$pwd\*"', "-Recurse", "-Force"], alwaysRun=True))

## f_windows_msi
f_windows_msi = util.BuildFactory()
f_windows_msi.addStep(steps.ShellCommand(name="unlock_file_handles", command=["dojob", "unlock_handles.bat"], alwaysRun=True, workdir=util.Interpolate("D:\\Buildbot\\%(prop:buildername)s")))
f_windows_msi.addStep(steps.ShellCommand(name="removedirs", command=["dojob", '"', "powershell", "-command", "Remove-Item", '"$pwd\*"', "-Recurse", "-Force", '"'], alwaysRun=True))
f_windows_msi.addStep(steps.ShellCommand(name="create tmp dir", command="mkdir tmpdir"))
f_windows_msi.addStep(steps.ShellCommand(
             name="fetch_tarball",
             description="fetching source tarball",
             descriptionDone="fetching source tarball...done",
             haltOnFailure=True,
             command=["dojob", '"', "powershell", "-command", "Start-BitsTransfer", "-Source", util.Interpolate("https://ci.mariadb.org/%(prop:tarbuildnum)s/%(prop:mariadb_version)s.tar.gz"), "-Destination", util.Interpolate("%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz"), '"']))
f_windows_msi.addStep(steps.ShellCommand(name="unpack tarball", command=["dojob", '"', util.Interpolate("tar -xvzf %(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz --strip-components=1"), '"']))
f_windows_msi.addStep(steps.Compile(name="cmake", env={'TMP': util.Interpolate("D:\\Buildbot\\%(prop:buildername)s\\build\\tmpdir"), 'TEMP': util.Interpolate("D:\\Buildbot\\%(prop:buildername)s\\build\\tmpdir")}, command=["dojob", '"', util.Interpolate('C:\VCTools\Common7\Tools\VsDevCmd.bat -arch=%(kw:arch)s && cmake . -G "Visual Studio 16 2019" -A %(kw:arch_cmake)s  -DBUILD_CONFIG=mysql_release -DWITH_THIRD_PARTY=HeidiSQL -DWITH_EMBEDDED_SERVER=0 -DSIGNCODE=ON -DWITH_UNIT_TESTS=0 -DMYSQL_MAINTAINER_MODE=ERR', arch=util.Property('arch', default='x64'), arch_cmake=util.Property('arch_cmake', default='x64')), '"']))
f_windows_msi.addStep(steps.Compile(name="compile", env={'TMP': util.Interpolate("D:\\Buildbot\\%(prop:buildername)s\\build\\tmpdir"), 'TEMP': util.Interpolate("D:\\Buildbot\\%(prop:buildername)s\\build\\tmpdir")}, command=["dojob", '"', util.Interpolate("C:\VCTools\Common7\Tools\VsDevCmd.bat -arch=%(kw:arch)s && cmake --build  .  --verbose --config RelWithDebInfo -- -m", arch=util.Property('arch', default='x64')), '"'], timeout=3600))
f_windows_msi.addStep(steps.Compile(name="package", env={'TMP': util.Interpolate("D:\\Buildbot\\%(prop:buildername)s\\build\\tmpdir"), 'TEMP': util.Interpolate("D:\\Buildbot\\%(prop:buildername)s\\build\\tmpdir")}, command=["dojob", '"', util.Interpolate("C:\VCTools\Common7\Tools\VsDevCmd.bat -arch=%(kw:arch)s && cmake --build  .  --config RelWithDebInfo --target win_package && cmake --build  .  --config RelWithDebInfo --target MSI", arch=util.Property('arch', default='x64')), '"'], timeout=3600))
f_windows_msi.addStep(steps.MTR(addLogs=True, name="test nm", env={'TMP': util.Interpolate("D:\\Buildbot\\%(prop:buildername)s\\build\\tmpdir"), 'TEMP': util.Interpolate("D:\\Buildbot\\%(prop:buildername)s\\build\\tmpdir")}, command=["dojob", '"', util.Interpolate("C:\VCTools\Common7\Tools\VsDevCmd.bat -arch=%(kw:arch)s && cd mysql-test && perl mysql-test-run.pl --verbose-restart --force --suite-timeout=120 --max-test-fail=10 --retry=3 --suite=vcol,gcol,perfschema,main,innodb,versioning,plugins,mariabackup,roles,auth_gssapi,rocksdb --parallel=%(kw:jobs)s %(kw:mtr_additional_args)s && cd ..", mtr_additional_args=util.Property('mtr_additional_args', default=''), jobs=util.Property('jobs', default=4), arch=util.Property('arch', default='x64')), '"'], timeout=7200, haltOnFailure="true", parallel=mtrJobsMultiplier, dbpool=mtrDbPool, autoCreateTables=True))
f_windows_msi.addStep(steps.MTR(addLogs=True, name="extra", env={'TMP': util.Interpolate("D:\\Buildbot\\%(prop:buildername)s\\build\\tmpdir"), 'TEMP': util.Interpolate("D:\\Buildbot\\%(prop:buildername)s\\build\\tmpdir")}, command=["dojob", '"', util.Interpolate("C:\VCTools\Common7\Tools\VsDevCmd.bat -arch=%(kw:arch)s && cd mysql-test && perl mysql-test-run.pl  --verbose-restart --force  --testcase-timeout=45 --suite-timeout=600  --retry=3 --suites=connect --parallel=%(kw:jobs)s %(kw:mtr_additional_args)s", mtr_additional_args=util.Property('mtr_additional_args', default=''), jobs=util.Property('jobs', default=4), arch=util.Property('arch', default='x64')), '"'], timeout=7200, haltOnFailure="true", parallel=mtrJobsMultiplier, dbpool=mtrDbPool, autoCreateTables=True))
# create package and upload to master
f_windows_msi.addStep(steps.ShellCommand(command='dojob "dir"'))
f_windows_msi.addStep(steps.ShellCommand(name="sha256sums", command=["powershell", "-command", 'Get-ChildItem .\* -Include @("*.msi", "*.zip") | Get-FileHash | Select-Object Hash, @{Name="Name";Expression={[System.IO.Path]::GetFileName($_.Path)}} | Format-Table -HideTableHeaders | Out-File sha256sums.txt']))
f_windows_msi.addStep(steps.SetPropertyFromCommand(command=["dojob", '"', 'dir /b *.msi *.zip', '"'], extract_fn=ls2list))
f_windows_msi.addStep(steps.MultipleFileUpload(workersrcs=util.Property("packages"), masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + "/" + '%(prop:buildername)s' + "/"), mode=0o755, url=util.Interpolate('https://ci.mariadb.org/' + "%(prop:tarbuildnum)s" + "/" + '%(prop:buildername)s' + "/"), doStepIf=savePackage))
f_windows_msi.addStep(steps.FileUpload(workersrc="sha256sums.txt", masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + "/" + '%(prop:buildername)s' + "/sha256sums.txt"), mode=0o755, url=util.Interpolate('https://ci.mariadb.org/' + "%(prop:tarbuildnum)s" + "/" + '%(prop:buildername)s' + "/"), doStepIf=savePackage))
f_windows_msi.addStep(steps.ShellCommand(name="cleanup", command=["dojob", '"', "powershell", "-command", "Remove-Item", '"$pwd\*"', "-Recurse", "-Force", '"'], alwaysRun=True))

## f_eco_php
f_eco_php = util.BuildFactory()
f_eco_php.addStep(steps.ShellCommand(
    name="fetch_install_script",
    command=["sh", "-xc", "curl https://raw.githubusercontent.com/MariaDB/mariadb.org-tools/master/buildbot.mariadb.org/dockerfiles/ecofiles/installdb.sh -o /buildbot/installdb.sh && chmod a+x /buildbot/installdb.sh"]))
f_eco_php.addStep(steps.ShellCommand(
    name="fetch_test_script",
    command=["sh", "-xc", "curl https://raw.githubusercontent.com/MariaDB/mariadb.org-tools/master/buildbot.mariadb.org/dockerfiles/ecofiles/test-php.sh -o /buildbot/test-php.sh && chmod a+x /buildbot/test-php.sh"]))
f_eco_php.addStep(steps.ShellCommand(
    name="fetching and installing database",
    command=["sh", "-xc", util.Interpolate("/buildbot/installdb.sh \"https://ci.mariadb.org/%(prop:tarbuildnum)s/%(prop:parentbuildername)s/%(prop:mariadb_binary)s\" --plugin-load-add=auth_pam --pam_use_cleartext_plugin")]))
f_eco_php.addStep(steps.ShellCommand(
    name="test PHP-7.1",
    command=["sh", "-xc", "/buildbot/test-php.sh PHP-7.1"]))
f_eco_php.addStep(steps.ShellCommand(
    name="test PHP-8.0",
    command=["sh", "-xc", "/buildbot/test-php.sh PHP-8.0"]))

## f_eco_dbdeployer
f_eco_dbdeployer = util.BuildFactory()
f_eco_dbdeployer.addStep(steps.ShellCommand(
    name="fetch_test_script",
    command=["sh", "-xc", "curl https://raw.githubusercontent.com/MariaDB/mariadb.org-tools/master/buildbot.mariadb.org/dockerfiles/ecofiles/test-dbdeployer.sh -o /buildbot/test-dbdeployer.sh && chmod a+x /buildbot/test-dbdeployer.sh"]))
f_eco_dbdeployer.addStep(steps.ShellCommand(
    name="download if needed latest dbdeployer",
    command=["sh", "-xc", "/buildbot/test-dbdeployer.sh dbdeployerfetch"]))
f_eco_dbdeployer.addStep(steps.ShellCommand(
    name="fetching mariadb tarball",
    command=["sh", "-xc", util.Interpolate("/buildbot/test-dbdeployer.sh init \"https://ci.mariadb.org/%(prop:tarbuildnum)s/%(prop:parentbuildername)s/%(prop:mariadb_binary)s\"")]))
f_eco_dbdeployer.addStep(steps.ShellCommand(
    name="deploy single ma",
    command=["sh", "-xc", util.Interpolate("/buildbot/test-dbdeployer.sh deploy single ma%(prop:mariadb_version)s")]))
f_eco_dbdeployer.addStep(steps.ShellCommand(
    name="deploy replication ma",
    command=["sh", "-xc", util.Interpolate("/buildbot/test-dbdeployer.sh deploy replication ma%(prop:mariadb_version)s")]))
f_eco_dbdeployer.addStep(steps.ShellCommand(
    name="global test",
    command=["sh", "-xc", "/buildbot/test-dbdeployer.sh global test"]))
f_eco_dbdeployer.addStep(steps.ShellCommand(
    name="global replication",
    command=["sh", "-xc", "/buildbot/test-dbdeployer.sh global test-replication"]))

## f_eco_pymysql
f_eco_pymysql = util.BuildFactory()
f_eco_pymysql.addStep(steps.ShellCommand(
    name="fetch_install_script",
    command=["sh", "-xc", "curl https://raw.githubusercontent.com/MariaDB/mariadb.org-tools/master/buildbot.mariadb.org/dockerfiles/ecofiles/installdb.sh -o /buildbot/installdb.sh && chmod a+x /buildbot/installdb.sh"]))
f_eco_pymysql.addStep(steps.ShellCommand(
    name="fetch_test_script",
    command=["sh", "-xc", "curl https://raw.githubusercontent.com/MariaDB/mariadb.org-tools/master/buildbot.mariadb.org/dockerfiles/ecofiles/test-pymysql.sh -o /buildbot/test-pymysql.sh && chmod a+x /buildbot/test-pymysql.sh"]))
f_eco_pymysql.addStep(steps.ShellCommand(
    name="fetching and installing database",
    command=["sh", "-xc", util.Interpolate("/buildbot/installdb.sh \"https://ci.mariadb.org/%(prop:tarbuildnum)s/%(prop:parentbuildername)s/%(prop:mariadb_binary)s\"")]))
f_eco_pymysql.addStep(steps.ShellCommand(
    name="test pymysql-master",
    command=["sh", "-xc", "/buildbot/test-pymysql.sh"]))
f_eco_pymysql.addStep(steps.ShellCommand(
    name="test pymysql-v0.7.11",
    command=["sh", "-xc", "/buildbot/test-pymysql.sh v0.7.11"]))

## f_eco_mysqljs
f_eco_mysqljs = util.BuildFactory()
f_eco_mysqljs.addStep(steps.ShellCommand(
    name="fetch_install_script",
    command=["sh", "-xc", "curl https://raw.githubusercontent.com/MariaDB/mariadb.org-tools/master/buildbot.mariadb.org/dockerfiles/ecofiles/installdb.sh -o /buildbot/installdb.sh && chmod a+x /buildbot/installdb.sh"]))
f_eco_mysqljs.addStep(steps.ShellCommand(
    name="fetch_test_script",
    command=["sh", "-xc", "curl https://raw.githubusercontent.com/MariaDB/mariadb.org-tools/master/buildbot.mariadb.org/dockerfiles/ecofiles/test-mysqljs.sh -o /buildbot/test-mysqljs.sh && chmod a+x /buildbot/test-mysqljs.sh"]))
f_eco_mysqljs.addStep(steps.ShellCommand(
    name="fetching and installing database",
    command=["sh", "-xc", util.Interpolate("/buildbot/installdb.sh \"https://ci.mariadb.org/%(prop:tarbuildnum)s/%(prop:parentbuildername)s/%(prop:mariadb_binary)s\"")]))
f_eco_mysqljs.addStep(steps.ShellCommand(
    name="test mysqljs-master",
    command=["sh", "-xc", "/buildbot/test-mysqljs.sh"]))
f_eco_mysqljs.addStep(steps.ShellCommand(
    name="test mysqljs-v2.18.1",
    command=["sh", "-xc", "/buildbot/test-mysqljs.sh v2.18.1"]))

# f_dockerlibrary
f_dockerlibrary = util.BuildFactory()
f_dockerlibrary.addStep(steps.ShellCommand(
    name="Update Fetch/Test Script",
    command=["sh", "-xc", "curl https://raw.githubusercontent.com/MariaDB/mariadb.org-tools/master/buildbot.mariadb.org/scripts/docker-library-build-and-test.sh -o docker-library-build-and-test.sh && chmod a+x docker-library-build-and-test.sh"]))
f_dockerlibrary.addStep(steps.ShellCommand(
    name="building and test docker library image for MariaDB",
    command=["bash", "-xc", util.Interpolate("./docker-library-build-and-test.sh \"%(prop:tarbuildnum)s\" \"%(prop:mariadb_version)s\" \"%(prop:parentbuildername)s\" \"%(prop:revision)s\"")]))

## f_aix
f_aix = util.BuildFactory()
f_aix.addStep(steps.SetProperty(property="dockerfile", value=util.Interpolate("%(kw:url)s", url=dockerfile), description="dockerfile"))
f_aix.addStep(downloadSourceTarballAIX())
f_aix.addStep(steps.ShellCommand(command=util.Interpolate("tar -xvzf /mnt/packages/%(prop:tarbuildnum)s_%(prop:mariadb_version)s.tar.gz --strip-components=1")))
f_aix.addStep(steps.ShellCommand(name="create html log file", command=['bash', '-c', util.Interpolate(getHTMLLogString(), jobs=util.Property('jobs', default='6'))]))
# build steps
f_aix.addStep(steps.Compile(command=
    ["sh", "-c", util.Interpolate("export TMPDIR=$HOME/tmp && export LIBPATH=/opt/freeware/lib/pthread/ppc64:/opt/freeware/lib:/usr/lib && cmake . -DCMAKE_BUILD_TYPE=%(kw:build_type)s -DCMAKE_C_COMPILER=%(kw:c_compiler)s -DCMAKE_CXX_COMPILER=%(kw:cxx_compiler)s -DCMAKE_AR=/usr/bin/ar -DLIBXML2_LIBRARY=/opt/freeware/lib/libxml2.a  -DPLUGIN_TOKUDB=NO -DPLUGIN_MROONGA=NO -DPLUGIN_SPIDER=NO -DPLUGIN_OQGRAPH=NO -DPLUGIN_PERFSCHEMA=%(kw:perf_schema)s -DPLUGIN_SPHINX=NO %(kw:additional_args)s -DWITH_UNIT_TESTS=NO -DPLUGIN_S3=NO -DWITH_MARIABACKUP=NO -DPLUGIN_WSREP_INFO=NO && make -j%(kw:jobs)s", perf_schema=util.Property('perf_schema', default='YES'), build_type=util.Property('build_type', default='RelWithDebInfo'), jobs=util.Property('jobs', default='3'), c_compiler=util.Property('c_compiler', default='gcc'), cxx_compiler=util.Property('cxx_compiler', default='g++'), additional_args=util.Property('additional_args', default='') )], env={'CCACHE_DIR':'/mnt/ccache'}, haltOnFailure="true"))

f_aix.addStep(steps.MTR(logfiles={"mysqld*": "/buildbot/mysql_logs.html"}, command=
    ["sh", "-c", util.Interpolate("cd mysql-test && exec perl mysql-test-run.pl --verbose-restart --force --retry=3 --max-save-core=1 --max-save-datadir=1 --skip-test='connect\.(grant|updelx)$' --max-test-fail=20 --parallel=6")], timeout=7200, haltOnFailure="true", parallel=mtrJobsMultiplier, dbpool=mtrDbPool, autoCreateTables=True))
f_aix.addStep(steps.ShellCommand(name="move mysqld log files", alwaysRun=True, command=['bash', '-c', util.Interpolate(moveMTRLogs(), jobs=util.Property('jobs', default='6'))]))
f_aix.addStep(steps.DirectoryUpload(name="save mysqld log files", compress="bz2", alwaysRun=True,  workersrc='/buildbot/logs/', masterdest=util.Interpolate('/srv/buildbot/packages/' + '%(prop:tarbuildnum)s' + '/logs/' + '%(prop:buildername)s' )))
f_aix.addStep(steps.ShellCommand(name="cleanup", command="rm -r * .* /mnt/packages/* 2> /dev/null || true", alwaysRun=True))



####### LOCKS
main_master_lock = util.MasterLock('main_master_lock', maxCount=30)

hz_bbw1_lock = util.MasterLock('hz_bbw1_lock', maxCount=7)
hz_bbw2_lock = util.MasterLock('hz_bbw2_lock', maxCount=7)
intel_bbw1_lock = util.MasterLock('intel_bbw1_lock', maxCount=18)
p9_rhel8_bbw1_lock = util.MasterLock('p9_rhel8_bbw1_lock', maxCount=4)
p9_rhel7_bbw1_lock = util.MasterLock('p9_rhel7_bbw1_lock', maxCount=2)
p9_db_bbw1_lock = util.MasterLock('p9_db_bbw1_lock', maxCount=5)
aarch_bbw1_lock = util.MasterLock('aarch64_bbw1_lock', maxCount=2)
aarch_bbw2_lock = util.MasterLock('aarch64_bbw2_lock', maxCount=2)
aarch_bbw3_lock = util.MasterLock('aarch64_bbw3_lock', maxCount=2)
aarch_bbw4_lock = util.MasterLock('aarch64_bbw4_lock', maxCount=2)
apexis_bbw1_lock = util.MasterLock('apexis_bbw1_lock', maxCount=1)
apexis_bbw2_lock = util.MasterLock('apexis_bbw2_lock', maxCount=1)
bg_bbw1_lock = util.MasterLock('bg_bbw1_lock', maxCount=3)
bg_bbw2_lock = util.MasterLock('bg_bbw2_lock', maxCount=2)
bg_bbw3_lock = util.MasterLock('bg_bbw3_lock', maxCount=2)
bg_bbw4_lock = util.MasterLock('bg_bbw4_lock', maxCount=2)
bg_bbw5_lock = util.MasterLock('bg_bbw5_lock', maxCount=2)
win_bbw1_lock = util.MasterLock('win_bbw1_lock', maxCount=1)
win_bbw2_lock = util.MasterLock('win_bbw2_lock', maxCount=4)
s390x_bbw1_lock = util.MasterLock('s390x_bbw1_lock', maxCount=1)

@util.renderer
def getLocks(props):
    worker_name = props.getProperty('workername', default=None)
    builder_name = props.getProperty('buildername', default=None)
    assert worker_name is not None
    assert builder_name is not None

    if builder_name in github_status_builders or builder_name in builders_install or builder_name in builders_upgrade:
        locks = []
    else:
        locks = [main_master_lock.access('counting')]

    if 'hz-bbw1-docker' in worker_name:
        locks = locks + [hz_bbw1_lock.access('counting')]
    if 'hz-bbw2-docker' in worker_name:
        locks = locks + [hz_bbw2_lock.access('counting')]
    if 'intel-bbw1-docker' in worker_name:
        locks = locks + [intel_bbw1_lock.access('counting')]
    if 'p9-rhel8-bbw1-docker' in worker_name:
        locks = locks + [p9_rhel8_bbw1_lock.access('counting')]
    if 'p9-rhel7-bbw1-docker' in worker_name:
        locks = locks + [p9_rhel7_bbw1_lock.access('counting')]
    if 'p9-db-bbw1-docker' in worker_name:
        locks = locks + [p9_db_bbw1_lock.access('counting')]
    if 'aarch64-bbw1-docker' in worker_name:
        locks = locks + [aarch_bbw1_lock.access('counting')]
    if 'aarch64-bbw2-docker' in worker_name:
        locks = locks + [aarch_bbw2_lock.access('counting')]
    if 'aarch64-bbw3-docker' in worker_name:
        locks = locks + [aarch_bbw3_lock.access('counting')]
    if 'aarch64-bbw4-docker' in worker_name:
        locks = locks + [aarch_bbw4_lock.access('counting')]
    if 'fjord1-docker' in worker_name:
        locks = locks + [apexis_bbw1_lock.access('counting')]
    if 'fjord2-docker' in worker_name:
        locks = locks + [apexis_bbw2_lock.access('counting')]
    if 'bg-bbw1-docker' in worker_name:
        locks = locks + [bg_bbw1_lock.access('counting')]
    if 'bg-bbw2-docker' in worker_name:
        locks = locks + [bg_bbw2_lock.access('counting')]
    if 'bg-bbw3-docker' in worker_name:
        locks = locks + [bg_bbw3_lock.access('counting')]
    if 'bg-bbw4-docker' in worker_name:
        locks = locks + [bg_bbw4_lock.access('counting')]
    if 'bg-bbw5-docker' in worker_name:
        locks = locks + [bg_bbw5_lock.access('counting')]
    if 'bbw1-docker-windows' in worker_name:
        locks = locks + [win_bbw1_lock.access('counting')]
    if 'bbw2-docker-windows' in worker_name:
        locks = locks + [win_bbw2_lock.access('counting')]
    if 's390x-docker' in worker_name:
        locks = locks + [s390x_bbw1_lock.access('counting')]

    return locks

protected_branches_mtr_additional_args = '--suite=main --skip-test="^stack_crash$|^float$|^derived_split_innodb$|^mysql_client_test$|^kill$|^processlist_not_embedded$|^sp-big$"'

####### BUILDERS LIST
c['builders'] = []

'''
 c['builders'].append(
    util.BuilderConfig(name="macos-10-13",
      workernames=["shinnok-bbw1-macos"],
      factory=f_macos_10_13))
'''

c['builders'].append(
    util.BuilderConfig(name="tarball-docker",
      workernames=["hz-bbw1-docker-tarball-debian-10", "intel-bbw1-docker-tarball-1-debian-10",  "intel-bbw1-docker-tarball-2-debian-10",  "intel-bbw1-docker-tarball-3-debian-10", "intel-bbw1-docker-tarball-4-debian-10", "intel-bbw1-docker-tarball-5-debian-10"],
      tags=["tar", "bake"],
      collapseRequests=True,
      nextBuild=nextBuild,
      factory=f_tarball))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-1804",
      workernames=workers["x64-bbw-docker-ubuntu-1804"],
      tags=["Ubuntu", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-1804-deb-autobake",
      workernames=workers["x64-bbw-docker-ubuntu-1804"],
      tags=["Ubuntu", "deb", "bake", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-1804-deb-autobake-install",
      workernames=["buildbot-ubuntu1804"],
      tags=["Ubuntu", "deb", "install", "kvm"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      properties={'systemdCapability': 'yes', 'needsGalera': 'yes', 'dist_name': 'ubuntu', 'version_name': 'bionic', 'arch': 'amd64'},
      factory=f_deb_install))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-1804-deb-autobake-major-upgrade",
      workernames=["buildbot-ubuntu1804"],
      tags=["Ubuntu", "deb", "upgrade", "kvm"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      properties={'systemdCapability': 'yes', 'needsGalera': 'yes', 'dist_name': 'ubuntu', 'version_name': 'bionic', 'arch': 'amd64', 'test_mode': 'server', "test_type": "major"},
      factory=f_deb_upgrade))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-1804-deb-autobake-minor-upgrade",
      workernames=["buildbot-ubuntu1804"],
      tags=["Ubuntu", "deb", "upgrade", "kvm"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      properties={'systemdCapability': 'yes', 'needsGalera': 'yes', 'dist_name': 'ubuntu', 'version_name': 'bionic', 'arch': 'amd64', 'test_mode': 'all', "test_type": "minor"},
      factory=f_deb_upgrade))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-2004",
      workernames=workers["x64-bbw-docker-ubuntu-2004"],
      tags=["Ubuntu", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-2004-clang11",
      workernames=workers["x64-bbw-docker-ubuntu-2004-clang"],
      tags=["Ubuntu", "quick", "clang"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'c_compiler': 'clang-11', 'cxx_compiler': 'clang++', 'mtr_additional_args': protected_branches_mtr_additional_args},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-2004-gcc10",
      workernames=workers["bg-bbw-docker-ubuntu-2004"],
      tags=["Ubuntu", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'c_compiler': 'gcc-10', 'cxx_compiler': 'g++-10'},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-2004-icc",
      workernames=workers["x64-bbw-docker-icc-ubuntu-2004"],
      tags=["Ubuntu", "quick", "icc", "icpc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'c_compiler': 'icc', 'cxx_compiler': 'icpc'},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-2004-deb-autobake",
      workernames=workers["bg-bbw-docker-ubuntu-2004"],
      tags=["Ubuntu", "deb", "bake", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="s390x-ubuntu-2004",
      workernames=workers["s390x-bbw-docker-ubuntu-2004"],
      tags=["Ubuntu", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="s390x-ubuntu-2004-deb-autobake",
      workernames=workers["s390x-bbw-docker-ubuntu-2004"],
      tags=["Ubuntu", "deb", "bake", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-2010",
      workernames=workers["x64-bbw-docker-ubuntu-2010"],
      tags=["Ubuntu", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-2010-deb-autobake",
      workernames=workers["x64-bbw-docker-ubuntu-2010"],
      tags=["Ubuntu", "deb", "bake", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-2104",
      workernames=workers["x64-bbw-docker-ubuntu-2104"],
      tags=["Ubuntu", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-2104-deb-autobake",
      workernames=workers["x64-bbw-docker-ubuntu-2104"],
      tags=["Ubuntu", "deb", "bake", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-2004-eco-php",
      workernames=["hz-bbw1-docker-eco-php-ubuntu-2004"],
      tags=["Ubuntu", "ecosystem", "PHP"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      factory=f_eco_php))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-2004-eco-dbdeployer",
      workernames=["hz-bbw1-docker-eco-dbdeployer-ubuntu-2004"],
      tags=["Ubuntu", "ecosystem", "dbdeployer"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      factory=f_eco_dbdeployer))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-10-eco-pymysql",
      workernames=["hz-bbw1-docker-eco-pymysql-python-3-9-slim-buster"],
      tags=["Debian", "ecosystem", "pymysql"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      factory=f_eco_pymysql))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-10-eco-mysqljs",
      workernames=["hz-bbw1-docker-eco-mysqljs-nodejs15-buster"],
      tags=["Debian", "ecosystem", "mysqljs"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      factory=f_eco_mysqljs))

c['builders'].append(
    util.BuilderConfig(name="amd64-rhel8-dockerlibrary",
      workernames=["bb-rhel8-docker"],
      tags=["RHEL"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      factory=f_dockerlibrary))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-1804-bigtest",
      workernames=["bm-bbw1-docker-ubuntu-1804"],
      tags=["Ubuntu", "big", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      factory=f_big_test))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-9",
      workernames=workers["x64-bbw-docker-debian-9"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-9-deb-autobake",
      workernames=workers["x64-bbw-docker-debian-9"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="x86-debian-9",
      workernames=workers["x64-bbw-docker-debian-9-i386"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="x86-debian-9-deb-autobake",
      workernames=workers["x64-bbw-docker-debian-9-i386"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-10",
      workernames=workers["x64-bbw-docker-debian-10"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'mtr_additional_args': protected_branches_mtr_additional_args},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-10-deb-autobake",
      workernames=workers["bg-bbw-docker-debian-10"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-11",
      workernames=workers["x64-bbw-docker-debian-11"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'mtr_additional_args': protected_branches_mtr_additional_args},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-11-deb-autobake",
      workernames=workers["x64-bbw-docker-debian-11"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-sid",
      workernames=workers["x64-bbw-docker-debian-sid"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-sid-deb-autobake",
      workernames=workers["x64-bbw-docker-debian-sid"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="x86-debian-sid",
      workernames=workers["x64-bbw-docker-debian-sid-i386"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="x86-debian-sid-deb-autobake",
      workernames=workers["x64-bbw-docker-debian-sid-i386"],
      tags=["Debian", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-rhel-7",
      workernames=workers["x64-bbw-docker-rhel-7"],
      tags=["RHEL", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-rhel-7-rpm-autobake",
      workernames=workers["x64-bbw-docker-rhel-7"],
      tags=["RHEL", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'rhel7'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-rhel-8",
      workernames=workers["x64-bbw-docker-rhel-8"],
      tags=["RHEL", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-rhel-8-rpm-autobake",
      workernames=workers["bg-bbw-docker-rhel-8"],
      tags=["RHEL", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'rhel8'},
      factory=f_rpm_autobake))


c['builders'].append(
    util.BuilderConfig(name="amd64-fedora-33",
      workernames=workers["x64-bbw-docker-fedora-33"],
      tags=["Fedora", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'mtr_additional_args': protected_branches_mtr_additional_args},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-fedora-33-rpm-autobake",
      workernames=workers["bg-bbw-docker-fedora-33"],
      tags=["Fedora", "rpm", "bake", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'fedora33'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-fedora-34",
      workernames=workers["x64-bbw-docker-fedora-34"],
      tags=["Fedora", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-fedora-34-rpm-autobake",
      workernames=workers["bg-bbw-docker-fedora-34"],
      tags=["Fedora", "rpm", "bake", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'fedora34'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-sles-12",
      workernames=workers["x64-bbw-docker-sles-12"],
      tags=["Fedora", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-sles-12-rpm-autobake",
      workernames=workers["x64-bbw-docker-sles-12"],
      tags=["Fedora", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'sles12'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-sles-15",
      workernames=workers["x64-bbw-docker-sles-15"],
      tags=["Fedora", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-sles-15-rpm-autobake",
      workernames=workers["x64-bbw-docker-sles-15"],
      tags=["Fedora", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'sles15'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-centos-7",
      workernames=workers["x64-bbw-docker-centos-7"],
      tags=["Centos", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'mtr_additional_args': protected_branches_mtr_additional_args},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-centos-7-rpm-autobake",
      workernames=workers["bg-bbw-docker-centos-7"],
      tags=["Centos", "rpm", "bake", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'centos7'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-centos-7-rpm-autobake-install",
      workernames=["buildbot-centos7"],
      tags=["Centos", "rpm", "install"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      properties={'systemdCapability': 'yes', 'needsGalera': 'yes', 'version_name': '7', 'arch': 'centos74-amd64'},
      factory=f_rpm_install))

c['builders'].append(
    util.BuilderConfig(name="amd64-centos-7-rpm-autobake-major-upgrade",
      workernames=["buildbot-centos7"],
      tags=["Centos", "rpm", "upgrade"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      properties={'systemdCapability': 'yes', 'needsGalera': 'yes', 'version_name': 'centos7', 'arch': 'amd64', "test_type": "major", "test_mode": "server"},
      factory=f_rpm_upgrade))

c['builders'].append(
    util.BuilderConfig(name="amd64-centos-7-rpm-autobake-minor-upgrade",
      workernames=["buildbot-centos7"],
      tags=["Centos", "rpm", "upgrade"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      properties={'systemdCapability': 'yes', 'needsGalera': 'yes', 'version_name': 'centos7', 'arch': 'amd64', "test_type": "minor", "test_mode": "server"},
      factory=f_rpm_upgrade))


c['builders'].append(
    util.BuilderConfig(name="amd64-centos-8",
      workernames=workers["bg-bbw-docker-centos-8"],
      tags=["Centos", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-centos-8-rpm-autobake",
      workernames=workers["bg-bbw-docker-centos-8"],
      tags=["Centos", "rpm", "bake", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'centos8'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-opensuse-15",
      workernames=workers["x64-bbw-docker-opensuse-15"],
      tags=["OpenSUSE", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-opensuse-15-rpm-autobake",
      workernames=workers["bg-bbw-docker-opensuse-15"],
      tags=["OpenSUSE", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'opensuse15'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-opensuse-42",
      workernames=workers["x64-bbw-docker-opensuse-42"],
      tags=["OpenSUSE", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-opensuse-42-rpm-autobake",
      workernames=workers["x64-bbw-docker-opensuse-42"],
      tags=["OpenSUSE", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'opensuse42'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-2004-fulltest",
      workernames=workers["bg-bbw-docker-ubuntu-2004"],
      tags=["Ubuntu", "full", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_full_test))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-ubuntu-1804",
      workernames=workers["p9-bbw-docker-ubuntu-1804"],
      tags=["Ubuntu", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-ubuntu-1804-deb-autobake",
      workernames=workers["p9-bbw-docker-ubuntu-1804"],
      tags=["Ubuntu", "deb", "bake", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-ubuntu-2004",
      workernames=workers["p9-bbw-docker-ubuntu-2004"],
      tags=["Ubuntu", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-ubuntu-2004-deb-autobake",
      workernames=workers["p9-bbw-docker-ubuntu-2004"],
      tags=["Ubuntu", "deb", "bake", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-ubuntu-2010",
      workernames=workers["p9-bbw-docker-ubuntu-2010"],
      tags=["Ubuntu", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-ubuntu-2010-deb-autobake",
      workernames=workers["p9-bbw-docker-ubuntu-2010"],
      tags=["Ubuntu", "deb", "bake", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-ubuntu-2104",
      workernames=workers["p9-bbw-docker-ubuntu-2104"],
      tags=["Ubuntu", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-ubuntu-2104-deb-autobake",
      workernames=workers["p9-bbw-docker-ubuntu-2104"],
      tags=["Ubuntu", "deb", "bake", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-debian-9",
      workernames=workers["p9-bbw-docker-debian-9"],
      tags=["Ubuntu", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-debian-9-deb-autobake",
      workernames=workers["p9-bbw-docker-debian-9"],
      tags=["Ubuntu", "deb", "bake", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-debian-10",
      workernames=workers["p9-bbw-docker-debian-10"],
      tags=["Ubuntu", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-debian-10-deb-autobake",
      workernames=workers["p9-bbw-docker-debian-10"],
      tags=["Ubuntu", "deb", "bake", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-debian-11",
      workernames=workers["p9-bbw-docker-debian-11"],
      tags=["Ubuntu", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-debian-11-deb-autobake",
      workernames=workers["p9-bbw-docker-debian-11"],
      tags=["Ubuntu", "deb", "bake", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-debian-sid",
      workernames=workers["p9-bbw-docker-debian-sid"],
      tags=["Ubuntu", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-debian-sid-deb-autobake",
      workernames=workers["p9-bbw-docker-debian-sid"],
      tags=["Ubuntu", "deb", "bake", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-ubuntu-1804-without-server",
      workernames=workers["p9-bbw-docker-ubuntu-1804"],
      tags=["Ubuntu", "without-server", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_without_server))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-ubuntu-1804-clang6",
      workernames=workers["p9-bbw-docker-clang-ubuntu-1804"],
      tags=["Ubuntu", "quick", "clang-6", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'c_compiler': 'clang-6.0', 'cxx_compiler': 'clang++-6.0', 'additional_args': '-DWITHOUT_ROCKSDB=True -DWITHOUT_CONNECT=True -DCMAKE_C_FLAGS=-Wno-inconsistent-missing-override -DCMAKE_CXX_FLAGS=-Wno-inconsistent-missing-override'},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-ubuntu-1804-clang10",
      workernames=workers["p9-bbw-docker-clang-ubuntu-1804"],
      tags=["Ubuntu", "quick", "clang-10", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'c_compiler': 'clang-10', 'cxx_compiler': 'clang++', 'additional_args': '-DWITHOUT_ROCKSDB=True -DWITHOUT_CONNECT=True -DCMAKE_C_FLAGS=-Wno-inconsistent-missing-override -DCMAKE_CXX_FLAGS=-Wno-inconsistent-missing-override'},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-rhel-7",
      workernames=workers["p9-bbw-docker-rhel-7"],
      tags=["RHEL", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-rhel-7-rpm-autobake",
      workernames=workers["p9-bbw-docker-rhel-7"],
      tags=["RHEL", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'rhel7'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-rhel-8",
      workernames=workers["p9-bbw-docker-rhel-8"],
      tags=["RHEL", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'mtr_additional_args': protected_branches_mtr_additional_args},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-rhel-8-rpm-autobake",
      workernames=workers["p9-bbw-docker-rhel-8"],
      tags=["RHEL", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'rhel8'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-centos-7",
      workernames=workers["p9-bbw-docker-centos-7"],
      tags=["Centos", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-centos-7-rpm-autobake",
      workernames=workers["p9-bbw-docker-centos-7"],
      tags=["Centos", "quick", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'centos7'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-1804-clang6",
      workernames=["fjord1-docker-ubuntu-1804"] + workers["x64-bbw-docker-clang-ubuntu-1804"],
      tags=["Ubuntu", "quick", "clang-6"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'c_compiler': 'clang-6.0', 'cxx_compiler': 'clang++-6.0', 'additional_args': '-DCMAKE_C_FLAGS=-Wno-inconsistent-missing-override -DCMAKE_CXX_FLAGS=-Wno-inconsistent-missing-override'},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-1804-debug",
      workernames=["fjord1-docker-ubuntu-1804"] + workers["x64-bbw-docker-clang-ubuntu-1804"],
      tags=["Ubuntu", "quick", "gcc", "debug"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'build_type': 'Debug'},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-1804-clang10",
      workernames=["fjord2-docker-ubuntu-1804"] + workers["x64-bbw-docker-clang-ubuntu-1804"],
      tags=["Ubuntu", "quick", "clang-10"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'c_compiler': 'clang-10', 'cxx_compiler': 'clang++', 'additional_args': '-DCMAKE_C_FLAGS=-Wno-inconsistent-missing-override -DCMAKE_CXX_FLAGS=-Wno-inconsistent-missing-override'},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-1804-clang10-asan",
      workernames=["fjord2-docker-ubuntu-1804"] + workers["x64-bbw-docker-clang-ubuntu-1804"],
      tags=["Ubuntu", "quick", "clang-10", "asan"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_asan_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-1804-msan",
      workernames=workers["bg-bbw-docker-msan-clang-ubuntu-1804"],
      tags=["Ubuntu", "quick", "clang-10", "msan"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_msan_build))

c['builders'].append(
    util.BuilderConfig(name="x86-ubuntu-1804",
      workernames=workers["bg-bbw-docker-x86-ubuntu-1804"],
      tags=["Ubuntu", "quick", "gcc", "32bit"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_32b_quick_build))

c['builders'].append(
    util.BuilderConfig(name="amd64-ubuntu-1804-valgrind",
      workernames=workers["bg-bbw-docker-valgrind-ubuntu-1804"] + workers['x64-bbw-docker-valgrind-ubuntu-1804'],
      tags=["Ubuntu", "quick", "gcc", "valgrind"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_valgrind_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-ubuntu-1804",
      workernames=workers["aarch64-bbw-docker-ubuntu-1804"],
      tags=["Ubuntu", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-ubuntu-1804-deb-autobake",
      workernames=workers["aarch64-bbw-docker-ubuntu-1804"],
      tags=["Ubuntu", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-ubuntu-2004",
      workernames=workers["aarch64-bbw-docker-ubuntu-2004"],
      tags=["Ubuntu", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-ubuntu-2004-deb-autobake",
      workernames=workers["aarch64-bbw-docker-ubuntu-2004"],
      tags=["Ubuntu", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-ubuntu-2010",
      workernames=workers["aarch64-bbw-docker-ubuntu-2010"],
      tags=["Ubuntu", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-ubuntu-2010-deb-autobake",
      workernames=workers["aarch64-bbw-docker-ubuntu-2010"],
      tags=["Ubuntu", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-ubuntu-2104",
      workernames=workers["aarch64-bbw-docker-ubuntu-2104"],
      tags=["Ubuntu", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-ubuntu-2104-deb-autobake",
      workernames=workers["aarch64-bbw-docker-ubuntu-2104"],
      tags=["Ubuntu", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-fedora-33",
      workernames=workers["aarch64-bbw-docker-fedora-33"],
      tags=["Fedora", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-fedora-33-rpm-autobake",
      workernames=workers["aarch64-bbw-docker-fedora-33"],
      tags=["Fedora", "rpm", "bake", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'fedora33'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-fedora-34",
      workernames=workers["aarch64-bbw-docker-fedora-34"],
      tags=["Fedora", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-fedora-34-rpm-autobake",
      workernames=workers["aarch64-bbw-docker-fedora-34"],
      tags=["Fedora", "rpm", "bake", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'fedora34'},
      factory=f_rpm_autobake))



c['builders'].append(
    util.BuilderConfig(name="aarch64-centos-7",
      workernames=workers["aarch64-bbw-docker-centos-7"],
      tags=["Centos", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-centos-7-rpm-autobake",
      workernames=workers["aarch64-bbw-docker-centos-7"],
      tags=["Centos", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'centos7'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-centos-8",
      workernames=workers["aarch64-bbw-docker-centos-8"],
      tags=["Centos", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-centos-8-rpm-autobake",
      workernames=workers["aarch64-bbw-docker-centos-8"],
      tags=["Centos", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'centos8'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-debian-9",
      workernames=workers["aarch64-bbw-docker-debian-9"],
      tags=["Debian", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-debian-9-deb-autobake",
      workernames=workers["aarch64-bbw-docker-debian-9"],
      tags=["Debian", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-debian-10",
      workernames=["aarch64-bbw4-docker-debian-10"],
      tags=["Debian", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'mtr_additional_args': protected_branches_mtr_additional_args},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-debian-10-deb-autobake",
      workernames=workers["aarch64-bbw-docker-debian-10"],
      tags=["Debian", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-debian-11",
      workernames=["aarch64-bbw4-docker-debian-11"],
      tags=["Debian", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'mtr_additional_args': protected_branches_mtr_additional_args},
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-debian-11-deb-autobake",
      workernames=workers["aarch64-bbw-docker-debian-11"],
      tags=["Debian", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-debian-sid",
      workernames=workers["aarch64-bbw-docker-debian-sid"],
      tags=["Debian", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-debian-sid-deb-autobake",
      workernames=workers["aarch64-bbw-docker-debian-sid"],
      tags=["Debian", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_deb_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-rhel-7",
      workernames=workers["aarch64-bbw-docker-rhel-7"],
      tags=["RHEL", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-rhel-7-rpm-autobake",
      workernames=workers["aarch64-bbw-docker-rhel-7"],
      tags=["RHEL", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'rhel7'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="aarch64-rhel-8",
      workernames=workers["aarch64-bbw-docker-rhel-8"],
      tags=["RHEL", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      factory=f_quick_build))

c['builders'].append(
    util.BuilderConfig(name="aarch64-rhel-8-rpm-autobake",
      workernames=workers["aarch64-bbw-docker-rhel-8"],
      tags=["RHEL", "quick", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'rpm_type': 'rhel8', 'mtr_additional_args': '-DPLUGIN_COLUMNSTORE=NO'},
      factory=f_rpm_autobake))

c['builders'].append(
    util.BuilderConfig(name="x86-debian-9-bintar-systemd",
      workernames=workers["x64-bbw-docker-debian-9-i386"],
      tags=["Debian", "bintar", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'additional_args': '-DWITH_SYSTEMD=yes'},
      factory=f_bintar))

c['builders'].append(
    util.BuilderConfig(name="x86-debian-9-bintar-initd",
      workernames=workers["x64-bbw-docker-debian-9-i386"],
      tags=["Debian", "bintar", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'additional_args': '-DWITH_SYSTEMD=no'},
      factory=f_bintar))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-9-bintar-systemd",
      workernames=workers["x64-bbw-docker-debian-9"],
      tags=["Debian", "bintar", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'additional_args': '-DWITH_SYSTEMD=yes'},
      factory=f_bintar))

c['builders'].append(
    util.BuilderConfig(name="amd64-debian-9-bintar-initd",
      workernames=workers["x64-bbw-docker-debian-9"],
      tags=["Debian", "bintar", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'additional_args': '-DWITH_SYSTEMD=no'},
      factory=f_bintar))

c['builders'].append(
    util.BuilderConfig(name="aarch64-centos-7-bintar-systemd",
      workernames=workers["aarch64-bbw-docker-centos-7"],
      tags=["Debian", "bintar", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'additional_args': '-DWITH_SYSTEMD=yes'},
      factory=f_bintar))

c['builders'].append(
    util.BuilderConfig(name="aarch64-centos-7-bintar-initd",
      workernames=workers["aarch64-bbw-docker-centos-7"],
      tags=["Debian", "bintar", "gcc", "aarch64"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'additional_args': '-DWITH_SYSTEMD=no'},
      factory=f_bintar))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-debian-9-bintar-systemd",
      workernames=workers["p9-bbw-docker-debian-9"],
      tags=["Ubuntu", "bintar", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'additional_args': '-DWITH_SYSTEMD=yes'},
      factory=f_bintar))

c['builders'].append(
    util.BuilderConfig(name="ppc64le-debian-9-bintar-initd",
      workernames=workers["p9-bbw-docker-debian-9"],
      tags=["Ubuntu", "bintar", "gcc", "pc9"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      locks=getLocks,
      properties={'additional_args': '-DWITH_SYSTEMD=no'},
      factory=f_bintar))

c['builders'].append(
    util.BuilderConfig(name="amd64-windows",
      workernames=["bbw1-windows"],
      tags=["Windows", "quick"],
      collapseRequests=True,
      nextBuild=nextBuild,
      factory=f_windows))

c['builders'].append(
    util.BuilderConfig(name="amd64-windows-compile-only",
      workernames=["hz-bbw2-windows"],
      tags=["Windows", "quick", "compile"],
      collapseRequests=True,
      nextBuild=nextBuild,
      factory=f_windows_compile))

c['builders'].append(
    util.BuilderConfig(name="amd64-windows-packages",
      workernames=["bbw1-windows"],
      tags=["Windows", "packages", "zip"],
      collapseRequests=True,
      nextBuild=nextBuild,
      factory=f_windows_msi))

c['builders'].append(
    util.BuilderConfig(name="x86-windows",
      workernames=["bbw1-windows"],
      tags=["Windows", "quick"],
      collapseRequests=True,
      nextBuild=nextBuild,
      properties={'arch': 'x86', 'arch_cmake': 'Win32'},
      factory=f_windows))

c['builders'].append(
    util.BuilderConfig(name="x86-windows-packages",
      workernames=["bbw1-windows"],
      tags=["Windows", "packages", "zip"],
      collapseRequests=True,
      nextBuild=nextBuild,
      properties={'arch': 'x86', 'arch_cmake': 'Win32'},
      factory=f_windows_msi))

c['builders'].append(
    util.BuilderConfig(name="aix",
      workernames=['aix-worker'],
      tags=["AIX", "quick", "gcc"],
      collapseRequests=True,
      nextBuild=nextBuild,
      canStartBuild=canStartBuild,
      factory=f_aix))

# Add a Janitor configurator that removes old logs
c['configurators'] = [util.JanitorConfigurator(
    logHorizon=timedelta(weeks=6),
    hour=23
)]

c['logEncoding'] = 'utf-8'

c['multiMaster'] = True

c['mq'] = {  # Need to enable multimaster aware mq. Wamp is the only option for now.
    'type' : 'wamp',
    'router_url': 'ws://buildbot.mariadb.org:8085/ws',
    'realm': 'realm1',
    # valid are: none, critical, error, warn, info, debug, trace
    'wamp_debug_level' : 'info'
}

#### prometheus exporter //TEMP added Faustin
c['services'].append(reporters.Prometheus(port=9101))
